# Statistische Voraussetzungen

## Einführung 

Das allgemeine lineare Modell, welches wir in diesem Kurs kennen gelernt haben (kompaktes und erweitertes Modell), ist eine der beliebtesten Methoden in der Sozialforschung, um Hypothesen zu testen. Die Idee des linearen Modells ist allerdings eine menschliche Erfindung und daher nicht perfekt.Beispielsweise hat jeder Test, den wir mit Hilfe des linearen Modells gerechnet haben, bestimmte Annahmen, die wir beachten sollten.

Nehmen wir die Skalierung der abhängigen Variable. In allen Tests dieses Kurses war die abhängige Variable metrisch (intervall- oder verhältnisskaliert) skaliert. Wäre die abhängige Variable diskret skaliert (z.B. Parteizugehörigkeit), könnten wir keines unserer Testverfahren dieses Kurses verwenden. Ebenso könnte es sein, dass die abhängige Variable binär skaliert ist, dass heißt, dass es nur zwei Ausprägungen gibt. Stell dir vor, du möchstest ein Modell aufstellen, dass vorhersagt, ob eine Person den Untergang der Titanic überlebt hat. Solche Fragen lassen sich beispielsweise mit der [logistischen Regression](https://de.wikipedia.org/wiki/Logistische_Regression#:~:text=Unter%20logistischer%20Regression%20oder%20Logit,der%20Verteilung%20abh%C3%A4ngiger%20diskreter%20Variablen.) prüfen, nicht aber mit dem allgemeinen linearen Modell.

Das allgemeine lineare Modell hat allerdings noch weitere Annahmen, die wir zumindest bei jedem Test kennen sollten. Diese Annahmen sind die Linearität des Modells, die Normalverteilung der Residuen, die Homoskedastizität und die Unabhängigkeit der Daten. Sind diese Annahmen nicht getroffen, kann es im schlimmsten Fall sein, dass unsere Ergebnisse verfälscht sind. Beispielsweise, indem die Verletzungen der Annahmen den Beta-Fehler verringern bzw. die Power der Studie reduzieren. Wir werden diese Annahmen in diesem letzten Modul des Kurses besprechen und auch erfahren, wie robust unsere Tests sind, das heißt, wie stark die Ergebnisse der Tests verändert werden, sollten die Annahmen nicht umgesetzt sein.

Bevor wir beginnen, ein kleiner Hinweis: Der Umgang mit Verletzungen der Annahmen wird unter Forschenden unterschiedlich gehandhabt. Manche Forschende wissen nicht, dass diese Annahmen überhaupt existieren, andere sehen es nicht so streng mit den Verletzungen der Annahmen. Andere wiederum nehmen es sehr genau und versuchen, den besten Weg zu finden, wie mit diesen Verletzungen umgegangen wird. Ich werde in diesem Modul keine Position dazu beziehen. Mir ist es wichtig, dass du über die Annahmen Bescheid weißt. Wie mit Verletzungen der Annahmen umgegangen wird, solltest du mit dir oder der Betreuerin / dem Betreuer deiner Forschungsarbeiten besprechen.

## Übersicht der Annahmen des allgemeinen linearen Modells

In der folgenden Tabelle siehst du die Annahmen, welche das allgemeine lineare Modell (alle Modelle, die wir in diesem Kurs kennenlernen werden) annimmt. Für jeden Test ist dargestellt, wie diese Annahmen herkömmlicherweise geprüft werden. Beispielsweise lässt sich die Normalität der Residuen durch den [Shapiro-Wilk Test](https://de.wikipedia.org/wiki/Shapiro-Wilk-Test) bei den meisten Tests prüfen.

| Testverfahren                                                            | Abhängige Variable metrisch skaliert | Linearität                                                    | Normalverteilung der Residuen                     | Homoskedastizität                                         | Unabhängigkeit der Daten                                 |
|--------------------------------------------------------------------------|--------------------------------------|---------------------------------------------------------------|---------------------------------------------------|-----------------------------------------------------------|----------------------------------------------------------|
| \-                                                                       | \-                                   | Die Beziehung zwischen X und dem Mittelwert von Y ist linear. | Für jeden festen Wert von X ist Y normalverteilt. | Die Varianz der Residuen ist für jeden Wert von X gleich. | Die Beobachtungen sind voneinander unabhängig.           |
| *t*-Test für eine Stichprobe                                             | erfüllt                              | \-                                                            | Shapiro-Wilk Test / Q-Q plot                      | \-                                                        | \-                                                       |
| Einfache lineare Regression                                              | erfüllt                              | Sichtung der Daten                                            | Shapiro-Wilk Test / Q-Q plot                      | Residual plots                                            | Durch die Sichtung des experimentellen Designs erkennbar |
| Multiple lineare Regression                                              | erfüllt                              | Sichtung der Daten                                            | Shapiro-Wilk Test / Q-Q plot                      | Residual plots                                            | Durch die Sichtung des experimentellen Designs erkennbar |
| einfaktorielle Varianzanalyse (und *t*-Test für unabhängige Stichproben) | erfüllt                              | \-                                                            | Shapiro-Wilk Test / Q-Q plot                      | Levene's Test                                             | Durch die Sichtung des experimentellen Designs erkennbar |
| mehrfaktorielle Varianzanalyse                                           | erfüllt                              | \-                                                            | Shapiro-Wilk Test / Q-Q plot                      | Levene's Test                                             | Durch die Sichtung des experimentellen Designs erkennbar |
| Kovarianzanalyse (ANCOVA)                                                | erfüllt                              | \-                                                            | Shapiro-Wilk Test / Q-Q plot                      | Levene's Test                                             | Durch die Sichtung des experimentellen Designs erkennbar |

Wie du erkennst, ist die erste Annahme bei allen Tests erfüllt. Dies liegt daran, dass alle unsere Tests auf Grundlage des [allgemeinen linearen Modells](https://de.wikipedia.org/wiki/Allgemeines_lineares_Modell) berechnet werden, welches immer eine metrisch skalierte abhängige Variable umfasst. Die Linearität der Daten prüfen wir in der Regel für die einfache und lineare Regression. Die Linearität bei der einfachen linearen Regression kann man prüfen, indem man sich die Daten grafisch betrachtet. Die Normalität der Residuen kann sowohl durch grafische Plots als auch durch den Shapiro-Wilk Test (und weitere) geprüft werden. Diese Annahme besagt, dass die Fehler der Modelle normalverteilt sind. Homoskedastizität ist eine der schwierigsten Annahmen. Diese Anname besagt, dass die Varianz der Residuen (der Fehler) für jeden Wert *X* in etwa gleich sein sollten. Für die Regressionsanalysen heißt dies, dass die Fehler sich gleichmäßig im Modell verteilen. Für die Varianzanalyse heißt dies, dass die Varianzen der einzelnen Gruppen ähnlich zueinander sind. Geprüft wird diese Annahme häufig durch den Levene Test. Zuletzt nehmen die Tests die Unabhängigkeit der Daten an. Die Unabhängigkeit kann man nur durch die Sichtung des experimentellen Designs prüfen. Wenn du beispielsweise in Schulklassen Daten erhebst, sind diese Daten selten unabhängig, da Schüler\*innen innerhalb einer Klasse mehr Ähnlichkeiten aufweisen als Schüler\*innen zwischen Klassen (indem beispielsweise eine Klasse mehr Wissen über eine Thematik hat als eine andere Klasse). In diesem Kurs haben wir keine Tests kennen gelernt, mit denen Hypothesen mit abhängigen Daten gerechnet werden könnten. Dies wäre für dich ein nächster Schritt, wenn du über die Inhalte dieses Kurses hinaus gehen möchtest (siehe [Repeated Measures Design](https://en.wikipedia.org/wiki/Repeated_measures_design)). Im Folgenden werden wir die einzelnen Testverfahren kennen lernen.

## Linearität 

Beginnen wir mit der Linearität. Und schauen wir uns dazu nochmal das erweiterte Modell der linearen Regression aus diesem Kurs an. In diesem Modell hatten wir die Hypothese aufgestellt, dass es einen positiven Zusammenhang zwischen der Anzahl der Worte in einer Mitschrift von Studierenden und der Erinnerungsleistung aus einem Vortrag gibt. Folgendes Modell hatte sich damals ergeben:

![](images/12_voraussetzungen/wo%CC%88rter.png)

Du siehst, dass das erweiterte Modell (hier blau dargestellt) eine Linie darstellt. Genau dies meinen wir mit Linearität. Wir nehmen an, dass die Daten eine lineare Beziehung haben. Um besser zu verstehen, was eine lineare Beziehung ist, schau dir folgende Datenvisualisierungen an:

![](images/12_voraussetzungen/dino.png)

Diese Darstellung ist an das [Anscombe Quartett](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) angelehnt, welches vom Statistiker Francis Anscombe entwickelt wurde. Die Daten selbst stammen von [Albert Cairo](http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html), einem Datenvisualisierer, welcher mit diesen Beispielen zeigen möchte, wie wichtig es ist, Daten zu visualisieren. Uns zeigt diese Darstellung, dass Daten nicht immer linear sind. Allerdings ist dies eine Annahme des allgemeinen linearen Modells. 

Nun, warum ist eine Verletzung dieser Annahme ein Problem? Es ist ein Problem, da das lineare Modell manchmal eine lineare Beziehung annimmt, die nicht linear ist. Nehmen wir einmal den exponentiellen Anstieg der Covid Fälle weltweit. [Exponentiell ](https://www.youtube.com/watch?v=Kas0tIxDvrg)bedeutet, dass für jede Wertsteigerung von *X*, *Y* höher ansteigt. Modelle sollen allerdings immer einen Teil der Wirklichkeit darstellen. Ein lineares Modell stellt in diesem Beispiel diese Wirklichkeit nicht dar und ist daher nicht geeignet, als Modell der Daten zu dienen. 

Für dich als Forscher\*in heißt dies, dass es bei jeder linearen oder multiplen Regression notwendig ist, die Daten zu visualisieren, bevor du einen Test rechnest. Ist die Beziehung zwischen *X* und *Y* offensichtlich nicht linear, ist das allgemeine lineare Modell evtl. nicht passend und du solltest ein anderes Modell verwenden (siehe [hier](https://en.wikipedia.org/wiki/Nonlinear_regression)).

## Normalverteilung der Residuen

Die erste Annahme ist die Normalverteilung der Residuen. Diese Annahme bedeutet, dass die Fehler der Modelle normalverteilt sind:

![](images/12_voraussetzungen/e.png)

Wir prüfen demnach, ob die Abstände einer jeden Vorhersage des Modells mit den wahren Werten der Stichprobe eine Normalverteilung darstellen.

### Prüfung der Annahme durch ein Histogramm der Residuen 

Schauen wir uns dazu die Verteilung der Residuen der einfachen linearen Regression zu Beginn des Kurses an. Bei diesem Modell hatten wir den Zusammenhang zwischen der Anzahl der Worte in einer Mitschrift und der Erinnerungsleistung aus einen Vortrag geprüft. Wenn ich die Fehler des erweiterten Modells *e~i~* als Histogramm darstelle, erhalte ich folgendes Ergebnis:

![](images/12_voraussetzungen/ha%CC%88ufigkeit.png)

Nun, die Fehler verteilen sich nicht perfekt in einer Normalverteilung. Die Verteilung ist ein wenig rechtsschief, da mehr Werte links der Mitte der Verteilung zu finden sind. Ein Histogramm ist allerdings nur eine Möglichkeit, die Normalverteilung der Residuen zu prüfen. Häufig wird auch der Q-Q Plot verwendet.

### Q-Q Plot 

Die Einzelheiten eines [Q-Q Plots](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot) sind kompliziert, für dich als Forscher\*in ist zunächst wichtig, wie man mit einem Q-Q Plot umgeht: Je näher die Punkte des Q-Q Plots an der dargestellten Gerade liegen, desto stärker sind die Residuen normalverteilt. In der folgenden Darstellung siehst du den Q-Q Plot für die Daten der einfachen linearen Regression, welche wir weiter oben vorgestellt haben. Wie du siehst, gibt es Abweichungen der Punkte von der Linie, allerdings sind diese Abweichungen nicht erstaunlich groß. Es kann daher argumentiert werden, dass die Annahme der Normalverteilung der Residuen nicht verletzt wurde.

![](images/12_voraussetzungen/resi.png)

### Was ist mit anderen Testverfahren? 

Wir haben gerade das Beispiel der einfachen linearen Regression verwendet. Das Argument kann jedoch für alle unsere Tests verwendet werden, da wir wissen, dass das erweiterte Modell Vorhersagen macht, die von den realen Werten abweichen. Wir können daher für jeden Test sowohl ein Histogramm als auch ein Q-Q Plot erstellen. Genau deswegen findest du bei der ANOVA in Jamovi ebenso unter Assumption Checks eine Checkbox, bei der du dir einen Q-Q Plot ausgeben lassen kannst. Zum Beispiel haben wir im Modul zur einfaktoriellen Varianzanalyse getestet, ob das Testen von Wissen für den Erwerb konzeptuellen Wissens wirksamer ist als die Erstellung einer Concept-Map. Im folgenden Bild siehst du, dass wir ebenso für diesen Test die Normalität mit Hilfe eines Q-Q Plots testen können.

![](images/12_voraussetzungen/anova.jpg)

### Shapiro-Wilk Test 

Ein weiterer Test zur Prüfung der Normalverteilung ist der [Shapiro-Wilk Test](https://www.statisticshowto.com/shapiro-wilk-test/). Allerdings weicht dieser Test ein wenig von der eben vorgestellten Idee der Normalverteilung ab, da er testet, ob die Daten, nicht die Residuen normalverteilt sind. Der Test beantwortet daher eine etwas andere Frage und macht eine Aussage über die Normalverteilung der Daten. Bei einem nicht-signifikanten Ergebnis wird davon ausgegangen, dass die Daten normalverteilt sind. In Jamovi können wir den Shapiro-Wilk Test berechnen, indem wir unter Assumption Checks auf Normality (Shapiro-Wilk) klicken. In den Ergebnissen erhalten wir anschließend das Ergebnis. Im folgenden Bild habe ich den Shapiro-Wilk Test für die Testing-Hypothese (Testing vs. Concept-Map) berechnet. Du siehst, dass das Ergebnis nicht signifikant ist, daher kann von einer Normalverteilung der Daten ausgegangen werden.

![](images/12_voraussetzungen/anova1.jpg)

### Zusammenfassung 

Die Annahme der Normalverteilung der Residuen geht davon aus, dass die Fehler des erweiterten Modells eine Normalverteilung darstellen. Wir haben drei Wege kennen gelernt, diese Annahme zu prüfen. Die Darstellung der Fehler in einem Histogramm, den Q-Q Plot und den Shapiro-Wilk Test. Am besten schaust du dir sowohl grafische Verfahren an und prüfst die Annahme durch einen Test wie den Shapiro-Wilk Test. Inwieweit Verletzungen der Normalität die Ergebnisse verfälschen, ist eine [umfangreiche Debatte](https://www.researchgate.net/post/How_robust_is_ANOVA_to_deviations_from_normality) (siehe auch [Schmider et al., 2010](https://econtent.hogrefe.com/doi/full/10.1027/1614-2241/a000016) und [diesen Beitrag](https://stats.stackexchange.com/questions/62918/two-way-anova-robustness-against-normality-violations)). Du solltest daher immer abwägen und recherchieren, ob dein Test Gefahr läuft, durch Verletzungen der Annahme der Normalverteilung verfälschte Ergebnisse zu liefern.

## Homoskedastizität 

Eine der kryptischsten Annahmen ist die Homoskedastizität. Der Begriff klingt bereits so neu, dass man sich keine Vorstellung machen kann, was er bedeutet. Machen wir einen Versuch in diesem Submodul. Die Definition der Annahme ist, dass die Varianz der Residuen für jeden Wert von *X* gleich sein soll.

### Residual Plots 

Beginnen wir, uns diese Definition am Beispiel der linearen Regression klar zu machen. Im nächsten Bild siehst du einen sogenannten Residual Plot. In dieser Darstellung ist auf der X-Achse die unabhängige Variabe (Anzahl der Worte der Mitschrift) dargestellt. Auf der Y-Achse sind die Residuen abgetragen. Schau dir beispielsweise den Punkt ganz rechts der X-Achse an. Der Punkt befindet sich auf der Y-Achse auf der Höhe von etwa 0.1. Das heißt, für den Wert X wurde der wahre Wert Y um 0.1 Punkte überschätzt.

![](images/12_voraussetzungen/residuen.png)

Wir können diesen Residual Plot nutzen, um die Homoskedastizität zu prüfen. An dem Plot können wir diese Annahme prüfen, indem wir folgendermaßen vorgehen: Wir fragen uns, ob die Abstände der Punkte zu der Linie für die verschiedenen Werte auf der X-Achse gleichmäßig sind? In der oberen Visalisierung siehst du beispielsweise, dass die Abstände der Residuen zu der Linie für kleine Werte von X weiter sind als für hohe Werte von X. In der Tendenz herrscht daher keine perfekte Homoskedastizität vor. 

Residual plots werden allerdings meist nicht anhand der Werte der Prädiktoren, sondern durch sogenannte Fitted Values dargestellt. Fitted Values sind nichts anderes als die vorhergesagte Werte in einem Modell. In der folgenden Visualisierung siehst du einen Residual Plot, in dem statt des Prädiktors auf der X-Achse die Fitted Values dargestellt sind.

![](images/12_voraussetzungen/residuen1.png)

Wie du siehst, sieht diese Darstellung exakt gleich aus wie oben. Dies liegt allerdings daran, dass wir eine einfache lineare Regression verwendet haben. Bei einer einfaktoriellen Varianzanalyse sähe diese Darstellung anders aus. Du solltest daher wenn möglich auf die Fitted Values zurück greifen.

Um ein extremes Beispiel zu sehen, empfehle ich dir [diesen Link](https://socratic.org/questions/what-is-homoskedasticity). Dort wird anhand von zwei Grafiken sehr schnell ersichtlich, wie eine Verletzung der Homoskedastizität aussieht.

### Prüfung der Homoskedastizität durch die Darstellung der Regressionsgerade 

Bei der einfachen linearen Regression können wir diese Annahme zudem prüfen, indem wir uns die Abstände der Punkte von der Regressionsgerade ansehen. Dieses Verfahren ist den Residual Plots sehr ähnlich, nur dass wir die Visualisierung anders betrachten müssen. Wenn du nun diese Darstellung mit dem Residual Plot vergleichst, siehst du in der rechten Hälfte der beiden Visualisierungen, dass die Abstände der Punkte von der Regressionsgerade ähnlich aussehen, und dass diese Abstände auf der rechten Hälfte der X-Achse kleiner sind als auf der linken Hälfte der X-Achse. Grafisch ist der Residual Plot daher nichts anderes als wenn du die Regressionsgerade horizontal richtest und die Daten entsprechend der Regressionsgerade angepasst werden.

![](images/12_voraussetzungen/gru%CC%88n.png)

### Prüfung der Homoskedastizität durch den Levene-Test 

Bei der einfachen linearen Regression lassen sich sehr einfach grafische Verfahren einsetzen. Bei den Verfahren der Varianzanalsye ist dies etwas schwieriger. Daher gibt es Tests, die prüfen können, ob die Varianzen der Prädiktoren bei unterschiedlichen Ausprägungen ähnlich sind. Gehen wir einen Schritt zurück in die erweiterten Modelle der Varianzanalyse. Bei diesen Modellen mussten wir Gruppen als Kontraste kodieren, indem wir Gruppen in numerische Werte überführt haben. Wenn wir nun sagen, dass die Varianzen der Prädiktoren bei unterschiedlichen Ausprägungen der Prädiktoren gleich sein sollen, meinen wir folgendes: Die Varianzen der Gruppen sollten zwischen den Gruppen gleich sein. Wenn du beispielsweise eine einfaktorielle Varianzanalyse mit zwei Gruppen rechnest (*t*-Test für unabhängige Stichproben), prüfst du für die Feststellung der Homoskedastizität, ob die Varianzen von Gruppe 1 und von Gruppe 2 ähnlich sind. Die Idee bleibt die selbe wie bei der einfachen linearen Regression, nur dass wir bei der Varianzanalyse von den Varianzen der Gruppen und nicht von Ausprägungen der Werte des Prädiktoren denken müssen. Und wir testen diese Annahme mit Hilfe des [Levene-Tests](https://de.wikipedia.org/wiki/Levene-Test).

Der Levene-Test ist erneut ein statistischer Hypothesentest, der folgende Ergebnisse liefert. Ist das Ergebnis signifikant, ist keine Homoskedastizität gegeben. Ist das Ergebnis nicht signfikant, ist Homoskedastizität gegeben. Jamovi erlaubt für jede Varianzanalyse den Levene-Test zu berechnen. Klicke dazu auf Assumption Checks und dann auf Homogeneity tests. In folgendem Beispiel erhalten wir kein signifikantes Ergebnis, daher kann von der Annahme der Homoskedastizität ausgegangen werden.

![](images/12_voraussetzungen/anova2.jpg)

### Zusammenfassung 

Die Homoskedastizität ist eine der weiteren Annahmen des allgemeinen linearen Modells und daher von allen Tests, die wir in diesem Kurs kennen gelernt haben. Die Annahme ist umgesetzt, wenn die Varianz der verschiedenen Ausprägungen der Prädiktoren gleichmäßig ist. Bei der linearen Regression können wir diese Annahme grafisch prüfen, bei der Varianzanalyse können wir den Levene-Test verwenden.

## Unabhängigkeit der Daten 

Alle bisherigen Tests dieses Kurses sind davon ausgegangen, dass unsere Daten unabhängig voneinander sind. Unabhängigkeit tritt immer dann auf, wenn uns das Auftreten eines Wertes *X~i~* keine Aussage über eine andere Ausprägung von *X~i~* macht. Stell dir einen *t*-Test für unabhängige Stichproben vor, bei dem wir *vor* einer Intervention das Vorwissen von zwei Gruppen vergleichen. Die Kenntnis über das Vorwissen einer Person ermöglicht dir nicht, das Vorwissen einer anderen Person vor der Intervention zu bestimmen. Allerdings sind nicht alle Daten immer unabhängig voneinander. Stell dir vor, du möchtest vergleichen, ob Männer und Frauen unterschiedlich zufrieden in ihrer Beziehung sind. Hierzu befragst du sowohl Männer und Frauen aus vier Paaren nach ihrer Beziehungszufriedenheit:

| Paar | Männer | Frauen |
|------|--------|--------|
| 1    | 1      | 1      |
| 2    | 4      | 3      |
| 3    | 6      | 7      |
| 4    | 5      | 6      |

Wenn du nun den Wert eines Partners kennst, erhältst du automatisch Informationen über den Wert des anderen Partners. Da sich Paare zu einem gewissen Teil übereinstimmen, wie zufrieden sie in ihrer Beziehung sind, sind die Daten voneinander abhängig. Ist ein Partner unter dem Mittelwert der abhängigen Variable, wird der Partner oder die Partnerin vermutlich ebenso unter dem Mittelwert sein. Wir nennen diese Art der Abhängigkeit positive Abhängigkeit, da die Daten ähnlich zueinander sind. Eine negative Abhängigkeit würde auftreten, wenn Werte gegensätzlich voneinander abhängig sind. Stell dir zum Beispiel vor, du testest die Breite von Baumkronen. Deine Daten umfassen Baumpaare, die sehr eng beieinander stehen. Wenn nun ein Baum eine sehr breite Krone hat, wird der benachbarte Baum vermutlich eine kleinere Krone haben, da beide um das Sonnenlicht kämpfen. In diesem Fall sprechen wir von einer negativen Abhängigkeit.

Abhängigkeit kann einerseits entstehen, wenn Daten wie in diesen Beispielen gruppiert sind, andererseits tritt Abhängigkeit auf, wenn Daten sequentiell erhoben werden. Stell dir hierzu vor, du erhebst die Cholesterinwerte von Proband\*innen über mehrere Messzeitpunkte, um zu prüfen, ob der Cholesterinspiegel der Personen steigt oder sinkt. Eine Person, die bereits beim ersten Messzeitpunkt einen hohen Cholesterinspiegel hat, wird vermutlich auch beim zweiten Messzeitpunkt einen hohen Cholesterspiegel haben. Genausogut wird eine Person, die einen niedrigen Cholesterinspiegel beim ersten Messzeitpunkt hat, vermutlich auch beim zweiten Messzeitpunkt einen niedrigen Cholesterinspiegel haben. Die Folge ist, dass die Daten abhängig voneinander sind. 

Aus den Daten allein können wir nicht sagen, ob die Abhängigkeit durch eine Gruppierung oder durch sequentielle Messzeitpunkte geschieht. Es ist unser Versuchsdesign, welches uns Hinweise liefert, welche Abhängigkeit vorherrscht. Wir nennen diese zwei Möglichkeiten gekreuzte Daten und genestete Daten.

### Gekreuzte Daten 

Normalerweise treten gekreuzte Daten auf, wenn wir Daten einer Versuchsperson mehrmals erheben. Wir haben gerade eben bereits das Beispiel des Cholesterins kennen gelernt. Der Cholesterinspiegel von Proband\*innen wird mehrmals gemessen. Stell dir ein anderes Beispiel vor: Du möchtest untersuchen, ob eine bestimmte Übung einen Einfluss darauf hat, wie schnell Proband\*innen in einen Meditationszustand kommen. Du gehst davon aus, dass Proband\*innen, die diese Übung über längere Zeit durchführen, schneller in einen Meditationszustand kommen. Alle Proband\*innen führen die Übung über drei Wochen durch. Du testest die Dauer bis die Proband\*innen in den Meditationszustand kommen je einmal wöchentlich. Folgende Ergebnisse erhältst du: 

| ID  | Woche 1 | Woche 2 | Woche 3 |
|-----|---------|---------|---------|
| 1   | 140     | 130     | 100     |
| 2   | 90      | 100     | 70      |
| 3   | 160     | 140     | 120     |
| 4   | 250     | 230     | 210     |
| 5   | 30      | 40      | 20      |
| 6   | 400     | 390     | 340     |

Zunächst kannst du anhand der Tabelle erkennen, dass die Proband\*innen im Schnitt über die Wochen schneller in den Meditationszustand kommen. Die Probandin mit der ID 4 zum Beispiel benötigt am Anfang 250 Sekunden, dann 230 Sekunden, dann 210 Sekunden. Ebenso erkennst du, dass die Daten abhängig voneinander sind. Beispielsweise fällt auf, dass die Werte der Probandin mit der ID 4 relativ hoch bleiben, wenn wir sie mit der Probandin mit der ID 2 vergleichen. Wer bereits lange Zeit beim ersten Messzeitpunkt benötigt, wird auch beim nächsten Messzeitpunkt mehr Zeit benötigen.

Wann sind die Daten allerdings gekreuzt? Wir sprechen von gekreuzten Daten, wenn die Werte einzelner Personen in verschiedenen Ausprägungen eines Faktors vorliegen. In diesem Fall haben wir den Faktor Zeitpunkt mit drei Ausprägungen (Woche 1, Woche 2, Woche 3). Für jede\*n Proband\*in liegt ein Wert in jeder Ausprägung vor. Die Daten wären nicht gekreuzt, wenn Daten nur in einer Ausprägung eines Faktors vorlägen. Stell dir zum Beispiel mehrere Schulklassen vor, die unterschiedliche Lernstrategien erhalten. Schulklasse A, B und C erhalten Lernstrategie *Z u*nd Schulklasse D, E und F erhalten Lernstrategie *Q*. Die Abhängigkeit der Daten entsteht dadurch, dass die Schüler\*innen jeweils in der gleichen Klasse stecken. Diese Daten sind nicht gekreuzt, da die Schüler\*innen nur in je einer Ausprägung des Faktors Schulklasse stecken.

Ein anderes Beispiel: Du möchtest prüfen, ob sich das Verhalten von Schüler\*innen ändert, wenn man ihnen öfter Lob gibt. Bisher hätten wir solche Fragestellungen getestet, indem wir zwei unabhängige Gruppen umgesetzt hätten, welche entweder gelobt werden oder nicht gelobt werden. Durch ein solches Design könnten wir allerdings nicht prüfen, ob Lob über die Zeit zu einer Veränderung des Verhaltens der Schüler\*innen führt. In deinem neuen Design gibst du daher allen Schüler\*innen über fünf Messzeitpunkte Lob. Erneut sind die Daten gekreuzt, da für jede Ausprägung des Faktors Messzeitpunkt ein Datenpunkt je eines Schülers / einer Schülerin steckt. In den Lehrbüchern spricht man dann in der Regel von Messwiederholungsdesigns. Diese sind in der einfachsten Form immer dadurch erkennbar, dass die Daten gekreuzt sind.

### Genestete Daten 

Wir hatten genestete Daten bereits mit unserem Schulklassenbeispiel kennen gelernt. Schüler\*innen innerhalb einer Schulklasse erhalten entweder die Lernstrategie *Q* oder die Lernstrategie *Z*. Genestete Daten zeichnen sich dadurch aus, dass die Proband\*innen bzw. Datenpunkte nur in einer Ausprägung eines Faktors vorliegen. In diesem Fall erhalten die Schüler\*innen der jeweiligen Gruppen nur eine der beiden Lernstrategien. Diese Aussage gilt nur für den Fall, wenn wir entweder gekreuzte oder genestete Daten vorliegen haben. Es gibt auch Designs, die beide Strukturen beinhalten. Über diese Designs werden wir allerdings in diesem Modul nicht sprechen. Um genestete Daten besser zu verstehen, siehst du hier in Beispiel des Lernstrategietrainings:

| \-      | Treatment Q | Treatment Z |
|---------|-------------|-------------|
| y       | Klasse A    | Klasse B    |
| *y~1i~* | 7           | 9           |
| *y~2i~* | 3           | 8           |
| *y~3i~* | 2           | 10          |
| *y~i~*  | 5           | 7           |

In der Tabelle kannst du erkennen, dass die Schüler\*innen innerhalb einer Schule immer nur entweder Treatment *Q* oder Treatment *Z* bekommen. Die Daten sind daher nicht gekreuzt. Allerdings sind die Daten unter dem Faktor der Schulklasse genested, was dazu führst, dass sich Schüler\*innen innerhalb einer Klasse ähnlich sind. Manche Klassen sind im Schnitt besser als die anderen Klassen. Hierdurch wissen wir, dass beispielsweise eine Schülerin aus Klasse A, die sehr gut ist, vermutlich besser sein wird, als eine Schülerin aus Klasse B, die etwas schlechter ist. 

Genestete Daten finden sich sehr häufig in großen Schulstudien, in denen Erhebungen in Klassen erhoben werden. Stell dir beispielsweise die PISA-Studie vor, in der nicht nur Klassen, sondern auch Schulen genested vorliegen können. Die statistischen Verfahren in solchen Designs werden zunehmend komplexer.

### Folgen gekreuzter und genesteter Daten für die Power einer Studie 

Ignoriert man die gekreuzte oder genestete Struktur von Daten, hat dies Einfluss auf den *F*-Wert und damit auch auf die Power einer Studie. Verletzung der Annahme der Unabhängigkeit sind die gravierendsten und sollten auf jeden Fall beachtet werden, wenn man die Daten mit Hilfe verschiedener statistischer Verfahren auswertet. Eine Übersicht der Auswirkungen siehst du in der folgenden Tabelle: 

| \-              | Arten der Abhängigkeit |
|-----------------|------------------------|
| **Gruppe**      | **positiv**            |
| Genestete Daten | *F* zu groß            |
| Gekreuzte Daten | *F* zu klein           |

Stell dir ein Beispiel vor: Du möchtest eine Messwiederholungsanalyse mit gekreuzten Daten rechnen. Innerhalb der Daten herrscht eine positive Abhängigkeit. Beispielsweise indem man die Entwicklung der intrinsischen Motivation von Studierenden über eine längere Zeit testet. Wer am Anfang intrinsisch motiviert ist, wird wohl auch später intrinsisch motiviert sein. Verletzt du nun die Annahme der Abhängigkeit und berechnest statt einer Messwiederholungsanalyse eine einfaktorielle Varianzanalyse, erhältst du in der Regel einen zu kleinen *F*-Wert. Dies bedeutet, du bist mit einer geringeren Wahrscheinlichkeit in der Lage, einen möglichen Effekt zu finden, da deine Power geringer wird. Als Folge könntest du über viele Experimente zu dem Entschluss kommen, dass es zu keiner Veränderung in der intrinsischen Motivation kommt, obwohl dieser Effekt existiert. Du solltest daher von vorneherein überlegen, ob dein Design abhängig oder unabhängig ist. Erst dann kannst du die korrekten Verfahren zum Testen deiner Hypothese auswählen.

### Zusammenfassung 

Wir haben in diesem Modul die Vorraussetzungen der allgemeinen linearen Modelle und damit unserer Testverfahren kennen gelernt. Manchmal werden diese Annahmen verletzt und dann müssen wir uns Gedanken machen, wie wir damit umgehen. Es gibt dabei keine festen Regeln, wie mit Verletzungen der Annahmen umgegangen werden soll. Forschende verfahren sehr unterschiedlich. Manche nehmen es sehr ernst mit den Verletzungen der Annahmen, andere weniger. In jedem Fall solltest du darüber informiert sein, dass es diese Annahmen gibt und dass diese deine Ergebnisse verfälschen können. 

Mit diesem Modul haben wir diesen Kurs abgeschlossen. Du solltest nun in der Lage sein, die meisten statistischen Fragestellungen durch die besprochenen Testverfahren prüfen zu können. Die wichtigste Botschaft dieses Kurses ist, dass wir nie Theorien bestätigen können, sondern nur falsifizeren können. Der Begriff der Signifikanz ist nur ein statistischer Ausdruck für diese Idee. Die andere zentrale Botschaft dieses Kurses ist, dass alle Testverfahren dieses Kurses durch das allgemeine lineare Modell geprüft werden können, indem wir erweiterte und kompakte Modelle aufstellen. Hast du diese Idee einmal verstanden, wirst du erkennen, dass ein *t*-Test für unabhängige Stichproben nur ein Sonderfall der einfaktoriellen Varianzanalyse ist. Und dass die einfache lineare Regression mit der einfaktoriellen Varianzanalyse zu vergleichen ist, nur dass die Prädiktoren anders definiert sind. Ich hoffe, ich konnte dir diese beiden Ideen in diesem Kurs vermitteln.
