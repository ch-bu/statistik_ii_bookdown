[{"path":"index.html","id":"einführung","chapter":"1 Einführung","heading":"1 Einführung","text":"sample book written Markdown. can use anything Pandoc’s Markdown supports, e.g., math equation \\(^2 + b^2 = c^2\\).bookdown package can installed CRAN Github:Remember Rmd file contains one one chapter, chapter defined first-level heading #.compile example PDF, need XeLaTeX. recommended install TinyTeX (includes XeLaTeX): https://yihui.org/tinytex/.","code":"\ninstall.packages(\"bookdown\")\n# or the development version\n# devtools::install_github(\"rstudio/bookdown\")"},{"path":"intro.html","id":"intro","chapter":"2 Über den Kurs","heading":"2 Über den Kurs","text":"https://www.nationalgeographic.com/science/phenomena/2012/03/10/failed-replication-bargh-psychology-study-doyen/https://replicationindex.com/2017/11/28/--know---john--bargh--quantitative-book-review/http://www.decisionsciencenews.com/2012/10/05/kahneman---storm--doubts-surrounding-social-priming-research/https://replicationindex.com/2019/03/17/raudit-bargh/","code":""},{"path":"intro.html","id":"aufbau","chapter":"2 Über den Kurs","heading":"2.1 Aufbau","text":"13 Termine vom 19. April bis zum 24. Juli","code":""},{"path":"intro.html","id":"termine","chapter":"2 Über den Kurs","heading":"2.1.1 Termine","text":"Mein Teil\n* 20. April - Einführung\n* 27. April - Grundlagen R und Jamovi\n* 03. Mai - Hypothesentesten\n* 11. Mai - Statistische ModellierungTeil der Studierenden (Vignetten für diese Sitzungen)\n* 18. Mai - Einfache lineare Regression\n* 25. Mai - Pfingstpause\n* 01. Juni - Multiple lineare Regression\n* 08. Juni - Einfaktorielle Varianzanalyse\n* 15. Juni - Mehrfaktorielle Varianzanalyse\n* 22. Juni - Ancova\n* 29. Juni - Mediation\n* 06. Juli - ModerationEnde\n* 13. Juli - Wiederholung und Evaluation\n* 20. Juli - Klausur (gleicher Aufbau, gleiche Idee)","code":""},{"path":"intro.html","id":"präsenztermine-aufbau","chapter":"2 Über den Kurs","heading":"2.1.2 Präsenztermine Aufbau","text":"14:15 - 14:25: Einführung14:25 - 15:10: Vorstellung der Studie15:10 bis 15:45: Angeleitete Diskussion","code":""},{"path":"intro.html","id":"didaktische-ideen","chapter":"2 Über den Kurs","heading":"2.2 Didaktische Ideen","text":"Studien, die untersucht wurden, nachzurechnen und erklären zu können\nabhängige und unabhnägige Variablen finden können\nberechnete Modell aufzeichnen können\ndie Parameter der Modelle erklären können\nstatistische Entscheidung bestimmen können\ngerichte von ungerichteten Hypothesen unterscheiden können\ndie Signifikanz interpretieren können\ndie Effektgröße interpretieren können\ndas Konfidenzintervall interpretieren können\ndie Ergebnisse R und Jamovi nachrechnen können\nden Output aufschreiben können\nwenn - dann Fragen beantworten können (Freiheitsgrade der Forscher)\nabhängige und unabhnägige Variablen finden könnenberechnete Modell aufzeichnen könnendie Parameter der Modelle erklären könnenstatistische Entscheidung bestimmen könnengerichte von ungerichteten Hypothesen unterscheiden könnendie Signifikanz interpretieren könnendie Effektgröße interpretieren könnendas Konfidenzintervall interpretieren könnendie Ergebnisse R und Jamovi nachrechnen könnenden Output aufschreiben könnenwenn - dann Fragen beantworten können (Freiheitsgrade der Forscher)","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlagen-r-r-studio-und-jamovi","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3 Grundlagen R, R-Studio und Jamovi","text":"","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"einführung-1","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.1 Einführung","text":"diesem Modul beschäftigen wir uns mit den Softwares, die wir für dieses Semester verwenden werden und wir wiederholen die Inhalte aus dem Seminar Statistik . Folgende Submodule umfasst dieses Modul:Software des Seminars: diesem Submodul erfährst du, welche Softwares wir für das Seminar verwenden und wie du diese installierst.Grundlagen R: diesem Submodul wiederholst du die grundlegenden Befehle R und lernst, wie du mit R und R-Studio arbeiten kannst.Grundlagen tidyverse: diesem Submodul lernst du mit der Statistik-Software Jamovi umzugehen. Wir werden Jamovi diesem Kurs verwenden, um statistische Fragestellungen zu beantworten.Quiz Statistik : dieser Stelle wiederholst du zentrale Konzepte aus Statistik , die Vorraussetzung für dieses Seminar sind.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"software-des-seminars","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.2 Software des Seminars","text":"Wir werden diesem Kurs drei Softwares verwenden. R, R-Studio und Jamovi. R und R-Studio verwenden wir, um Daten zu bereinigen, deskriptive Daten zu berechnen und die Ergebnisse unserer Tests zu dokumentieren. Jamovi verwenden wir, um statistische Fragestellungen zu beantworten. Beide Softwares lassen sich miteinander integrieren, indem wir Ergebnisse aus Jamovi als Code R übertragen können. Der Vorteil dieser Übertragung ist, dass du hierdurch keine Befehle R lernen musst und dadurch ohne große Mühe statistische Testverfahren R rechnen kannst. diesem Modul lernst du diejenigen Kentnisse R und Jamovi, die wir diesem Seminar immer wieder brauchen.R: R ist eine statistische Programmiersprache zur Analyse von Daten. Mit R werden wir diesem Kurs Daten bereinigen und visualisieren. Datenvisualisierung ist ein zentraler Bestandteil der Datenanalyse, da wir durch Visualisierungen Muster Daten erkennen können, die aus den Rohdaten schwer zu entnehmen sind. Zudem verwenden wir R für die Dokumentation unserer Ergebnisse. Die Dokumentation ist wichtig, da wir auch Jahre nach unserer Analyse verstehen möchten, wie wir die Daten ausgewertet haben. SPSS oder Jamovi ist dies deutlich unübersichtlicher.R-Studio: R-Studio ist eine Entwicklungsumgebung für die Programmiersprache R. Sie umfasst eine grafische Benutzeroberfläche und vereinfacht die Arbeit mit R.Jamovi: Jamovi ist eine Software mit der man die gängigsten statistischen Verfahren einer grafischen Benutzeroberfläche berechnen kann. diesem Kurs verwenden wir Jamovi zur Berechnung der Verfahren und werden deren Ergebnisse R übertragen. Zwar wird der empirischen Sozialforschung häufig SPSS eingesetzt, allerdings ist SPSS kostenpflichtig und umfasst viele Verfahren, die wir diesem Kurs nicht benötigen. Jamovi hat den Vorteil, dass es kostenlos ist und eine ähnliche Oberfläche wie SPSS hat. Der Transfer zu SPSS ist daher relativ einfach. Ein weiterer Grund für Jamovi ist, dass es sich sehr einfach mit R integrieren lässt.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"download-der-software","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.3 Download der Software","text":"Die drei Softwares sind unter folgenden Links kostenfrei für Mac und Windows zugänglich. Lade dir die Softwares gleich jetzt herunter. Wir werden alle drei Softwares jedem Modul des Kurses verwenden.R > 4.0.2: Lade R der Version 4.0.2 oder größer herunter.R-Studio: Lade die neueste Version von R-Studio herunter.Jamovi 1.2 solid: Lade die Version 1.1.9 solid von Jamovi herunter.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"warum-so-viele-softwares","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.4 Warum so viele Softwares?","text":"Es ist heutzutage nicht mehr möglich Statistik ohne Software zu betreiben. Wir werden diesem Kurs versuchen, diejenigen Softwares zu verwenden, mit denen du einfachsten Daten analysieren und statistische Verfahren berechnen kannst. Ein paar Fragen könntest du dir dieser Stelle dennoch stellen:Warum überhaupt R? Keine Datenanalyse kommt ohne die Verarbeitung von Daten aus. Stell dir beispielsweise vor du möchtest neue Variablen berechnen bzw. ein Balkendiagramm erstellen. Solche Datenveränderungen und Visualisierungen lassen sich R sehr elegant mit dem Pakettidyverseumsetzen. Zudem ermöglicht uns das Paketggplot2 die Visualisierung von Daten. R ist zudem kostenfrei und kann sowohl auf Mac als auch auf Windows installiert werden.Warum nicht alles R? R hat für Beginner eine steile Lernkurve. Viele statistische Verfahren lassen sich direkt R berechnen (z.B.psych,car), jedoch muss man hierfür häufig mehrere Pakete installieren und diese ebenso anwenden können. Wir vermeiden dies diesem Kurs, indem wir die Analysen Jamovi umsetzen.Warum nicht alles SPSS? SPSS ist eine der Sozialforschung beliebte Software, um statistische Verfahren zu rechnen. SPSS ist allerdings kostenpflichtig. Da es kostenfreie Alternativen gibt, die alle Verfahren dieses Kurses abdecken, rechnen wir mit Jamovi. Wenn man Jamovi verstanden hat, ist der Transfer zu SPSS einfach.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlagen-r","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5 Grundlagen R","text":"diesem Submodul lernst du zentrale Befehle R, welche du immer wieder verwenden wirst. Genauer gehen wir auf folgende Themen ein:Umgang mit R-StudioPakete installieren und ladenDas ArbeitsverzeichnisDatensätze importierenGrundlegende OperatorenGrundlegende Funktionen RDaten exportieren","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"umgang-mit-r-studio","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.1 Umgang mit R-Studio","text":"R-Studio ist eine Entwicklungsumgebung für die Programmiersprache R. R-Studio vereinfacht dir die Arbeit mit R, indem es beispielsweise einen Editor integriert, welchen du R-Code schreiben kannst. R-Studio hat vier zentrale Fenster:\nFigure 3.1: Die vier zentralen Fenster von R-Studio\nIm Skript links oben findest du die R-Skripte. Dort speicherst du diejenigen Befehle, welche du auf jeden Fall speichern möchtest. Beispielsweise ein statistisches Verfahren, mit welchem du eine Hypothesen prüfst oder eine Visualisierung, die du erstellt hast.der Konsole links unten probierst du verschiedene Befehle aus. Die Konsole ist flüchtig und daher kein Ort, um dauerhaft Berechnungen zu sichern. Hierfür verwendest du besten das Skript.Das Environment und die History im Fenster rechts oben ist für diesen Kurs weniger relevant. Im Environment siehst du, auf welche Variablen und Daten du zugreifen kannst.Rechts unten findest du den Output und die Plots/Visualisierungen. der Regel schaust du hier deine Visualisierungen , die du im Skript bzw. der Konsole erstellst.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"befehle-aus-der-konsole-ausführen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.2 Befehle aus der Konsole ausführen","text":"Befehle lassen sich sowohl der Konsole als auch im Skript ausführen. Als Faustregel: Die Konsole dient dem Herumspielen mit den Daten, im Skript schreibst du alle Befehle auf, die du gerne behalten möchtest. Nehmen wir , du möchtest die Zahl 5 mit der Zahl 8 addieren:Um den Befehl der Konsole auszuführen, drückst du die ENTER-TasteAnschließend erhältst du das Ergebnis der Berechnung. Um diesen Output aus der Konsole wieder zu entfernen, kannst du die Tastenkombination STRG+L verwenden. Hierdurch verschwindet der Output:Wenn du eine Grafik erstellst (den Code musst du dieser Stelle nicht verstehen), wird der Output dem Plots Panel angezeigt, ohne dass du der Konsole einen Output erhältst:","code":"\n5 + 8## [1] 13"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"befehle-aus-dem-skript-ausführen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.3 Befehle aus dem Skript ausführen","text":"Genau die gleichen Befehle kannst du aus einem Skript ausführen (Um ein neues Skript zu öffnen drücke STRG + UMSCHALT + N auf deiner Tastatur):Um diesen Befehl auszuführen, musst du Deinen Cursor auf die jeweilige Zeile legen und STRG+ENTER drücken (für Mac-Nutzer: command + enter):Wenn du ENTER-Taste nicht drückst, springt der Cursor die nächste Zeile, ohne dass der Befehl ausgeführt wird. Alternativ kannst du die Zeile ausführen, indem du den Button Run drückst:Um mehrere Zeilen ausführen, musst du mehrere Zeilen selektieren und STRG+ENTER drücken:","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"pakete-installieren-und-laden","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.4 Pakete installieren und laden","text":"Ein Paket ist eine Sammlung Funktionen und Daten, welche du gebündelt herunterladen kannst. Pakete erweitern die Funktionalität von R. R hat bereits viele Funktionen, die wir für die Datenanalyse verwenden können. Beispielsweise umfasst R die Funktion mean, mit der wir Mittelwerte aus einer Variablen berechnen können. Selbst wenn R hunderte Funktionen hat, die mit R mitgeliefert werden, brauchen wir häufig weitere Funktionen, um unsere Daten zu analysieren. Für diesen Kurs benötigen wir insbesondere Pakete, mit denen wir Daten analysieren, visualisieren und auswerten können. diesem Kurs verwenden wir folgende Pakete:tidyverse: Tidyverse umfasst eine Vielzahl Paketen zur Analyse und Verarbeitung von Daten. Die Pakete haben eine einheitliche Philosophie und arbeiten reibungslos miteinander.jmv >= 1.2.23: jmv ist ein Paket, welches mit Jamovi zusammen arbeitet und uns ermöglicht, die Analysen, die wir Jamovi umgesetzt haben, R zu übertragen.janitor: Viele Datensätze sind unstrukturiert und enthalten komplexe Variablennamen. Mit dem Paket janitor können wir diese bereinigen.styler: Mit styler können wir unseren Code formatieren, dass er den Gestaltungsrichtlinien entspricht. Beispielsweise möchten wir nicht, dass eine Zeile Code länger als 80 Zeilen ist. Mit Hilfe von styler können wir solche Fehler durch einen Klick korrigieren.Du kannst zu jeder Zeit R-Studio sehen, welche Pakete installiert sind, indem du dir den Package Panel anschaust (rechts unten R-Studio):","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"pakete-intallieren","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.4.1 Pakete intallieren","text":"Um Pakete zu installieren, kannst du R-Studio auf Install unter dem Fenster Packages klicken:Trage zunächst das Paket unter Packages ein und drücke anschließend auf Install. Installiere sowohl tidyverse, janitor, jmv als auch styler. Alternativ kannst du direkt den Befehl die Konsole eingeben, um die Pakete zu installieren (führe die Befehle besten nacheinander aus):Prüfe anschließend, ob alle Pakete installiert wurden. Suche hierfür die Pakete dem Panel Packages:","code":"\ninstall.packages(\"tidyverse\")\n# Dann\ninstall.packages(\"janitor\")\n# Dann\ninstall.packags(\"jmv\")\n# Dann\ninstall.packags(\"styler\")"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"pakete-laden","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.4.2 Pakete laden","text":"Um die Funktionalität eines Paketes verwenden zu können, ist es mit der Installation nicht getan. Wir müssen die Pakete zusätzlich laden. besten lädst du die Pakete immer Anfang deines R-Skripts, indem du folgende Befehl für jedes Paket eingibst:Um anschließend zu prüfen, welche Pakete gerade geladen sind, kannst du den Befehl sessionInfo() ausführen:Unter loaded via namespace kannst du erkennen, welche Pakete installiert sind, aber nicht geladen sind. Unter attached packages siehst du, welche Pakete geladen sind, beispielsweise jmv. Erst nachdem ein Paket geladen ist, kannst du die Funktionen der Pakete verwenden. Wenn du R-Studio neu startest, muss jedes Paket immer neu geladen werden. Diesen Schritt vergisst man häufig, wodurch Fehler entstehen. Stelle daher immer sicher, dass du die nötigen Pakete lädst, bevor du Funktionen der Pakete verwendest. Um zu prüfen, aus welchem Paket eine Funktion stammt, setze ein Fragezeichen vor die Funktion (siehe nächstes Bild links oben). Anschließend siehst du die Dokumentation dieses Befehls dem Panel Help:","code":">     library(tidyverse)\n>     library(jmv)\nsessionInfo()## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 10 x64 (build 22000)\n## \n## Matrix products: default\n## \n## locale:\n## [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n## [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n## [5] LC_TIME=German_Germany.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n## [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.6     purrr_0.3.4    \n## [5] readr_1.4.0     tidyr_1.1.3     tibble_3.1.2    ggplot2_3.3.4  \n## [9] tidyverse_1.3.1\n## \n## loaded via a namespace (and not attached):\n##  [1] tidyselect_1.1.1 xfun_0.24        bslib_0.3.1      haven_2.4.1     \n##  [5] colorspace_2.0-1 vctrs_0.3.8      generics_0.1.0   htmltools_0.5.2 \n##  [9] yaml_2.2.1       utf8_1.2.1       rlang_0.4.11     jquerylib_0.1.4 \n## [13] pillar_1.6.1     withr_2.4.2      glue_1.4.2       DBI_1.1.1       \n## [17] dbplyr_2.1.1     readxl_1.3.1     modelr_0.1.8     jpeg_0.1-8.1    \n## [21] lifecycle_1.0.0  cellranger_1.1.0 munsell_0.5.0    gtable_0.3.0    \n## [25] rvest_1.0.0      memoise_2.0.0    evaluate_0.14    knitr_1.33      \n## [29] fastmap_1.1.0    fansi_0.5.0      highr_0.9        broom_0.7.7     \n## [33] Rcpp_1.0.7       backports_1.2.1  scales_1.1.1     cachem_1.0.5    \n## [37] jsonlite_1.7.2   fs_1.5.0         png_0.1-7        hms_1.1.0       \n## [41] digest_0.6.27    stringi_1.6.2    bookdown_0.24    grid_4.1.0      \n## [45] cli_3.0.1        tools_4.1.0      magrittr_2.0.1   sass_0.4.0      \n## [49] crayon_1.4.1     pkgconfig_2.0.3  downlit_0.4.0    ellipsis_0.3.2  \n## [53] xml2_1.3.2       reprex_2.0.0     lubridate_1.7.10 assertthat_0.2.1\n## [57] rmarkdown_2.9    httr_1.4.2       rstudioapi_0.13  R6_2.5.0        \n## [61] compiler_4.1.0"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"das-arbeitsverzeichnis","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.5 Das Arbeitsverzeichnis","text":"Wenn du R öffnest, legt R im Hintergrund immer einen Ordner fest, aus dem du alle Dateien importierst und exportierst. Diesen Ordner nennt man das Arbeitsverzeichnis. Du kannst dir das Arbeitsverzeichnis R anzeigen lassen, indem du folgenden Befehl der Konsole ausführst:Als Output erhältst du das Verzeichnis des Ordners, welcher gerade als Arbeitsverzeichnis bestimmt ist.Solange du R nicht mit Projekten arbeitest, musst du wissen, wo das Arbeitsverzeichnis liegt, um Dateien zu importieren. Wenn du beispielsweise folgenden Befehl verwendest, um die Datei human_resources.csv einzulesen, nimmt R automatisch , dass sich diese Datei im Arbeitsverzeichnis befindet:Der Text zwischen den Anführungszeichen wird auch als relativer Pfad bezeichnet. Liegt die Datei beispielsweise einen Ordner über dem Arbeitsverzeichnis (unserem Beispiel im Ordner Dropbox), verwenden wir zwei Punkte, um einen Ordner nach oben zu klettern:Nun sucht R die Datei human_resources.csv im Ordner Dropbox. Die einfachste Methode, um allerdings eine Datei zu importieren, ist, das Arbeitsverzeichnis dort festzulegen, wo die Datei gespeichert ist. Dies können wir tun, indem wir den Shortcut Ctrl+ UMSCHALT + H R-Studio ausführen. Danach öffnet sich ein Fenster, dem wir das Arbeitsverzeichnis bestimmen können.","code":"\ngetwd()## [1] \"C:/Users/Christian Burkhart/repositories/statistik_ii_bookdown\"\n# Nehmen wir an, dass sich das Arbeitsverzeichnis \n# in folgendem Ordner befindet: \n#    C:/Users/Christian/Dropbox/Lehre\nhuman_resources <- read_csv(\"human_resources.csv\")\n# Nehmen wir an, dass sich das Arbeitsverzeichnis \n# in folgendem Ordner befindet: \n#    C:/Users/Christian/Dropbox/Lehre\nhuman_resources <- read_csv(\"../human_resources.csv\")"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"datensätze-importieren","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.6 Datensätze importieren","text":"diesem Kurs arbeiten wir mit Daten, die Tabellen angeordnet sind. Häufig liegen Daten als Excel-Dateien vor. Ein gängiges Format, um Daten zu speichern sind allerdings CSV-Dateien. CSV steht für Comma Seperated Values. Dies bedeutet, dass Werte CSV-Dateien entweder durch ein Komma oder ein Semikolon getrennt sind. folgendem Beispiel siehst du ein Datensatz mit drei Variablen, die jeder Reihe durch ein Komma getrennt sind:Da CSV-Dateien ein sehr bekanntes Dateiformat für Daten sind, lassen sich CSV-Dateien sowohl Excel, Jamovi, SPSS, als auch R importieren (Excel, SPSS, Jamovi). Wir werden diesem Modul mit dem Datensatz human_resources.csv arbeiten.Eine CSV-Datei können wir R importieren, indem wir die Datei dem Panel Files suchen und auf die Datei klicken. Klicke anschließend auf auf Import Dataset:Anschließend siehst du ein neues Fenster, welchem der Code angezeigt wird, mit dem wir die Daten importieren können. Kopiere einfachsten die zweite Zeile des Code Preview (gelb markiert) und drücke dann auf Cancel.Falls die Daten nicht sauber Spalten angeordnet sind, kannst du unter dem Reiter Delimiter die Trennzeichen ändern. Im folgenden Beispiel sind die Trennzeichen der CSV-Datei Kommas.Diesen kopierten Code fügst du dein R-Skript ein. Achte darauf, dass du vorher das Paket tidyverse lädst:\nFigure 3.2: Beispiel für das Laden eines Datensatzes mit dem Paket tidyverse\nIm nächsten Schritt liest du den Datensatz ein, indem du den Befehl ausführst:Die rote Schrift hat keine Bedeutung. Sie zeigt , welche Variablen der Datensatz umfasst. Um zu prüfen, ob der Datensatz der Variable gespeichert wurde, gib den Datensatz der Konsole aus:Gleichzeitig kannst du im Panel Environment sehen, ob dein Datensatz geladen wurde:Der Output zeigt uns , dass der Datensatz 1470 Reihen und 17 Variablen hat.","code":"id,variable1,variable2\nku22su99,2,3\nnn08se21,5,6"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlegende-operatoren-in-r","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.7 Grundlegende Operatoren in R","text":"","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"rechenoperationen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.7.1 Rechenoperationen","text":"R umfasst die typischen Rechenoperatoren, die du aus der Schule kennst. Du kannst mit R Plus, Minus oder Geteilt rechnen.Zahlen voneinander teilen:Das Produkt zweier Zahlen berechnen:Zwei Zahlen miteinander addieren:Die Zeichen +, -, / oder * nennen wir Operatoren. Operatoren sind nichts anderes als besondere Symbole, die eine bestimmte Aufgabe haben. Zum Beispiel hat der Operator + die Aufgabe, zwei Zahlen zu addieren. Wir können ebenso mehrere Operatoren miteinander verschachteln:","code":"\n3 / 9## [1] 0.3333333\n3 * 4## [1] 12\n3 + 4 ## [1] 7\n(3 / 9) * 4 + 3## [1] 4.333333"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"der-zuordnungsoperator","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.7.2 Der Zuordnungsoperator","text":"Der Zuordnungsoperator <- wird verwendet, um Variablen zu kreiieren. Variablen kannst du dir wie Boxen bei einem Umzug vorstellen, die etwas enthalten. Jede Box bekommt ein Label, hier einen Variablennamen. der Box steckt, kannst du erfahren, indem du die Box aufmachst, bzw. dir die Variable R ausgeben lässt. Erstellen wir hierzu eine neue Variable mit dem Namen sum_score:Jede Variable umfasst drei Elemente:Der Variablenname: sum_score beispielsweise. Dieser Name ist willkürlich. Er sollte nicht mit einer Zahl beginnen und kleingeschrieben sein. Trenne mehrere Wörter besten mit einem Unterstrich (z.B. sum_score).Der Variablenname: sum_score beispielsweise. Dieser Name ist willkürlich. Er sollte nicht mit einer Zahl beginnen und kleingeschrieben sein. Trenne mehrere Wörter besten mit einem Unterstrich (z.B. sum_score).Der Zuordnungsoperator <-: Achte darauf, dass vor dem < und hinter dem - ein Leerzeichen steht. Ebenso sollte zwischen Operatoren ein Leerzeichen stehen. Falsch: sum_score<-3+4, falsch: sum_score <- 3+4, richtig: sum_score <- 3 + 4.Der Zuordnungsoperator <-: Achte darauf, dass vor dem < und hinter dem - ein Leerzeichen steht. Ebenso sollte zwischen Operatoren ein Leerzeichen stehen. Falsch: sum_score<-3+4, falsch: sum_score <- 3+4, richtig: sum_score <- 3 + 4.Der Inhalt der Variable: 3 + 4. Der Inhalt kann im Prinzip alles sein: Text: “Hallo,” ein Datensatz: read_csv(…) oder der Output einer Funktion: mean(c(1, 3, 4))Der Inhalt der Variable: 3 + 4. Der Inhalt kann im Prinzip alles sein: Text: “Hallo,” ein Datensatz: read_csv(…) oder der Output einer Funktion: mean(c(1, 3, 4))Wenn du eine Variable erstellst, passiert zunächst nichts. R speichert intern das Produkt der Variable sum_score. Um das Ergebnis der Berechnung zu sehen, führe die Variable R aus:Variablennamen sollten immer geschrieben sein, dass man weiß, der Variable steckt:Trenne einzelne Wörter der Variable mit einem Unterstrich:Schreibe Variablen besten alle Buchstaben des Variablennamen Kleinschreibung:Variablen sollten exakt angegeben werden. Kleinste Fehler führen zu Fehlern. Zum Beispiel macht die Groß- oder Kleinschreibung einen Unterschied:","code":"\nsum_score <- 3 + 4\nsum_score## [1] 7\nx <- 3 + 2 # schlecht\nsumme_zahlen <- 3 + 2 # besser\nmy_age <- 24  # gut\n\nmy.age <- 24 # schlecht\nmy-age <- 24 # schlecht\nmy/age <- 24 # schlecht\nmy_age <- 24\n\n# nicht:\nMy_age <- 24\nmy_age <- 24\nMy_age\n# Error: object 'My_age' not found"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"der-operator","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.7.3 Der == Operator","text":"Wir können ebenso prüfen, ob zwei Werte gleich sind, indem wir den == Operator verwenden:Oder:Oder:Später werden wir diesen Operator verwenden, um Reihen einem Datensatz zu filtern. Eine volle Liste der restlichen Operatoren findest du hier.","code":"\n3 == 4## [1] FALSE\n3 == 3## [1] TRUE\n3 == 1 + 2## [1] TRUE"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"funktionen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.8 Funktionen","text":"Jede Programmiersprache ist nur umfangreich, wie viele Funktionen sie hat. Funktionen werden von Menschen geschrieben, deren Ziel es ist, verschiedenste Berechnungen zu automatisieren. Gib zum Beispiel einmal deine Konsole nur die Funktion mean ein. du erhältst ist der Beginn einer Funktion, die Menschen für die Programmiersprache R geschrieben haben. Funktionen haben immer den gleichen Aufbau:function_name: Dies ist der Name der Funktion. Auch dieser ist wie bei Variablen willkürlich gewählt.argument1: Funktionen haben immer Argumente. Ein Argument besagt, welche Objekte eine Funktion gespeist werden. Stell dir Funktionen wie eine Fabrik vor, die etwas herstellt. Jede Fabrik benötigt Rohmaterial mit dem Produkte erzeugt werden. Argumente sind äquivalent zu Rohmaterialien. Sie werden die Funktion gespeist und der Funktion verarbeitet.value1: Jedes dieser Rohmaterialien hat bestimmte Werte. Beispielsweise kann value1 eine Zahl (3) oder ein Text sein (“Hallo”). Wir werden später andere Datentypen kennen lernen, die ebenso Funktionen gespeist werden können (z.B. Vektoren oder Dataframes - mehr dazu gleich).Beispielsweise umfasst R die Funktion sqrt mit der wir die Wurzel einer Zahl berechnen können:Mit Hilfe des ? Zeichens können wir die Funktion näher betrachten und uns ansehen, welche Argumente eine Funktion annimmt:Die Funktion sqrt hat demnach nur ein Argument mit dem Namen x. x kann sowohl eine einzelne Zahl als auch mehrere Zahlen sein. Wir müssen das Argument nicht immer angeben. Wir hätten die Funktion daher auch formulieren können:Achte darauf, dass jede Funktion mit einer Klammer schließt. Tust du dies nicht, denkt R, dass dein Befehl noch nicht zu Ende ist und zeigt Dir dies mit einem + :Eine andere Funktion heißt sum. Mit sum kannst du mehrere Zahlen miteinander addieren:Wenn du dir die Funktion unter der Hilfe mit ?sum anschaust, erkennst du, dass die Funktion unendlich viele Argumente hat. Dies wird mit einem … gekennzeichnet:Wir könnten daher ebenso die Summe von fünf Zahlen zusammen rechnen:Lade als nächstes das Paket tidyverse (library(tidyverse)). Das Paket tidyverse umfasst die Funktion select. Mit Hilfe von select werden wir später Variablen aus einem Datensatz selektieren. Wenn du dir die Dokumentation der Funktion mit Hilfe von ?select anschaust, erkennst du, dass die Funktion mehrere Argumente hat:Das erste Argument heißt .data. Hierfür fügen wir später den Datensatz ein. Das zweite Argument hat keinen expliziten Namen, sondern umfasst eine mit Komma getrennte Liste Variablennamen. Schauen wir uns ein Beispiel . Hierfür laden wir zunächst das Paket tidyverse und den Datensatz human_resources:Anschließend können wir die Funktion select ausführen, um verschiede Variablen aus dem Datensatz zu nehmen (Um zu sehen, welche Variablen im Datensatz stecken, gebe colnames(human_resources) die Konsole ein):Du erkennst das erste Argument .data, welches wir den Datensatz einfügen. Zusätzlich geben wir mehrere Variablennamen ein, indem wir die Variablennamen durch ein Komma trennen. Wir hätten ebenso die Argumente umdrehen können:Generell ist es allerdings ratsam, die Reihenfolge der Argumente beizubehalten. Wenn wir dies tun, können wir die Namen der Argumente ignorieren:Versuchen wir nochmal von diesem Beispiel zu abstrahieren. Funktionen haben einen Namen und eine umgebende Klammer:Fasst alle Funktionen haben Argumente. Die Anzahl der Argumente ist abhängig von der Funktion. Hier siehst du das Schema einer Funktion mit zwei Argumenten:Die Reihenfolge der Argumente ist egal, solange wir die Argumente explizit benennen:Bennenen wir die Argumente nicht, müssen wir die Reihenfolge beachten, die der Funktion (siehe ?function_name) vorgegeben ist:","code":"\nfunction_name(argument1 = value1, argument2 = value2)\nsqrt(9)## [1] 3\nsqrt(x = 9)## [1] 3sqrt(9\n+\nsum(3, 4, 5)## [1] 12\nsum(1, 2, 3, 4, 5)## [1] 15\nlibrary(tidyverse)\nhuman_resources <- read_csv(\"human_resources.csv\")\nselect(.data = human_resources, id, age)## # A tibble: 1,470 x 2\n##       id   age\n##    <dbl> <dbl>\n##  1     1    41\n##  2     2    49\n##  3     3    37\n##  4     4    33\n##  5     5    27\n##  6     6    32\n##  7     7    59\n##  8     8    30\n##  9     9    38\n## 10    10    36\n## # ... with 1,460 more rows\nselect(id, age, .data = human_resources)## # A tibble: 1,470 x 2\n##       id   age\n##    <dbl> <dbl>\n##  1     1    41\n##  2     2    49\n##  3     3    37\n##  4     4    33\n##  5     5    27\n##  6     6    32\n##  7     7    59\n##  8     8    30\n##  9     9    38\n## 10    10    36\n## # ... with 1,460 more rows\nselect(human_resources, id, age)## # A tibble: 1,470 x 2\n##       id   age\n##    <dbl> <dbl>\n##  1     1    41\n##  2     2    49\n##  3     3    37\n##  4     4    33\n##  5     5    27\n##  6     6    32\n##  7     7    59\n##  8     8    30\n##  9     9    38\n## 10    10    36\n## # ... with 1,460 more rows\nfunction_name()\nfunction_name(argument1 = value1, argument2 = value2)\nfunction_name(argument2 = value2, argument1 = value1)\nfunction_name(value1, value2)"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlegende-funktionen-in-r","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.9 Grundlegende Funktionen in R","text":"Es gibt ein paar wenige Befehle, die du immer wieder R benötigst. Wir werden die Befehle anhand des Datensatzes human_resources kennen lernen.Zunächst müssen wir tidyverse laden und den Datensatz importieren:Mit Viewkannst du Dir den Datensatz einem Excel-ähnlichen Format betrachten:Du kannst dir die Variablennamen mit der Funktion colnames ausgeben lassen:Manchmal möchte man wissen, wie viele Reihen einem Datensatz stecken. Hierfür kannst du die Funktion nrowverwenden:Genausogut lassen sich die Anzahl der Variablen (bzw. Spalten) einem Datensatz mit der Funktion ncolausgeben lassen:Zuletzt benötigen wir noch die Funktion head. Mithilfe von head können wir uns die ersten Reihen eines Datensatzes ansehen:","code":"\nlibrary(tidyverse)\nhuman_resources <- read_csv(\"human_resources.csv\")\nView(human_resources)\ncolnames(human_resources)##  [1] \"id\"                         \"age\"                       \n##  [3] \"department\"                 \"distance_from_home\"        \n##  [5] \"education\"                  \"employee_count\"            \n##  [7] \"gender\"                     \"job_role\"                  \n##  [9] \"job_satisfaction\"           \"marital_status\"            \n## [11] \"monthly_income\"             \"num_companies_worked\"      \n## [13] \"performance_rating\"         \"total_working_years\"       \n## [15] \"work_life_balance\"          \"years_at_company\"          \n## [17] \"years_since_last_promotion\"\nnrow(human_resources)## [1] 1470\nncol(human_resources)## [1] 17\nhead(human_resources)## # A tibble: 6 x 17\n##      id   age department      distance_from_ho~ education  employee_count gender\n##   <dbl> <dbl> <chr>                       <dbl> <chr>               <dbl> <chr> \n## 1     1    41 Sales                           1 College                 1 Female\n## 2     2    49 Research & Dev~                 8 Below Col~              1 Male  \n## 3     3    37 Research & Dev~                 2 College                 1 Male  \n## 4     4    33 Research & Dev~                 3 Master                  1 Female\n## 5     5    27 Research & Dev~                 2 Below Col~              1 Male  \n## 6     6    32 Research & Dev~                 2 College                 1 Male  \n## # ... with 10 more variables: job_role <chr>, job_satisfaction <chr>,\n## #   marital_status <chr>, monthly_income <dbl>, num_companies_worked <dbl>,\n## #   performance_rating <chr>, total_working_years <dbl>,\n## #   work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"daten-exportieren","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.5.9.1 Daten exportieren","text":"Wenn wir Daten importieren möchten, wollen wir sie auch exportieren können. Wir werden diesem Kurs mehrmals Daten bereinigen und verändern und möchten diese Daten anschließend wieder einer CSV-Datei speichern. Hierfür benutzen wir die write_csvFunktion. Die Funktion write_csv hat zwei wichtige Argumente:Achte darauf, dass du die Funktion nur verwenden kannst, wenn du das Paket tidyverse geladen hast.x steht für den Datensatz, den wir der Funktion überführen.path steht für den Dateinamen denen wir die Datei speichern. Achte darauf, diesen Pfad immer mit Anführungsstrichen \" zu umrunden.R speichert die Datei immer das aktuelle Arbeitsverzeichnis. Diese kannst du verändern, indem du mit dem Shortcut STRG + Umschalt + H (für Mac COMMAND + Umschalt + H) das Arbeitsverzeichnis wechselt. diesen Ordner wird die Datei anschließend gespeichert.","code":"\nwrite_csv(x, path)\nwrite_csv(NAME_GEREINIGER_DATENSATZ, \"datensatz_gereinigt.csv\")"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlagen-tidyverse","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6 Grundlagen tidyverse","text":"Tidyverse ist eine Sammlung Paketen zur Datenanalyse, welche von Hadley Wickamentwickelt wurde. Hadley Wickam ist Chief Data Scientist bei R-Studio und versucht mit der Entwicklung von tidyverse die Analyse von Daten R zu vereinfachen. Alle Pakete haben eine einheitliche Philosophie und arbeiten reibungslos miteinander. Da tidyverse aktuell die beste Software zur Datenanalyse R ist, verwenden wir dieses Paket.Genauer werden wir diesem Seminar tidyverse verwenden, um Daten zu bereinigen und zu visualisieren. Denn nicht immer liegen Daten der Form vor, die wir für die Analyse der Daten benötigen. Bevor wir statistische Fragestellungen mit Jamovi berechnen, werden wir immer auf tidyverse zurück kommen, um unsere Daten das Format zu bringen, welches wir für unsere Verfahren benötigen. Genauer gehen wir diesem Seminar auf folgende Funktionen und Operatoren ein, die wir immer wieder verwenden:Der Pipe %>% Operatorglimpse: Variablen einem Datensatz betrachtencount: Diskrete Variablen zählenselect: Variablen aus einem Datensatz selektierenarrange: Datensätze nach Variablen sortierenfilter: Reihen aus einem Datensatz filternmutate: Neue Variablen erstellenMehrere Befehle nacheinander ausführenBevor du mit diesem Modul beginnst, stelle sicher, dass du das Paket tidyverse und den Datensatz human_resources.csv geladen hast. Der Datensatz stammt von dieser Seite und umfasst Daten über die Mitarbeitende einer fiktiven Firma. Unter anderem umfasst der Datensatz das Einkommen der Mitarbeitenden, ihre Entfernung zum Arbeitsort, ihre Position im Unternehmen und ihr Bildungsniveau","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"der-pipe-operator","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.1 Der Pipe %>% Operator","text":"Häufig führen wir nur eine Funktion aus, wenn wir einfache Berechnungen R umsetzen möchten. Beispielsweise kann man mit einer Zeile den Mittelwert einer Variable berechnen. passiert allerdings, wenn wir mehrere Funktionen nacheinander ausführen müssen? Ein Beispiel: Stell Dir vor, du möchtest aus einem Vektor mit Zahlen den Mittelwert berechnen, aus dem Mittelwert anschließend die Wurzel ziehen und diesen Wert mit der Zahl 5 addieren. Dies wäre ein möglicher Lösungsweg:Dieser Code sieht nicht nur kompliziert aus, er ist es auch. Beispielsweise ist es schwer zu erkennen, welche Klammer zu welcher Funktion gehört. Alternativ könnten wir den Output der Funktionen (z.B. mean(c(4, 5, 6))) Variablen speichern und die Berechnung sequentiell ausführen:Die Lösung ist bereits eleganter aber immer noch nicht perfekt, da wir Variablen erstellen, die wir später nicht mehr benötigen; wir möchten schließlich nur das Ergebnis wissen. Eine Alternative, dieses Problem zu lösen, ist der Pipe-Operator. Unser Problem der verschachtelten Funktionen können wir mit Hilfe des Pipe-Operators folgendermaßen lösen:ist hier passiert? Die Idee ist folgende: Jede Funktion nimmt Daten auf, verarbeitet diese und gibt diese weiter. Eine Analogie wären Fabriken. Die erste Fabrik fällt Holz und fertigt aus diesem Holz Bretter . Das Holz ist der Input der Fabrik, Bretter der Output. Diese Bretter werden nun die nächste Fabrik geschickt, welche anschließend die Bretter schleift. Die geschliffenen Bretter gehen anschließen die Gitarrenbauerin, die aus ihnen eine Gitarre baut. Das Prinzip ist folgendes: Es gibt eine serielle Verarbeitung der Produkte. Genauso funktioniert der Pipe-Operator. Er übergibt den Output einer Funktion die nächste Funktion. Hier ein weiteres Beispiel:Die Funktion mean(c(9, 10, 8)) berechnet den Mittelwert aus dem Vektor mit den Zahlen 9, 10, 8 (= 9). Diese Zahl 9 wird die Funktion sqrt übergeben. Du siehst, dass der Funktion sqrt(.) ein Punkt notiert ist. Dieser Punkt steht für den Output der vorherigen Funktion (hier mean -> 9). Wir könnten diesen Punkt ebenso weglassen:Ein anderes Beispiel: Wir berechnen die Summe aus zwei Zahlen mit der Funktion sum. Die erste Zahl der Summe übergeben wir allerdings mithilfe des Pipe-Operators:Alternativ können wir den Punkt . entfernen:Diese Befehle sind äquivalent zu folgendem Code:Der Vorteil des Pipe-Operators wird dir vermutlich erst im Verlaufe des Kurses deutlich, wenn wir mehrere Manipulationen Daten vornehmen. dieser Stelle sei gesagt, dass wir den Pipe-Operator immer wieder verwenden werden, da er die Lesbarkeit unseres Codes erhöht. den nächsten Erklärungen wirst du sehen, weshalb der Operator wichtig ist.Der Pipe Operator ist häufig schwierig mit der Tastatur zu schreiben. R-Studio gibt es einen Shortcut um den Pipe-Operator einzufügen: Ctrl + Umschalt + M. Dies ist ein Shortcut, den es sich lohnt zu lernen.","code":"\nsum(sqrt(mean(c(4, 5, 6))), 5)## [1] 7.236068\nmittelwert <- mean(c(4, 5, 6))\nwurzel <- sqrt(mittelwert)\nsum(wurzel, 5)## [1] 7.236068\nmean(c(4, 5, 6)) %>%\n  sqrt(.) %>%\n  sum(., 5)## [1] 7.236068\nmean(c(9, 10, 8)) %>%\n  sqrt(.)## [1] 3\nmean(c(9, 10, 8)) %>% \n  sqrt()## [1] 3\n3 %>% sum(., 3)## [1] 6\n3 %>% sum(3)## [1] 6\nsum(3, 3)## [1] 6"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlegende-tidyverse-befehle","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2 Grundlegende tidyverse-Befehle","text":"Es gibt ein paar Funktionen der Datenanalyse, die wir immer wieder brauchen. Beispielsweise möchten wir häufig neue Variablen berechnen, bestimmte Reihen aus einem Datensatz filtern oder die Häufigkeit des Vorkommens bestimmter Werte zählen. Wir werden den Rest dieses Submoduls verbringen, diese Befehle kennen zu lernen. Im Verlaufe des Seminars wirst du diese Befehle immer wieder verwenden. Es ist daher ratsam, dass du dir diese Befehle gut einprägst.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"glimpse-variablen-in-einem-datensatz-ansehen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2.1 Glimpse: Variablen in einem Datensatz ansehen","text":"Excel sieht man die Daten jederzeit, R nicht. Um einen Datensatz beispielsweise R zu sehen, musst du ihn über die Konsole ausgeben lassen:Das funktioniert, allerdings wirst du nicht immer alle Variablen sehen können. Von den 17 Variablen diesem Datensatz sind 9 nur namentlich erwähnt und du siehst nicht, den Variablen steckt. Eine Möglichkeit alle Variablen anzusehen ist die glimpse-Funktion. Glimpse ordnet die Variablen Reihen und nicht Spalten und erlaubt dir dadurch einen umfassenderen Einblick die Daten:Nun siehst du alle 17 Variablen des Datensatzes. Ebenso siehst du, dass der Datensatz 1470 Reihen enthält. Glimpse solltest du immer dann verwenden, wenn du sehen möchtest, welche Variablen ein Datensatz enthält und diesen Variablen drinsteckt.","code":"\nhuman_resources## # A tibble: 1,470 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     1    41 Sales                          1 College                 1 Female\n##  2     2    49 Research & De~                 8 Below Col~              1 Male  \n##  3     3    37 Research & De~                 2 College                 1 Male  \n##  4     4    33 Research & De~                 3 Master                  1 Female\n##  5     5    27 Research & De~                 2 Below Col~              1 Male  \n##  6     6    32 Research & De~                 2 College                 1 Male  \n##  7     7    59 Research & De~                 3 Bachelor                1 Female\n##  8     8    30 Research & De~                24 Below Col~              1 Male  \n##  9     9    38 Research & De~                23 Bachelor                1 Male  \n## 10    10    36 Research & De~                27 Bachelor                1 Male  \n## # ... with 1,460 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nglimpse(human_resources)## Rows: 1,470\n## Columns: 17\n## $ id                         <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ~\n## $ age                        <dbl> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35,~\n## $ department                 <chr> \"Sales\", \"Research & Development\", \"Researc~\n## $ distance_from_home         <dbl> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26~\n## $ education                  <chr> \"College\", \"Below College\", \"College\", \"Mas~\n## $ employee_count             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n## $ gender                     <chr> \"Female\", \"Male\", \"Male\", \"Female\", \"Male\",~\n## $ job_role                   <chr> \"Sales Executive\", \"Research Scientist\", \"L~\n## $ job_satisfaction           <chr> \"Very High\", \"Medium\", \"High\", \"High\", \"Med~\n## $ marital_status             <chr> \"Single\", \"Married\", \"Single\", \"Married\", \"~\n## $ monthly_income             <dbl> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 2~\n## $ num_companies_worked       <dbl> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5~\n## $ performance_rating         <chr> \"Excellent\", \"Outstanding\", \"Excellent\", \"E~\n## $ total_working_years        <dbl> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5,~\n## $ work_life_balance          <chr> \"Bad\", \"Better\", \"Better\", \"Better\", \"Bette~\n## $ years_at_company           <dbl> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, ~\n## $ years_since_last_promotion <dbl> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0~"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"count-diskrete-variablen-zählen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2.2 count: Diskrete Variablen zählen","text":"Mit Hilfe von countkönnen wir die Häufigkeit diskreter (nominalskalierter) Daten zählen. Beispielsweise können wir unserem Datensatz prüfen, wie viele Männer und wie viele Frauen der Firma arbeiten:Es gibt 588 Frauen und 882 Männer dem Datensatz. Wie du siehst, habe ich den Pipe-Operator verwendet, um diese Häufigkeiten zu berechnen. Worten sage ich folgendes: Nimm den Datensatz und übergib ihn als erstes Argument die Funktion count.Um zu verstehen, weshalb der Pipe-Operator für die Funktion count funktioniert, müssen wir uns nochmal ansehen, wie Funktionen funktionieren. Funktionen haben häufig Argumente, das heißt sie enthalten Informationen, mit denen sie Berechnungen ausführen. Schauen wir uns die Argumente der count-Funktion . Wenn du count() der Konsole tippst, erscheint folgender Hinweis:Die ersten beiden Argumente der Funktion sind x und … x steht für einen Datensatz, die drei Punkte … für Variablen des Datensatzes (wenn du wissen möchtest, woher ich das weiß tippe ?count der Konsole und schaube bei Help unter Arguments).Wir hätten aus diesem Grund ebenso den Datensatz innerhalb der Funktion als Argument übergeben können und zudem die Variablen nennen können, für die wir die einzelnen Ausprägungen (z.B. Mann und Frau) zählen möchten:Wie du siehst, haben wir nun das erste Argument x explizit angegeben. Wir sagen R damit: “Bitte berechne mir die Häufigkeit der Ausprägungen der Variable gender für den Datensatz human_resources.”Da der Pipe-Operator nichts anderes macht als Informationen von einer Funktion oder einem Befehl eine andere Funktion zu übergeben, können wir nun den Datensatz die Funktion count übergeben. der Pipe-Operator übergibt, wird immer mit einem Punkt (.) gekennzeichnet.Da nun x das erste Argument der Funktion count ist, können wir es weglassen und nur den Punkt erwähnen. Ebenso können wir den Punkt weglassen und erhalten dennoch unseren Output.Die Logik dieses Pipe-Operators gilt für alle nachfolgenden Funktionen. Versuche daher selbst einmal mit dem Pipe-Operator und dem count-Befehl zu spielen, um zu verstehen, wie der Pipe-Operator arbeitet.Zuletzt können wir mit dem count-Befehl ebenso weitere, komplexere Fragen beantworten. Beispielsweise können wir uns fragen, welche Ausbildung Männer und Frauen haben. Im Datensatz gibt es eine Variable mit dem Namen education, der der höchste Bildungsabschluss für jeden Mitarbeiter / jede Mitarbeiterin gespeichert ist:Beispielsweise kannst du erkennen, dass 22 Frauen einen Doktorabschluss haben. Bei den Männern sind es 26.Im Grunde könntest du unendlich viele nominalskalierte Variablen die Funktion count eintragen, allerdings würde dies unübersichtlich werden. der Regel reichen eine oder zwei Variablen.","code":"\nhuman_resources %>% count(gender)## # A tibble: 2 x 2\n##   gender     n\n##   <chr>  <int>\n## 1 Female   588\n## 2 Male     882\ncount(x = human_resources, gender)## # A tibble: 2 x 2\n##   gender     n\n##   <chr>  <int>\n## 1 Female   588\n## 2 Male     882\nhuman_resources %>% count(x = ., gender)## # A tibble: 2 x 2\n##   gender     n\n##   <chr>  <int>\n## 1 Female   588\n## 2 Male     882\nhuman_resources %>% count(., gender)## # A tibble: 2 x 2\n##   gender     n\n##   <chr>  <int>\n## 1 Female   588\n## 2 Male     882\nhuman_resources %>% count(gender)## # A tibble: 2 x 2\n##   gender     n\n##   <chr>  <int>\n## 1 Female   588\n## 2 Male     882\nhuman_resources %>% count(gender, education)## # A tibble: 10 x 3\n##    gender education         n\n##    <chr>  <chr>         <int>\n##  1 Female Bachelor        235\n##  2 Female Below College    60\n##  3 Female College         117\n##  4 Female Doctor           22\n##  5 Female Master          154\n##  6 Male   Bachelor        337\n##  7 Male   Below College   110\n##  8 Male   College         165\n##  9 Male   Doctor           26\n## 10 Male   Master          244"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"select-variablen-aus-einem-datensatz-selektieren","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2.3 select: Variablen aus einem Datensatz selektieren","text":"Datensätze haben manchmal viele Variablen. Um den Überblick zu behalten, können wir uns mit selectnur ein paar wenige Variablen ansehen. Zum Beispiel können wir aus unserem Datensatz nur die Variablen id und age selektieren:Der Aufbau der select-Funktion ist identisch mit den Funktionen glimpse und count. Das erste Argument ist der Datensatz, dann werden die Variablen aufgelistet, mit der die Funktion rechnen soll.Beispielsweise könnten wir ebenso drei Variablen aus dem Datensatz selektieren.Im Übrigen. Wenn du dich fragt, woher man weiß, welche Variablen einem Dtensatz sind. Mit der glimpse-Funktion kannst du dir die Variablennamen einem Datensatz immer wieder ansehen.Manchmal wollen wir allerdings genau das Gegenteil. Variablen aus einem Datensatz entfernen. Dies können wir mit select erreichen, indem wir ein Minus vor die Variable setzen, die wir entfernen möchten:Oder, stell dir vor, du möchtest mehrere Variablen aus dem Datensatz entfernen, die beieinander liegen. Nehmen wir beispielsweise , du möchtest die Variablen education bis monthly_income aus dem Datensatz selektieren, welche laut dem glimpse-Befehl hintereinander stehen:Um diese Variablen aus dem Datensatz zu selektieren, musst du die erste und die letzte Variable benennen und mit einem Doppelpunkt trennen.Möchtest du hingegen, dass genau diese Variablen aus dem Datensatz entfernt werden, musst du die Variablen mit einer Klammer umschließen und ein - davor schreiben.","code":"\nhuman_resources %>% select(id, age)## # A tibble: 1,470 x 2\n##       id   age\n##    <dbl> <dbl>\n##  1     1    41\n##  2     2    49\n##  3     3    37\n##  4     4    33\n##  5     5    27\n##  6     6    32\n##  7     7    59\n##  8     8    30\n##  9     9    38\n## 10    10    36\n## # ... with 1,460 more rows\nhuman_resources %>% select(id, age, department)## # A tibble: 1,470 x 3\n##       id   age department            \n##    <dbl> <dbl> <chr>                 \n##  1     1    41 Sales                 \n##  2     2    49 Research & Development\n##  3     3    37 Research & Development\n##  4     4    33 Research & Development\n##  5     5    27 Research & Development\n##  6     6    32 Research & Development\n##  7     7    59 Research & Development\n##  8     8    30 Research & Development\n##  9     9    38 Research & Development\n## 10    10    36 Research & Development\n## # ... with 1,460 more rows\nhuman_resources %>% select(-gender)## # A tibble: 1,470 x 16\n##       id   age department   distance_from_ho~ education employee_count job_role \n##    <dbl> <dbl> <chr>                    <dbl> <chr>              <dbl> <chr>    \n##  1     1    41 Sales                        1 College                1 Sales Ex~\n##  2     2    49 Research & ~                 8 Below Co~              1 Research~\n##  3     3    37 Research & ~                 2 College                1 Laborato~\n##  4     4    33 Research & ~                 3 Master                 1 Research~\n##  5     5    27 Research & ~                 2 Below Co~              1 Laborato~\n##  6     6    32 Research & ~                 2 College                1 Laborato~\n##  7     7    59 Research & ~                 3 Bachelor               1 Laborato~\n##  8     8    30 Research & ~                24 Below Co~              1 Laborato~\n##  9     9    38 Research & ~                23 Bachelor               1 Manufact~\n## 10    10    36 Research & ~                27 Bachelor               1 Healthca~\n## # ... with 1,460 more rows, and 9 more variables: job_satisfaction <chr>,\n## #   marital_status <chr>, monthly_income <dbl>, num_companies_worked <dbl>,\n## #   performance_rating <chr>, total_working_years <dbl>,\n## #   work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nglimpse(human_resources)## Rows: 1,470\n## Columns: 17\n## $ id                         <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ~\n## $ age                        <dbl> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35,~\n## $ department                 <chr> \"Sales\", \"Research & Development\", \"Researc~\n## $ distance_from_home         <dbl> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26~\n## $ education                  <chr> \"College\", \"Below College\", \"College\", \"Mas~\n## $ employee_count             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n## $ gender                     <chr> \"Female\", \"Male\", \"Male\", \"Female\", \"Male\",~\n## $ job_role                   <chr> \"Sales Executive\", \"Research Scientist\", \"L~\n## $ job_satisfaction           <chr> \"Very High\", \"Medium\", \"High\", \"High\", \"Med~\n## $ marital_status             <chr> \"Single\", \"Married\", \"Single\", \"Married\", \"~\n## $ monthly_income             <dbl> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 2~\n## $ num_companies_worked       <dbl> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5~\n## $ performance_rating         <chr> \"Excellent\", \"Outstanding\", \"Excellent\", \"E~\n## $ total_working_years        <dbl> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5,~\n## $ work_life_balance          <chr> \"Bad\", \"Better\", \"Better\", \"Better\", \"Bette~\n## $ years_at_company           <dbl> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, ~\n## $ years_since_last_promotion <dbl> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0~\nhuman_resources %>% select(education:monthly_income)## # A tibble: 1,470 x 7\n##    education  employee_count gender job_role     job_satisfaction marital_status\n##    <chr>               <dbl> <chr>  <chr>        <chr>            <chr>         \n##  1 College                 1 Female Sales Execu~ Very High        Single        \n##  2 Below Col~              1 Male   Research Sc~ Medium           Married       \n##  3 College                 1 Male   Laboratory ~ High             Single        \n##  4 Master                  1 Female Research Sc~ High             Married       \n##  5 Below Col~              1 Male   Laboratory ~ Medium           Married       \n##  6 College                 1 Male   Laboratory ~ Very High        Single        \n##  7 Bachelor                1 Female Laboratory ~ Low              Married       \n##  8 Below Col~              1 Male   Laboratory ~ High             Divorced      \n##  9 Bachelor                1 Male   Manufacturi~ High             Single        \n## 10 Bachelor                1 Male   Healthcare ~ High             Married       \n## # ... with 1,460 more rows, and 1 more variable: monthly_income <dbl>\nhuman_resources %>% select(-(education:monthly_income))## # A tibble: 1,470 x 10\n##       id   age department    distance_from_ho~ num_companies_w~ performance_rat~\n##    <dbl> <dbl> <chr>                     <dbl>            <dbl> <chr>           \n##  1     1    41 Sales                         1                8 Excellent       \n##  2     2    49 Research & D~                 8                1 Outstanding     \n##  3     3    37 Research & D~                 2                6 Excellent       \n##  4     4    33 Research & D~                 3                1 Excellent       \n##  5     5    27 Research & D~                 2                9 Excellent       \n##  6     6    32 Research & D~                 2                0 Excellent       \n##  7     7    59 Research & D~                 3                4 Outstanding     \n##  8     8    30 Research & D~                24                1 Outstanding     \n##  9     9    38 Research & D~                23                0 Outstanding     \n## 10    10    36 Research & D~                27                6 Excellent       \n## # ... with 1,460 more rows, and 4 more variables: total_working_years <dbl>,\n## #   work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"arrange-datensätze-nach-variablen-sortieren","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2.4 arrange: Datensätze nach Variablen sortieren","text":"Stell dir vor, du möchtest wissen, wer die ältesten Mitarbeitende der Firma sind. Excel würdest du hierfür den Datensatz nach dem Alter der Mitarbeitenden sortieren. tidyverse kannst du das gleiche mit der Funktion arrange schaffen:Wie du siehst sind die Mitarbeitenden von jung nach alt sortiert. Dich interessieren allerdings die älteren Mitarbeitende. Hierfür müssen wir arrange zusätzlich sagen, dass die Variable von hoch nach niedrig angezeigt wird.Nun siehst du, dass die ältesten Mitarbeitende 60 Jahre alt sind. Ebenso erkennst du, dass die Mitarbeitende von alt nach jung sortiert sind.Wir können aber genausogut zwei Variablen sortieren. Die Reihenfolge der Variablen, die wir die Funktion arrange eingeben, gibt , welche Variable zuerst sortiert wird. Zum Beispiel können diejenigen Mitarbeitende innerhalb eines Alters (z.B. alle 60 Jahre alt) nach der Distanz sortieren, die sie zur Arbeit fahren müssen:Wie du siehst sind die Mitarbeitende, welche 60 Jahre alt sind, nun danach sortiert, wie weit sie von dem Arbeitsplatz entfernt wohnen. Der Mitarbeiter mit der id 1210 beispielsweise wohnt nur einen Kilometer vom Arbeitsplatz entfernt, die Mitarbeitende mit der id 428 wohnt 28 Kilometer.","code":"\nhuman_resources %>% arrange(age)## # A tibble: 1,470 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1   297    18 Research & De~                 3 Bachelor                1 Male  \n##  2   302    18 Sales                         10 Bachelor                1 Female\n##  3   458    18 Sales                          5 Bachelor                1 Male  \n##  4   728    18 Research & De~                 5 College                 1 Male  \n##  5   829    18 Research & De~                 8 Below Col~              1 Male  \n##  6   973    18 Research & De~                 1 Bachelor                1 Female\n##  7  1154    18 Sales                          3 College                 1 Female\n##  8  1312    18 Research & De~                14 Bachelor                1 Female\n##  9   128    19 Sales                         22 Below Col~              1 Male  \n## 10   150    19 Research & De~                 3 Below Col~              1 Female\n## # ... with 1,460 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% arrange(desc(age))## # A tibble: 1,470 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1   412    60 Research & De~                 7 Bachelor                1 Female\n##  2   428    60 Sales                         28 Bachelor                1 Female\n##  3   537    60 Sales                         16 Master                  1 Male  \n##  4   880    60 Sales                          7 Master                  1 Male  \n##  5  1210    60 Research & De~                 1 Master                  1 Male  \n##  6     7    59 Research & De~                 3 Bachelor                1 Female\n##  7    64    59 Sales                         25 Bachelor                1 Female\n##  8    71    59 Sales                          1 Below Col~              1 Female\n##  9   106    59 Human Resourc~                 2 Master                  1 Female\n## 10   226    59 Research & De~                 3 Bachelor                1 Male  \n## # ... with 1,460 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% arrange(desc(age), distance_from_home)## # A tibble: 1,470 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1  1210    60 Research & De~                 1 Master                  1 Male  \n##  2   412    60 Research & De~                 7 Bachelor                1 Female\n##  3   880    60 Sales                          7 Master                  1 Male  \n##  4   537    60 Sales                         16 Master                  1 Male  \n##  5   428    60 Sales                         28 Bachelor                1 Female\n##  6    71    59 Sales                          1 Below Col~              1 Female\n##  7   759    59 Sales                          1 College                 1 Male  \n##  8   106    59 Human Resourc~                 2 Master                  1 Female\n##  9   744    59 Research & De~                 2 Bachelor                1 Female\n## 10     7    59 Research & De~                 3 Bachelor                1 Female\n## # ... with 1,460 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"filter-reihen-aus-einem-datensatz-filtern","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2.5 filter: Reihen aus einem Datensatz filtern","text":"Eine weitere häufige Funktion ist das Filtern von Daten. Stell dir beispielsweise vor, du möchtest alle Männer aus dem Datensatz entfernen. Das heißt, jede Reihe bzw. Person, für die der Variable gender Male steht, soll aus dem Datensatz entfernt werden. Dies können wir mit filter erreichen:Die Funktion lässt sich besten verstehen, wenn wir die Operatoren ==, !=, >, < und %% im einzelnen durchgehen. Beginnen wir mit dem Operator !=. != steht für “ist nicht.” unserem Beispiel haben wir tidyverse gesagt: “Behalte alle Reihen, der die Variable gender nicht”Male\" ist.Etwas einfacher sehen wir den gleichen Effekt, wenn wir uns fragen, ob zwei Zahlen gleich oder verschieden ist. Du weißt, dass 3 nicht 4 ist (TRUE). Du weißt ebenso, dass die Aussage 3 ist nicht 3 falsch ist (FALSE). Ebenso würdest du zustimmen, wenn ich sage 4 ist gleich 4 (TRUE). Wenn ich aber sage, dass 3 gleich 4 ist würdest du sagen, dass ist falsch (FALSE).Auf Variablen übertragen fragen wir uns bei der Funktion filter immer, ob die Ausprägung einer Variable gleich oder ungleich eines bestimmten Wertes ist. Diejenigen Berechnungen, die TRUE ergeben, werden behalten, diejenigen, die FALSE ergeben, werden aus dem Datensatz entfernt. Wenn ich demnach sage gender != “Male” entferne ich alle Reihen, denen die Ausprägung der Variable gender “Male” ist.Wenn du übrigens nicht weißt, welche Ausprägungen es für eine Variable gibt, kannst du diese mit der count-Funktion finden: z.B. count(human_resources, gender)Mit dem Wissen um TRUE und FALSE können wir komplexere Berechnungen mit filter durchführen. Zum Beispiel möchten wir nur Mitarbeitende dem Datensatz behalten, die älter als 50 Jahre sind.Wie du siehst, hat der Datensatz nur noch 143 Mitarbeitende. Zwar haben wir diesem Beispiel nicht den Operator != oder ==, sondern den Operator > verwendet. Dennoch gibt uns die Aussage age > 50 einen wahren Wert (TRUE) oder einen falschen Wert (FALSE) zurück. Wer beispielsweise 30 Jahre alt ist, wird nicht den Datensatz übernommen (30 > 50 -> FALSE). Eine Mitarbeiterin, die 52 Jahre alt ist, wird den Datensatz übernommen (52 > 50 -> TRUE).Manchmal möchten wir allerdings mehrere Zeilen gleichzeitig aus einem Datensatz entfernen beziehungsweise behalten. Stell dir vor, wir möchten alle Mitarbeitende aus dem Datensatz filtern, die über 50 Jahre sind und die weiblich sind. Hierfür haben wir zwei Möglichkeiten:Einerseits können wir die Aussagen mit einem Komma trennen, andererseits können wir ein & (und) dazwischen setzen. Beide Varianten behalten nur diejenigen Mitarbeiterinnen, die über 50 sind und weiblich sind.Das Gegenteil wären Mitarbeitende, die entweder über 50 Jahre alt sind oder weiblich sind. Hierfür verwenden wir den | (oder) Operator:Du siehst, dass der Datensatz nun 667 Mitarbeitende enthält. Bei unserem vorherigen und-Befehl waren es 64 Mitarbeitende.Stell dir weiterhin vor, du möchtest alle Mitarbeitende aus dem Datensatz filtern, die entweder einen Bachelor- oder Masterabschluss haben. Momentan können wir diese Frage mit dem Oder-Operator (|) beantworten. Es geht allerdings eleganter mit dem %%-Operator:Beide Befehle kommen zu dem gleichen Ergebnis. Die Variante mit dem %%-Operator ist allerdings kürzer und daher zu bevorzugen. Diese Variante eignet sich beispielsweise auch, um Probanden mit einer bestimmten ID aus einem Datensatz zu entfernen.","code":"\nhuman_resources %>% filter(gender != \"Male\")## # A tibble: 588 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     1    41 Sales                          1 College                 1 Female\n##  2     4    33 Research & De~                 3 Master                  1 Female\n##  3     7    59 Research & De~                 3 Bachelor                1 Female\n##  4    12    29 Research & De~                15 College                 1 Female\n##  5    16    29 Research & De~                21 Master                  1 Female\n##  6    19    53 Sales                          2 Master                  1 Female\n##  7    21    24 Research & De~                11 College                 1 Female\n##  8    23    34 Research & De~                 7 Master                  1 Female\n##  9    26    53 Research & De~                 5 Bachelor                1 Female\n## 10    27    32 Research & De~                16 Below Col~              1 Female\n## # ... with 578 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\n3 != 4## [1] TRUE\n3 != 3## [1] FALSE\n4 == 4## [1] TRUE\n3 == 4## [1] FALSE\nhuman_resources %>% filter(age > 50)## # A tibble: 143 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     7    59 Research & De~                 3 Bachelor                1 Female\n##  2    19    53 Sales                          2 Master                  1 Female\n##  3    26    53 Research & De~                 5 Bachelor                1 Female\n##  4    64    59 Sales                         25 Bachelor                1 Female\n##  5    66    55 Research & De~                 8 Bachelor                1 Female\n##  6    71    59 Sales                          1 Below Col~              1 Female\n##  7    83    55 Sales                          1 College                 1 Male  \n##  8    86    56 Research & De~                 7 Bachelor                1 Male  \n##  9    88    51 Research & De~                 9 Master                  1 Male  \n## 10    92    51 Sales                         21 Master                  1 Male  \n## # ... with 133 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% filter(age > 50 & gender == \"Female\")## # A tibble: 64 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     7    59 Research & De~                 3 Bachelor                1 Female\n##  2    19    53 Sales                          2 Master                  1 Female\n##  3    26    53 Research & De~                 5 Bachelor                1 Female\n##  4    64    59 Sales                         25 Bachelor                1 Female\n##  5    66    55 Research & De~                 8 Bachelor                1 Female\n##  6    71    59 Sales                          1 Below Col~              1 Female\n##  7    96    54 Research & De~                 2 Master                  1 Female\n##  8   106    59 Human Resourc~                 2 Master                  1 Female\n##  9   111    51 Research & De~                 1 Master                  1 Female\n## 10   113    54 Human Resourc~                26 Bachelor                1 Female\n## # ... with 54 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% filter(age > 50, gender == \"Female\")## # A tibble: 64 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     7    59 Research & De~                 3 Bachelor                1 Female\n##  2    19    53 Sales                          2 Master                  1 Female\n##  3    26    53 Research & De~                 5 Bachelor                1 Female\n##  4    64    59 Sales                         25 Bachelor                1 Female\n##  5    66    55 Research & De~                 8 Bachelor                1 Female\n##  6    71    59 Sales                          1 Below Col~              1 Female\n##  7    96    54 Research & De~                 2 Master                  1 Female\n##  8   106    59 Human Resourc~                 2 Master                  1 Female\n##  9   111    51 Research & De~                 1 Master                  1 Female\n## 10   113    54 Human Resourc~                26 Bachelor                1 Female\n## # ... with 54 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% filter(age > 50 | gender == \"Female\")## # A tibble: 667 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     1    41 Sales                          1 College                 1 Female\n##  2     4    33 Research & De~                 3 Master                  1 Female\n##  3     7    59 Research & De~                 3 Bachelor                1 Female\n##  4    12    29 Research & De~                15 College                 1 Female\n##  5    16    29 Research & De~                21 Master                  1 Female\n##  6    19    53 Sales                          2 Master                  1 Female\n##  7    21    24 Research & De~                11 College                 1 Female\n##  8    23    34 Research & De~                 7 Master                  1 Female\n##  9    26    53 Research & De~                 5 Bachelor                1 Female\n## 10    27    32 Research & De~                16 Below Col~              1 Female\n## # ... with 657 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% filter(education == \"Bachelor\" | education == \"Master\")## # A tibble: 970 x 17\n##       id   age department       distance_from_h~ education employee_count gender\n##    <dbl> <dbl> <chr>                       <dbl> <chr>              <dbl> <chr> \n##  1     4    33 Research & Deve~                3 Master                 1 Female\n##  2     7    59 Research & Deve~                3 Bachelor               1 Female\n##  3     9    38 Research & Deve~               23 Bachelor               1 Male  \n##  4    10    36 Research & Deve~               27 Bachelor               1 Male  \n##  5    11    35 Research & Deve~               16 Bachelor               1 Male  \n##  6    15    28 Research & Deve~               24 Bachelor               1 Male  \n##  7    16    29 Research & Deve~               21 Master                 1 Female\n##  8    19    53 Sales                           2 Master                 1 Female\n##  9    20    38 Research & Deve~                2 Bachelor               1 Male  \n## 10    22    36 Sales                           9 Master                 1 Male  \n## # ... with 960 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhuman_resources %>% filter(education %in% c(\"Bachelor\", \"Master\"))## # A tibble: 970 x 17\n##       id   age department       distance_from_h~ education employee_count gender\n##    <dbl> <dbl> <chr>                       <dbl> <chr>              <dbl> <chr> \n##  1     4    33 Research & Deve~                3 Master                 1 Female\n##  2     7    59 Research & Deve~                3 Bachelor               1 Female\n##  3     9    38 Research & Deve~               23 Bachelor               1 Male  \n##  4    10    36 Research & Deve~               27 Bachelor               1 Male  \n##  5    11    35 Research & Deve~               16 Bachelor               1 Male  \n##  6    15    28 Research & Deve~               24 Bachelor               1 Male  \n##  7    16    29 Research & Deve~               21 Master                 1 Female\n##  8    19    53 Sales                           2 Master                 1 Female\n##  9    20    38 Research & Deve~                2 Bachelor               1 Male  \n## 10    22    36 Sales                           9 Master                 1 Male  \n## # ... with 960 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"mutate-neue-variablen-berechnen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.2.6 mutate: Neue Variablen berechnen","text":"Manchmal möchten wir neue Variablen aus einem Datensatz berechnen. Stell dir vor, du möchtest das Einkommen der Mitarbeitenden von Dollar Euro umrechnen. Oder, du möchtest aus dem monatlichen Einkommen der Mitarbeiter, das Jahreseinkommen berechnen. Diese Berechnungen kannst du mit dem mutate Befehl umsetzen. Berechnen wir einmal das Jahreseinkommen der Mitarbeitenden:Zunächst musst du den Namen der neuen Variable linksseitig nennen (yearly_income). Anschließend folgt ein =. Hinter dem = schreibst du auf, wie die Variable berechnet wird. diesem Fall haben wir das monatliche Einkommen mal 12 berechnet, da ein Jahr 12 Monate hat.Ein anders Beispiel. Stell dir vor, wir möchten eine Variable erstellen, die anzeigt, ob eine Mitarbeiterin / ein Mitarbeiter mehr oder weniger als das Jahreseinkommen verdient:Drei Dinge lernen wir aus diesem Beispiel.Zunächst siehst du, dass du mehrere neue Variablen gleichzeitig berechnen kannst. diesem Beispiel haben wir sowohl die Variable yearly_income als auch salary_above_average berechnet.Ebenso kannst du erkennen, dass wir eine neue Variable direkt verwenden können, um eine weitere Variable zu berechnen. Beispielsweise haben wir die Variable yearly_income im ersten Schritt erzeugt und im zweiten Schritt zur Berechnung der Variable salary_above_average verwendet.Zuletzt erkennst du, dass wir zur Berechnung der Variable salary_above_average die Funktion mean verwendet haben. Vermutlich ist deine Annahme, dass der Mittelwert nur berechnet werden kann, wenn auch der Datensatz vorher angegeben wird. Zum Beispiel: mean(human_resources$yearly_income). Innerhalb der tidyverse-Funktionen musst du den Datensatz allerdings nie angeben, sondern kannst lediglich die Variablennamen angeben. Aus diesem Grund funktioniert der mean-Befehl dieser Stelle.","code":"\nhuman_resources %>% \n  mutate(\n    yearly_income = monthly_income * 12\n  )## # A tibble: 1,470 x 18\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     1    41 Sales                          1 College                 1 Female\n##  2     2    49 Research & De~                 8 Below Col~              1 Male  \n##  3     3    37 Research & De~                 2 College                 1 Male  \n##  4     4    33 Research & De~                 3 Master                  1 Female\n##  5     5    27 Research & De~                 2 Below Col~              1 Male  \n##  6     6    32 Research & De~                 2 College                 1 Male  \n##  7     7    59 Research & De~                 3 Bachelor                1 Female\n##  8     8    30 Research & De~                24 Below Col~              1 Male  \n##  9     9    38 Research & De~                23 Bachelor                1 Male  \n## 10    10    36 Research & De~                27 Bachelor                1 Male  \n## # ... with 1,460 more rows, and 11 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>, yearly_income <dbl>\nhuman_resources %>% \n  mutate(\n    yearly_income        = monthly_income * 12,\n    salary_above_average = yearly_income > mean(yearly_income)\n  )## # A tibble: 1,470 x 19\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     1    41 Sales                          1 College                 1 Female\n##  2     2    49 Research & De~                 8 Below Col~              1 Male  \n##  3     3    37 Research & De~                 2 College                 1 Male  \n##  4     4    33 Research & De~                 3 Master                  1 Female\n##  5     5    27 Research & De~                 2 Below Col~              1 Male  \n##  6     6    32 Research & De~                 2 College                 1 Male  \n##  7     7    59 Research & De~                 3 Bachelor                1 Female\n##  8     8    30 Research & De~                24 Below Col~              1 Male  \n##  9     9    38 Research & De~                23 Bachelor                1 Male  \n## 10    10    36 Research & De~                27 Bachelor                1 Male  \n## # ... with 1,460 more rows, and 12 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>, yearly_income <dbl>,\n## #   salary_above_average <lgl>"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"mehrere-befehle-nacheinander-ausführen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.3 Mehrere Befehle nacheinander ausführen","text":"Mit diesen Befehlen können wir bereits recht komplexere Operationen Datensätzen ausführen. Nur, bei einem Befehl bleibt es selten, häufig möchten wir mehrere dieser Befehle nacheinander ausführen. Nur wie?Der Trick besteht darin, mehrere dieser Befehle mit dem Pipe-Operator zusammen zu führen. Nehmen wir ein Beispiel: Du möchtest aus dem Datensatz alle Frauen filtern und anschließend prüfen, welchen Bildungsabschluss die Frauen dem Unternehmen haben:Wie du siehst, habe ich zunächst den Datensatz nach den Frauen gefiltert und anschließend gezählt, welcher Bildungsabschluss unter den Frauen wie häufig auftritt. Vlt. möchest du die Häufigkeit zusätzlich sortieren?Wie du siehst, haben wir nun zusätzlich die Funktion arrange verwendet, um die Häufigkeit von hoch nach niedrig zu sortieren. Die meisten Frauen der Firma haben offensichtlich einen Bachelor-Abschluss.Oder, stell dir vor, du möchtest wissen, welche Mitarbeitende besonders weit von der Arbeitsstelle wohnen, um ihnen evtl. die Möglichkeit für zusätzliche Home-Office Tage zu geben. Dabei interessiert dich das Alter der Mitarbeitenden, deren id und deren Distanz zum Arbeitsort:Insgesamt wohnen 25 Mitarbeitende mehr als 25 Kilometer vom Arbeitsort entfernt. Wer wohnt eigentlich weitesten entfernt?Es sind mehrere Personen, mit einer Distanz von 29 Kilometer. Und wie alt ist die älteste Person, die weit zur Arbeit fahren muss?57 Jahre alt. Wie du siehst, können wir mit diesen Befehlen bereits sehr schnell Fragen den Datensatz beantworten. Tidyverse hat noch eine Vielzahl Funktionen, mit denen wir noch viel komplexere Berechnungen ausführen können (siehe tidyverse). Für diesen Kurs beschränken wir uns auf diese zentralen Funktionen und werden diese immer wieder diesem Kurs verwenden.Solange du den Output dieser Funktionen nicht speicherst, geht er verloren. Stell dir vor, du möchtest einen neuen Datensatz speichern, der nur die weiblichen Mitarbeiterinnen enthält. Diese Variante würde zwar die Berechnungen ausführen, allerdings den Datensatz nicht dauerhaft speichern:Mit dieser Variante würdest du den neuen Datensatz mit allen weiblichen Mitarbeiterinnen zwar der Konsole ausgeben. Sobald R-Studio schließt, ist der Datensatz allerdings wieder verloren.Um den Datensatz dauerhaft zu behalten, hast du zwei Möglichkeiten. Zunächst kannst du den neuen Datensatz als Variable speichern:Indem du den Datensatz einer Variable speicherst, kannst du ihn innerhalb einer R-Session (lange du R geöffnet hast) aufrufen. Speicherst du den Code einem Skript, kannst du den Datensatz jedes mal neu berechnen. der Konsole geht der Code verloren, sobald du R schließt.Um den Datensatz dauerhaft zu speichern, kannst du ihn als CSV-Datei exportieren (siehe vorheriges Submodul). Hierfür solltest du allerdings wissen, welchen Order der Datensatz gespeichert wird. Dies kannst du mit getwd() erfahren. Um das Arbeitsverzeichnis zu wechseln, drücke Strg + Umschalt + H auf deiner Tastatur (siehe auch hier).","code":"\nhuman_resources %>% \n  filter(gender == \"Female\") %>% \n  count(education)## # A tibble: 5 x 2\n##   education         n\n##   <chr>         <int>\n## 1 Bachelor        235\n## 2 Below College    60\n## 3 College         117\n## 4 Doctor           22\n## 5 Master          154\nhuman_resources %>% \n  filter(gender == \"Female\") %>% \n  count(education) %>% \n  arrange(desc(n))## # A tibble: 5 x 2\n##   education         n\n##   <chr>         <int>\n## 1 Bachelor        235\n## 2 Master          154\n## 3 College         117\n## 4 Below College    60\n## 5 Doctor           22\nhuman_resources %>% \n  filter(distance_from_home > 25) %>% \n  select(id, age, distance_from_home)## # A tibble: 87 x 3\n##       id   age distance_from_home\n##    <dbl> <dbl>              <dbl>\n##  1    10    36                 27\n##  2    13    31                 26\n##  3    62    38                 29\n##  4   113    54                 26\n##  5   120    43                 26\n##  6   131    43                 28\n##  7   139    25                 28\n##  8   142    45                 29\n##  9   151    40                 26\n## 10   182    34                 27\n## # ... with 77 more rows\nhuman_resources %>% \n  filter(distance_from_home > 25) %>% \n  select(id, age, distance_from_home) %>% \n  arrange(desc(distance_from_home))## # A tibble: 87 x 3\n##       id   age distance_from_home\n##    <dbl> <dbl>              <dbl>\n##  1    62    38                 29\n##  2   142    45                 29\n##  3   200    38                 29\n##  4   205    38                 29\n##  5   260    31                 29\n##  6   272    47                 29\n##  7   353    48                 29\n##  8   410    42                 29\n##  9   425    57                 29\n## 10   426    50                 29\n## # ... with 77 more rows\nhuman_resources %>% \n  filter(distance_from_home > 25) %>% \n  select(id, age, distance_from_home) %>% \n  arrange(desc(distance_from_home), desc(age))## # A tibble: 87 x 3\n##       id   age distance_from_home\n##    <dbl> <dbl>              <dbl>\n##  1   425    57                 29\n##  2  1435    52                 29\n##  3   426    50                 29\n##  4   353    48                 29\n##  5   272    47                 29\n##  6   142    45                 29\n##  7  1038    45                 29\n##  8   876    44                 29\n##  9   410    42                 29\n## 10   605    42                 29\n## # ... with 77 more rows\nhuman_resources %>% \n  filter(gender == \"Female\")## # A tibble: 588 x 17\n##       id   age department     distance_from_ho~ education  employee_count gender\n##    <dbl> <dbl> <chr>                      <dbl> <chr>               <dbl> <chr> \n##  1     1    41 Sales                          1 College                 1 Female\n##  2     4    33 Research & De~                 3 Master                  1 Female\n##  3     7    59 Research & De~                 3 Bachelor                1 Female\n##  4    12    29 Research & De~                15 College                 1 Female\n##  5    16    29 Research & De~                21 Master                  1 Female\n##  6    19    53 Sales                          2 Master                  1 Female\n##  7    21    24 Research & De~                11 College                 1 Female\n##  8    23    34 Research & De~                 7 Master                  1 Female\n##  9    26    53 Research & De~                 5 Bachelor                1 Female\n## 10    27    32 Research & De~                16 Below Col~              1 Female\n## # ... with 578 more rows, and 10 more variables: job_role <chr>,\n## #   job_satisfaction <chr>, marital_status <chr>, monthly_income <dbl>,\n## #   num_companies_worked <dbl>, performance_rating <chr>,\n## #   total_working_years <dbl>, work_life_balance <chr>, years_at_company <dbl>,\n## #   years_since_last_promotion <dbl>\nhr_women <- human_resources %>% \n  filter(gender == \"Female\")\n# getwd(), um zu sehen, in welchen Ordner die Daten gespeichert werden \n# Strg + Umschalt + H um das Arbeitsverzeinis zu wechseln\nhuman_resources %>% \n  filter(gender == \"Female\") %>% \n  write_csv(\"hr_women.csv\")"},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"weitere-informationen-zu-den-tidyverse-befehlen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.6.4 Weitere Informationen zu den tidyverse Befehlen","text":"Wir haben diesem Submodul eine Reihe wichtigen Befehlen kennen gelernt, mit denen wir bereits komplexe Berechnungen R durchführen können. Nimm dir Zeit, diese Befehle kennen zu lernen, wir werden sie den Übungen ohnehin mehrmals wiederholen. Solltest du mehr Interesse tidyverse haben, schau dir folgende Links :David Robinson ScreencastsR Data ScienceModernDive - Statistical Inference via Data Science - Data Wrangling","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"grundlagen-jamovi","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.7 Grundlagen Jamovi","text":"Jamovi ist eine Statistik-Software, die die Vorteile von einem Grafikprogramm und der Flexibilität einer Programmiersprache verbindet. Einerseits ähnelt die Oberfläche von Jamovi der bekannten, aber kostenpflichtigen Statistik-Software SPSS, andererseits ermöglicht Jamovi die Integration der Ergebnisse R und ist damit die perfekte Schnittstelle für diesen Kurs. Wir werden diesem Submodul die Grundlagen von Jamovi kennen lernen, um später mit Jamovi statistische Fragestellungen zu beantworten.Für dieses Submodul nehme ich , dass du Jamovi bereits herunter geladen hast und dir ebenso den Datensatz human_resources.csv herunter geladen hast (siehe Datensatz unten dieser Infobox).","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"datensätze-mit-jamovi-einlesen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.7.1 Datensätze mit Jamovi einlesen","text":"Öffnest du Jamovi, siehst du lediglich ein leeres Fenster:Wir müssen daher zunächst die Daten Jamovi einfügen. Hierfür klickst du auf Open -> Import und wählst den Datensatz von deinem PC aus.Im Anschluss solltest du den Datensatz Jamovi sehen können.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"die-benutzeroberfläche-von-jamovi","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.7.2 Die Benutzeroberfläche von Jamovi","text":"Optisch ähnelt Jamovi Excel oder SPSS und ist daher vermutlich intuitiver zu bedienen als R. Wir werden diesem Semester daher die bekannten statistischen Verfahren mit Jamovi rechnen und R für die Dokumentation deiner Ergebnisse und verschiedener Berechnungen verwenden.Unter Analyse findest du verschiedene Buttons, mit denen du sowohl statistische Verfahren berechnen kannst, als auch deskriptive Daten des Datensatzes berechnen kannst:Diese Bezeichnungen sagen dir vermutlich zu diesem Zeitpunkt nicht viel, das ist auch nicht schlimm, da wir diese Bezeichnungen Stück für Stück diesem Seminar lernen werden. Im Verlaufe des Semesters werden wir uns ausführlich mit t-Tests, ANOVAs und der Regression beschäftigen.Unter Data findest du verschiedene Befehle, mit denen du die Daten manipulieren kannst. Wir werden diese Leiste diesem Seminar kaum benutzen und die Datenmanipulation R machen.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"deskriptive-daten-mit-jamovi-berechnen","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.7.3 Deskriptive Daten mit Jamovi berechnen","text":"Nutzen wir Jamovi, um ein paar Einsichten unseren Datensatz zu gewinnen. Fragen wir uns beispielsweise, wie viel die Mitarbeitende des Unternehmens im Durchschnitt verdienen. Aus dem letzten Semester weißt du, dass man hierzu den Mittelwert einer Variable berechnen muss. Jamovi klickst du hierfür auf Exploration und anschließend auf Descriptives:Nun hast du die Möglichkeit eine Variable auszuwählen und verschiedene Maße der zentralen Tendenz und der Streuung zu berechnen. unserem Fall möchten wir das mittlere Einkommen aller Mitarbeitenden berechnen:Wie du siehst, habe ich unter Central Tendency Mean ausgewählt und erhalte ein monatliches Bruttoeinkommen von 6503 Euro.Wir könnten ebenso untersuchen, wie hoch das mittlere Einkommen für Personen mit verschiedenen Bildungsabschlüssen ist. Also, verdienen Mitarbeitende mit einem Masterabschluss mehr als Mitarbeitende mit einem Bachelorabschluss?Offensichtlich ja. Im Schnitt verdienen Mitarbeidende mit einem Bachelorabschluss 6517 Euro brutto, mit einem Masterabschluss 6832 Euro brutto. Du erkennst im Bild ebenso, dass ich mir die Standardabweichung der Variablen ausgegeben habe.Ebenso kannst du dir die Verteilung der Einkommen pro Bildungsabschluss als Visualisierung ausgeben lassen. Hierzu klickst du auf Plots und anschließend auf Histogram:","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"jamovi-in-r-exportieren","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.7.4 Jamovi in R exportieren","text":"Ein Trick, den wir über den ganzen Kurz verwenden werden, ist es, den Output von Jamovi R zu übertragen. Wir machen das, um unsere Berechnungen dauerhaft einem Skript zu speichern und um somit unsere Ergebnisse zu dokumentieren.Um den den Output R zu übertragen, musst du zunächst auf die drei Punkte rechts oben Jamovi klicken:Anschließend öffnet sich ein Fenster, welchem du den Syntax mode aktivierst:Wie du sehen kannst, erstellt Jamovi den Output deiner Berechnungen Form von R-Code. Diesen R-Code kannst du anschließend kopieren.Im nächsten Schritt musst du mehrere Dinge beachten. Zunächst musst du sicher stellen, dass das Paket jmv geladen ist (library(jmv)). jmv ist die Schnittstelle zu R. Ist das Paket nicht geladen, wird der Code einen Fehler anzeigen. Ebenso solltest du sicher stellen, dass dein Datensatz importiert ist (siehe Zeile 4 im nächsten Bild). Zuletzt musst du im Jamovi-Code immer den Namen des Datensatzes anpassen (siehe Zeile 8 im nächsten Bild). Ansonsten kann es zu Fehlern kommen.Wie du siehst, erhälst du den gleichen Output wie Jamovi. Wann solltest du allerdings den Code von Jamovi R übertragen? Das R-Skript dient der Dokumentation deiner Berechnungen. Alle Berechnungen, die du daher dauerhaft behalten möchtest, sollten einem R-Skript gespeichert werden. Alle Berechnungen, die du nur einmal ausprobierst, müssen nicht das R-Skript.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"zusammenfassung","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.7.5 Zusammenfassung","text":"Die eben beschriebenen Schritte wirst du diesem Semester immer wieder ausführen, bis du sie auswendig kennst. diesem Submodul hast du einen kurzen Überblick über die Möglichkeiten von Jamovi erhalten und du hast gesehen, wie Daten Jamovi importiert werden können. Ebenso hast du gelernt, wie man deskriptive Daten Jamovi berechnet und R überführt.","code":""},{"path":"grundlagen-r-r-studio-und-jamovi.html","id":"quiz","chapter":"3 Grundlagen R, R-Studio und Jamovi","heading":"3.8 Quiz","text":"Dieses Quiz dient dir zur Auffrischung deines Wissens aus Statistik und als Grundlage für diesen Kurs. Das Quiz beinhaltet nicht alle Inhalte aus Statistik , sondern nur diejenigen, welche diesem Seminar vorausgesetzt werden. Versuche das Quiz ohne begleitendes Material auszufüllen und wenn nötig, wiederhole wichtige Konzepte, solltest du sie noch nicht verstanden haben.","code":""},{"path":"statistisches-hypothesentesten.html","id":"statistisches-hypothesentesten","chapter":"4 Statistisches Hypothesentesten","heading":"4 Statistisches Hypothesentesten","text":"","code":""},{"path":"statistisches-hypothesentesten.html","id":"einführung-2","chapter":"4 Statistisches Hypothesentesten","heading":"4.1 Einführung","text":"diesem Modul beginnen wir heraus zu finden, wie wir Fragestellungen der Sozialwissenschaft beantworten bzw. wie wir Hypothesen testen. Wir werden diesem Modul lernen, dass wir nie der Lage sind, Hypothesen zu bestätigen, sondern Hypothesen nur widerlegen können. Bei jedem Test prüfen wir daher, ob eine Hypothese gegeben den Daten, die wir erheben, unwahrscheinlich ist. Ob wir eine Hypothese widerlegen oder nicht, hängt davon ab wie groß diese Wahrscheinlichkeit ist. Ist die Wahrscheinlichkeit sehr gering, widerlegen wir die Hypothese. Ist die Wahrscheinlichkeit nicht sehr unwahrscheinlich, behalten wir die Hypothese vorerst. Um zu diesen statistischen Entscheidungen zu kommen, verwenden wir Stichprobenkennwertverteilungen. Ebenso wirst du diesem Modul lernen, dass wir Fehler diesen Entscheidungen machen. Diese Themen werden wir diesem Modul kennen lernen, indem wir versuchen werden, folgende Fragestellung zu beantworten:Lesen Studenten und Studentinnen mehr als 10 Bücher pro Jahr?Wir werden diese Fragestellung beantworten, indem wir einen t-Test für eine Stichprobe berechnen. Anhand folgende Submodule beantworten wir diese Fragestellung:Falsifikation als Ziel wissenschaftlichen Fortschritts: diesem Submodul lernst du, dass man der Statistik Hypothesen nur widerlegen und nicht prüfen kann.Falsifikation als Ziel wissenschaftlichen Fortschritts: diesem Submodul lernst du, dass man der Statistik Hypothesen nur widerlegen und nicht prüfen kann.Strichprobenkennwertverteilungen: diesem Submodul lernst du, Stichprobenkennwertverteilungen sind.Strichprobenkennwertverteilungen: diesem Submodul lernst du, Stichprobenkennwertverteilungen sind.Prozess des statistischen Hypothesentestens: diesem Submodul lernst du, wie wir Fragestellungen der Sozialforschung statistisch beantworten.Prozess des statistischen Hypothesentestens: diesem Submodul lernst du, wie wir Fragestellungen der Sozialforschung statistisch beantworten.Alpha- und Betafehler und Power: diesem Submodul lernst du, welche Fehler wir statistischen Entscheidungen für oder gegen eine Hypothese machen können.Alpha- und Betafehler und Power: diesem Submodul lernst du, welche Fehler wir statistischen Entscheidungen für oder gegen eine Hypothese machen können.Die Effektstärke Cohen’s d: diesem Submodul lernst du, eine Effektstärke Beispiel der Effektstärke Cohen’s d ist.Die Effektstärke Cohen’s d: diesem Submodul lernst du, eine Effektstärke Beispiel der Effektstärke Cohen’s d ist.Quiz statistisches Hypothesentesten: diesem Quiz wiederholst du die Inhalte dieses Moduls.Quiz statistisches Hypothesentesten: diesem Quiz wiederholst du die Inhalte dieses Moduls.","code":""},{"path":"statistisches-hypothesentesten.html","id":"falsifikation-als-ziel-wissenschaftlichen-fortschritts","chapter":"4 Statistisches Hypothesentesten","heading":"4.2 Falsifikation als Ziel wissenschaftlichen Fortschritts","text":"","code":""},{"path":"statistisches-hypothesentesten.html","id":"wissenschaftliche-fragestellungen","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.1 Wissenschaftliche Fragestellungen","text":"Das wichtigste Ziel für Bildungswissenschaftler*innen ist es, Lernumgebungen zu schaffen, denen Lernende etwas lernen. Nur, woher wissen wir, wie wir zu diesem Ziel kommen? Meinungen über wirksames Lernen gibt es zur Genüge: Manche denken, man müsse eine Lernumgebung dem Lerntyp der Lernenden anpassen. Andere widersprechen dieser Idee und sagen, Lerntypen gibt es nicht (Pasher et al., 2009). Ebenso gibt es die Meinung, dass Motivation der entscheidende Prädiktor für Lernen ist. Oder stimmt es wirklich, dass es wirksam ist, das Lehrbuch nachts unter das Kopfkissen zu legen? Ist es der Tat weniger lernförderlich auf dem Laptop einen Text zu lesen als auf einem ausgedruckten Papier? Dies sind nur ein paar wenige Fragestellungen, mit denen sich Bildungswissenschaftler*innen ihrer täglichen Arbeit beschäftigen. der praktischen Arbeit, müssen wir als Lernende und Lehrende viele dieser Fragen beantworten, der Hoffnung, durch unsere Entscheidungen effektiver zu lernen beziehungsweise zu lehren. Nur, welche Entscheidung ist die korrekte? Diese Frage bringt uns das Herz der Wissenschaft und der Frage, wie wir Dinge der Welt überhaupt wissen können.","code":""},{"path":"statistisches-hypothesentesten.html","id":"logischer-positivismus-und-die-induktion","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.2 Logischer Positivismus und die Induktion","text":"Zunächst gehen wir davon aus, dass wir überhaupt im Stande sind, etwas zu wissen. Nicht jede Fragestellung ist nämlich prüfbar. Sollten Esspflanzen genetisch manipuliert werden? Ist die Todesstrafe moralisch vertretbar? Dies sind moralische Fragestellungen, die sich einer klaren Antwort entziehen. Der logische Positivismus stellt sich gegen solche Fragestellungen. Nach dem logischen Positivismus sind wissenschaftliche Fragestellungen nur sinnvoll, solange sie verifizierbar sind. Wenn ich behaupte, dass die Erde einen Durchmesser von 12742 Kilometer hat, kann ich dir die Schritte beschreiben, die mich zu diesem Schluss führen. Die Behauptung, dass Esspflanzen nicht genetisch manipuliert werden sollten, lässt sich zwar begründen, allerdings nicht verifizieren. Es gibt keine eindeutige Antwort auf diese Frage. Andere Behauptungen wiederum sind prüfbar. Die Behauptung, mein Neffe kommt aus Österreich, kann ich direkt prüfen. Generelle Behauptungen, wie beispielsweise Lernumgebungen sind wirksamer, wenn sie den Lerntypen der Lernenden angepasst werden, lassen sich hingegen nicht durch eine einzige Beobachtung verifizieren. Vielmehr unterliegen sie dem Problem der Induktion. Induktion ist ein Prozess, bei dem aus einer Fülle Einzelbeobachtungen allgemeine Schlüsse gezogen werden. Beispielsweise hast du seit deiner Geburt die Beobachtung gemacht, dass die Sonne morgens aufgeht. Du hast daher eine sehr starke Überzeugung darüber, dass auch morgen die Sonne morgens aufgehen wird.Induktion als Prozess verlangt, dass wir empirische, das heißt, auf Grundlage von Beobachtungen, Aussagen sammeln und durch diese zu Schlussfolgerungen gelangen. Diese empirischen Aussagen helfen uns, der Idee des logischen Positivismus, unsere Behauptungen zu verifizieren. Der logische Positivismus hat also die Hoffnung, zu sicherem Wissen über die Welt zu gelangen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"das-problem-der-induktion","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.3 Das Problem der Induktion","text":"Einer der wichtigsten Kritiker des logischen Positivismus war Karl Popper. Karl Popper lebte zu Beginn des zwanzigsten Jahrhunderts Wien und war von den damaligen politischen und wissenschaftlichen Einflüssen beeinflusst. Unter anderem erlebte er, wie die Newton’schen Gesetze auf dem Hintergrund der allgemeinen Relativitätstheorie von Einstein bröckelten. Popper hatte ein Problem mit der Idee der Induktion und der Hoffnung, durch die Induktion zu sicheren Wissen zu gelangen. Selbst wenn tausende Beobachtungen zu der Feststellung führen, dass morgen die Sonne aufgeht, können wir uns morgen doch nicht sicher sein, dass sie wirklich aufgeht. Tatsächlich wird die Sonne etwa sechs Milliarden Jahren nicht mehr aufgehen. Die scheinbare Sicherheit der Induktion ist demnach keine Sicherheit, da wir nie zu allgemeingültigen Aussagen auf Grundlage der Induktion kommen können.Ein sehr gutes Beispiel für dieses Phänomen lässt sich der Debatte finden, ob die Welt den letzten Jahrzehnten besser geworden ist und dieser Fortschrtt den nächsten Jahrzehnten anhalten wird. Munk Debatte mit Steven Pinker, Matt Ridley, Malcolm Gladwell und Alain de Botton beispielsweise gab es zwei Lager. Steven Pinker und Matt Ridley behaupteten, dass die Welt den letzten Jahrzehnten Fortschritte gemacht hat. Malcom Gladwell und Alain de Botton behaupteten, dass der bisherige Fortschritt kein Garant für die zukünftige Weiterentwicklung der Welt ist. Gladwell beispielsweise behauptete, dass eine gezielte Cyberattacke auf westliche Staaten sehr schnell den Fortschritt der Welt stoppen könnte. Kurzum: Wir können uns unserer bisherigen Erfolge nicht sicher sein und auf Grundlage der hart gewonnenen empirischen Fakten der Vergangenheit keine Garantie für den zukünftigen Fortschritt der Menschheit aussprechen.Popper sah dieses Problem sehr deutlich der Physik. Über mehrere Jahrhunderte konnten unzählige empirische Beobachtungen die Theorie von Newton bestätigen. Die Newton’schen Gravitationsgesetze waren ebendas, ein Gesetz. Bis Einstein zeigte, dass die Gesetze für den atomaren und subatomaren Bereich nicht mehr gelten. Die Quantenphysik zeigt uns bis heute, dass wir noch keine allgemeine Erklärung der Physik haben und die Newton’schen Gesetze eben keine Gesetze sind. Popper war daher klar: Wir können nie Klarheit über die Welt gewinnen, geschweige denn eine wahre Theorie der Welt aufstellen. Die Findung von Wahrheit ist nicht das Ziel der Wissenschaft. Die Theorie bleibt immer nur ein aktuelles Bild unseres Denkens oder unsere beste Schätzung. Induktion ist zum Scheitern verurteilt, wenn sie gesichertes Wissen finden möchte.","code":""},{"path":"statistisches-hypothesentesten.html","id":"die-rolle-der-falsifikation-und-der-kritischen-diskussion","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.4 Die Rolle der Falsifikation und der kritischen Diskussion","text":"Wenn wir also nicht behaupten können, dass eine Theorie wahr ist, bleibt übrig? Stell dir erneut die Theorie der Lerntypen vor. Wir können nach Popper die Theorie nicht bestätigen. wir allerdings können, ist diese Theorie zu falsifizieren. Der Duden definiert falsifizieren als “(eine wissenschaftliche Aussage, eine Behauptung) durch empirische Beobachtung, durch einen logischen Beweis widerlegen.” Wir können also feststellen, dass eine Theorie nicht stimmt.Eine Analogie hilft dieser Stelle: Norman Borlaug war einer der wichtigsten Figuren der Agrarwissenschaft der Weltgeschichte. Durch die Züchtung resistenter Weizen- und Maissorten verhinderte er den Tod von Millionen Menschen. Borlaugs Aufgabe war es, Nutzpflanzen zu erzeugen, die gegenüber verschiedenen Schädlingen resistent waren. Beispielsweise fand Borlaug eine resistente Weizensorte, die sowohl schwere Ähren tragen konnte und zudem nicht durch die Schwere der Ähre abknickte. Diese Weizensorte ist analog zu einer wissenschaftlichen Theorie. Immer wieder konnte Borlaug zeigen, dass diese Weizensorte, einen guten Ertrag erwirtschaftete. anderen Worten, die Weizensorte war der Falsifikation stabil, indem sie immer wieder zeigte, dass sie stabile und ertragreiche Ähren liefert. Andere Weizensorten bestanden den Test der Zeit nicht. Sie knickten ab oder wurden von schädlingen Befallen. Wenn wir die anderen Weizensorten als Theorien verstehen, könnten wir sagen, sie wurden falsifiziert.Da wir zwar nicht verifzieren, aber falsifizieren können, ist die kritische Diskussion ein Herzstück der Wissenschaft bis heute. “Haben Sie nicht X bedacht” oder “könnte man es nicht sehen” sind typische Fragen von Wissenschaftler*innen. Die Fragen drücken genau diese Idee von Popper aus: Finde ich Wege, eine Theorie zu widerlegen. Die Theorie der Lernstile beispielsweise liese sich durch Experimente falsifizieren. Ich könnten Lernende bitten, sich verschiedene Lerntypen einordnen zu lassen. Nehmen wir einmal zur Einfachhheit visuelle und auditive Lerntypen. Eine Gruppe der visuellen Lernenden erhält visuelles Lernmaterial, die andere Gruppe der visuellen Lernenden auditives Lernmaterial. Ich achte zudem sehr genau darauf, dass die Inhalte der Lernmaterialen gleich sind. Das gleiche mache ich für auditive Lernende. Wenn ich nun feststelle, dass visuelle und auditive Lernende sowohl mit ihrer bevorzugten Darbietungsform als auch mit der nicht-bevorzugten Darbietungsform gleich gut lernen, habe ich die Theorie der Lerntypen widerlegt. Zeigen viele Experimente das gleiche Bild, habe ich gute Evidenz dafür, dass die Theorie der Lerntypen nicht haltbar ist (der Tat findet man genau diesen Befund der Forschung, siehe Pashler et al., 2009).Eine solche offene kritische Diskussion ist nicht üblich der Menschheitsgeschichte. David Deutsch behauptet gar, dass lediglich der Renaissanz Florenz, Plato’s Akademie des goldenen Zeitalters Athen als auch unserer Zeit eine solche kritische Diskussion möglich war (siehe auch Beginning Infinity). Wissenschaftliches Arbeiten wie es sich Popper vorstellt, ist daher eine ungewöhnliche und neue Form der Erkenntnisgewinnung. Wir sollten dabei nicht vergessen, dass kritische Diskussion auch eine psychologische Komponente hat. Kritik wird meist persönlich aufgenommen und muss von den Empfängern der Kritik verarbeitet werden. Dabei ist es wichtig zu betonen, dass der wissenschaftlichen Debatte die Ideen und nicht die Personen kritisiert werden.","code":""},{"path":"statistisches-hypothesentesten.html","id":"wissenschaft-als-korrektiv-des-denkens","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.5 Wissenschaft als Korrektiv des Denkens","text":"Poppers Idee der Falsifikation führt dazu, dass die wesentliche Aufgabe der Wissenschaft darin besteht, Theorien mit der Realität abzugleichen. Und Theorien gibt es zu Hauf. Ebenso sind Theorie nie neutral, sondern gefärbt von den Personen, die die Theorien entwerfen. Allein die Theorien des menschlichen Gedächtnisses sind erkennbar der Metapher des Computers angelehnt. Das Dreikomponentenmodell von Atkinson und Shiffrin beispielsweise umfasst mindestens zwei Komponenten, die wir auch modernen Computern finden. Einen zentralen Kurzzeitspeicher, der Informationen hält, die wir aktuell verarbeiten und eine Langzeitspeicherkomponente, die wir hinzufügen können. Ebenso ist die Idee der Informationsverarbeitung die Computermetapher angelegt. Kurzum: welcher Welt wir leben, beeinflusst die Theorien, welche wir aufstellen. Für Popper ist es daher gar nicht entscheidend, wer die Theorien aufstellt und die Theorien besagen, vielmehr sollen empirische Beobachtungen die Gültigkeit dieser Theorien prüfen.Genau weil Theorien subjektiv sind und Menschen gerne recht haben mit ihren Theorien, erlaubt uns die Falsifikation dieser Theorien, unser Denken zu “korrigieren.” Gut umgesetzte Experimente können uns vor Augen halten, dass unsere Theorie nicht korrekt ist. Selbst wenn ich ein glühender Verfechter der Lerntypentheorie bin, muss ich feststellen, dass eine Vielzahl Studien diese Theorie falsifiziert hat. Solange ich den wissenschaftlichen Prozess anerkenne, zwingen mich diese Befunde, meine Annahme über die Lerntheorien zu korrigieren. Ungeachtet dessen, ob ich ein Fan dieser Theorie bin oder nicht. Nur manche Theorien lassen sich nicht falsifizierenSelbst wenn es viele Theorien gibt, werden nicht alle den Test der Zeit bestehen. Durch die Falsifikation von Popper werden mit der Zeit, diejenigen Theorien, die sich als falsch erweisen, verschwinden. Nur diejenigen Theorien, die sich nicht falsizieren lassen, bleiben bestehen. Beispielsweise ist die Cognitive Load Theory bis heute nocht nicht umfassend falsifiziert worden.\nFigure 4.1: Illustation verschiedener Theorien, die Aussagen über die Welt machen. Rote Theorien wurden falsifiziert, grüne Theorien noch kaum falzifiziert.\nEine Theorie, die sich nicht falsifizieren konnte, ist aber nicht korrekt! Wir können eine Theorie nie prüfen, sondern lediglich widerlegen. Dieser Punkt ist wichtig, da wir wir später feststellen werden, dass die Falsifikation und nicht die Verifikation das Kernelement empirischer Studien sind (mehr dazu im Modul zum statistischen Hypothesentesten).","code":""},{"path":"statistisches-hypothesentesten.html","id":"wissenschaftliche-und-nicht-wissenschaftliche-theorien","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.6 Wissenschaftliche und nicht-wissenschaftliche Theorien","text":"Der Unterschied zwischen der Verifikation und der Falsifikation ist sehr deutlich, wenn Menschen im Alltag über Lernen sprechen. Stell dir vor, du sagst einer Freundin, dass massiertes Lernen (oder Bulimielernen) wenig lernförderlich ist. Die Freundin entgegnet dir sofort: “Nein, das kann nicht sein, da ich mich auch Wochen danach den Lernstoff erinnere.” Deine Freundin hat eine rudimentäre Theorie über Lernen, die besagt, dass intensives, kurzes Lernen lernförderlich ist. Sie versucht mit der Aussage ihre Theorie zu verifizieren. Genau das zeichnet wissenschaftliches Denken allerdings nicht aus. Auch aus dem Grund, dass es sehr einfach ist, Dinge zu verifizieren. Wenn ich glaube, dass Gewalttaten der Regel von Tätern begangen werden, die einen geringen Selbstwert haben, werde ich eine Fülle Beispielen finden, die diese Theorie bestätigen (siehe Baumeister, 2000). Der Mobber / die Mobberin aus meiner Schule beispielsweise, der mit sich nicht zufrieden war. Der Terrorist, der sich geringer als die reichen Westler fühlt. Ebenso werde ich Fragen der Psychologie viele Bestätigungen subjektiver Theorien finden können. Selbst Theorien, die unserem Weltverständnis völlig entgegen wirken, finden Formen der Verifikation. Daryl Bem beispielsweise, ein bekannter Psychologe, hat eine Studie veröffentlicht, der er scheinbar zeigen konnte, dass Menschen die Zukunft voraus sagen können. Sogenannte präkognitiven Vorgänge sind nicht mit unserem Verständnis von der Welt vereinbar, dennoch könnte ich diese Studie heranziehen, um dir glaubhaft zu machen, dass es Präkognition gibt.Nein, nach Popper müssen wissenschaftliche Theorien falsifizierbar sein, um das wissenschaftliche Theorien gelten zu können. Genau deswegen sagt Popper ist die Psychoanalyse keine wissenschaftliche Theorie. Die Psychoanalyse kann nicht widerlegt werden. Jeder Traum beispielsweise kann verschiedenen Formen erklärt werden. Wenn nun eine Analystin eine Interpretation für den Traum findet und der Patient die Interpretation als korrekt einstuft, liegt der Analyst richtig. Wenn der Patient allerdings die Interpretation vehement ablehnt, kann die Analysten behaupten, dass genau diese Ablehnung ein psychologischer Prozess ist, die Wahrheit der Interpretation zu verdrängen. Die Analystin hat demnach immer recht (es sollte allerdings angemerkt werden, dass es Beispiele gibt, die zeigen, dass die Psychoanalyse falsifzierbar wäre, siehe Grünbaum, 1984). Und genau solche Theorien sind daher keine wissenschaftlichen Theorien. Sie entziehen sich der Falsifikation.Wissenschaftler*innen sollten sich daher immer fragen: “Unter welchen Bedingungen muss ich zugeben, dass meine Theorie unhaltbar ist?” Nur dann kann Fortschritt der Erkenntnisgewinnung erzielt werden.","code":""},{"path":"statistisches-hypothesentesten.html","id":"der-grad-der-falsifikation","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.7 Der Grad der Falsifikation","text":"Nehmen wir , du überlegst dir sehr gut vor einem Experiment, wie deine Theorie falsifiziert werden könnte. Du glaubst, dass es eine Korrelation zwischen der Anzahl der Bücher gibt, die Menschen lesen und dem Umfang des Vokabulars von Menschen gibt. Korrelationen bewegen sich zwischen -1 und 1. Du kommst zu dem Schluss, dass eine Korrelation von 0 deine Theorie falsifizieren würde. Mit diesem Schluss hast du allerdings keinen strengen Test, um deine Hypothese zu prüfen. Warum? Da deine Theorie fasst alle Beobachtungen mit einschließt. Du behauptest, dass es eine Korrelation gibt, nicht welche Korrelation es gibt. Folgende Ergebnisse wären daher mit deiner Theorie konform:\nFigure 4.2: Annahme einer Korrelation > oder < als 0\nTheorie, dass es eine Korrelation gibtWenn deine Theorie besagt, dass es eine Korrelation zwischen zwei Variablen gibt, sind alle Korrelationen außer 0 mit deiner Theorie konform.Ein einziger Befund würde deine Theorie falsizifieren: Die Nulkorrelation. der Praxis tritt eine Korrelation von 0 allerdings gut wie nie auf, da zwei Variablen immer einer gewissen Weise miteinander korrelieren:Die Nullkorrelation als Falsifikation deiner HypotheseLediglich die rote Korrelation (r = 0) würde deine Hypothese falsifizieren. Dein Test wäre daher schwach, da fast alle Beobachtungen konform zu deiner Theorie sind. Der Grad deiner Falsifikation wäre zu klein.Ein besserer Test wäre es, spezifische Aussagen zu machen. Indem du beispielsweise behauptest, es gibt eine positive Korrelation (bzw. positiver Zusammenhang) zwischen der Anzahl der gelesenen Bücher und dem Umfang des Wortschatzes von Personen gibt, schließt du bereits 50% der Korrelationen aus und erhöhst dadurch die Falsifikation deiner Hypothese:Die gerichtete Hypothese ist falsifizierbarer als die ungerichtete HypotheseIndem du von einer positiven Korrelation ausgehst, erhöhst du den Grad der Falsifikation, da 50% der Werte deine Theorie falsifizieren würden (r < 0).Noch besser wäre es, würden wir noch genauere Aussagen über die Korrelation treffen können. Beispielsweise, die Korrelation ist größer als r > .30. Diese Annahme würde 80% der möglichen Korrelationen ausschließen und die Falsifizierbarkeit deiner Annahme noch weiter erhöhen. Die Falsifikation können wir noch weiter steigern, indem wir Aussagen über die Reichweite unserer Theorie treffen. Gehen wir beispielsweise davon aus, dass unsere Korrelation nur für “hohe Literatur” gilt, kann unsere Theorie spezifischer getestet und damit falsifiziert werden. psychologischen Fachartikeln finden wir immer wieder Hypothesen mit einer geringen Falsifizierbarkeit. Wenn ich beispielsweise teste, ob sich zwei Versuchsgruppen voneinander unterscheiden, erlaube ich, dass sowohl Gruppe als auch Gruppe B höhere Werte haben darf als die andere Gruppe. Wenn ich allerdings sage, dass Gruppe höhere Werte als Gruppe B haben sollte, habe ich meine Falsifizierbarkeit erhöht. Als geübte Leser*wissenschaftlicher Artikel solltest du daher lernen, den Grad der Falsifizierbarkeit einer Hypothese oder einer Theorie einzuschätzen. Ist die Falsifizierbarkeit gering, wird der Artikel weniger gut geeignet sein, eine Theorie zu testen als wenn die Falsifizierbarkeit hoch ist.","code":""},{"path":"statistisches-hypothesentesten.html","id":"das-problem-der-falsifikation","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.8 Das Problem der Falsifikation","text":"Falsifikation fördert die kritische Diskussion, sie ist allerdings selbst Gegenstand von Kritik. Wir hatten gesagt, dass Falsifikation durch empirische Beobachtungen geschieht. Widerlegen die Beobachtungen unsere Theorie, müssen wir unsere Theorie auf Dauer überdenken. Allerdings kann man sich diesem Prozess entziehen, indem man die empirische Beobachtung selbst anzweifelt. Nehmen wir die Intelligenz als Beispiel. Stell dir vor, deine Theorie besagt dass Intelligenz den Wohlstand von Menschen vorhersagt. Je intelligenter Personen sind, desto größeren Wohlstand besitzen sie. Intelligenz testest du mit dem Raven’s Progressive Matrices Test. Nun könnte man dich für die Wahl dieses Tests kritisieren. Es kann ja sein, dass dieser Test nur bestimmte Aspekte der Intelligenz testet bzw. nicht Intelligenz, sondern ein anderes Konstrukt testet. Wäre dem , ist dein Test nicht geeignet, deine Theorie zu falsifizieren. Noch mehr, der Test selbst müsste der Falsifikation stand halten.Das Beispiel zeigt uns sehr deutlich, dass Wissenschaftler*innen einen Konsens finden müssen, unter welchen Bedingungen sie Falsifikation erlaubt. Dieser Konsens ist ausgehandelt und ebenso wenig “wahr” wie die Theorie selbst. Vielmehr ist sowohl die Theorie als auch die Methodik zur Beanwortung statistischer Fragestellungen immer Gegenstand eines kritischen Austausches, der nie zu Ende gehen wird.","code":""},{"path":"statistisches-hypothesentesten.html","id":"inwieweit-sind-theorien-der-lehr--und-lernforschung-falsifizierbar","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.9 Inwieweit sind Theorien der Lehr- und Lernforschung falsifizierbar?","text":"Theorien der Lehr- und Lernforschung sind meist probabilistisch, das heißt, sie machen Aussagen über eine Population Menschen und besagen, dass ein Befund wahrscheinlich eintreten wird und nicht auf jeden Fall eintreten wird. Das Gegenstand zur Probabilistik ist der Determinismus. Deterministische Aussagen treffen immer zu. Wenn ich beispielsweise deterministisch behaupten würde, verteiltes Lernen ist lernwirksamer als massiertes Lernen, würde bereits ein Gegenbefund, meine Hypothese widerlegen. Theorien der Lehr- und Lernforschung sind allerdings nicht deterministisch, sondern probabilistisch. Du kennst diesen Unterschied aus deinem Alltag. Wenn du behauptest, dass Rauchen krebserregend ist, gibt es immer wieder Personen, die einen Onkel kennen, der zwar ein Leben lang geraucht hat, aber nie Krebs bekommen hat. Diese Kritik ist allerdings unangebracht, da die Aussage probabilistisch gemeint war. Also, Rauchen erhöht die Wahrscheinlichkeit Krebs zu bekommen. Wer raucht muss nicht zwangsläufig Krebs bekommen. Wenn nun einzelne empirische Beobachtungen unsere Theorie nicht falsifizieren können, ist die Lehr- und Lernforschung überhaupt eine Wissenschaft? Ja, da nicht einzelne Beobachtungen Theorien der Lehr- und Lernforschung falsifizieren, sondern viele solcher Beobachtungen. Stell dir das Würfeln einer Münze vor. Du gehst davon aus, dass die Münze fair ist, das heißt Kopf und Zahl kommen mit einer Wahrscheinlichkeit von 50% dran. Hättest du diese Annahme widerlegt, wenn deine Münze fünf mal Stück Kopf ist? Oder 100 mal? Nein, da solche Ereignisse zwar ungewöhnlich, aber nicht unmöglich sind. Wenn nun aber Kopf immer wieder häufiger auftritt, wirst du mit der Zeit genügend Evidenz haben, die Annahme der fairen Münze aufzugeben. Genau weil die Falsifikation der Lehr- und Lernforschung nur über einen längeren Zeitraum und viele Untersuchungen gelingt, können Wissenschaftler*innen eine Theorie als auch einen Befund gegen diese Theorie akzeptieren. Selbst wenn eine Studie zeigt, dass beispielsweise eine hohe extrinsische Belastung lernförderlich ist, wird diese Studie dich nicht dazu bringen, die Cognitive Load Theory umzuschmeißen. Erst eine Fülle Untersuchungen, die ebenda zeigen, dass extrinsische Belastungen lernförderlich sind, würden dich der Theorie zweifeln lassen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"zusammenfassung-1","chapter":"4 Statistisches Hypothesentesten","heading":"4.2.10 Zusammenfassung","text":"Wir haben diesem Submodul gesehen, dass die Falsifikation das Herz des wissenschaftlichen Erkenntnisgewinns ist. Zwar können wir auf Grundlage der Induktion keine Theorien bestätigen, wir können sie allerdings falsifizieren. Präzise Hypothesen erhöhen die Falsifikation und sollten gesucht werden. Sind Aussagen nicht präzise ist es teils nicht mehr möglich, eine Theorie zu falsifizieren. Ebenso haben wir gesehen, dass einzelne empirische Beobachtungen probabilistischen Disziplinen wie der Lehr- und Lernforschung nicht genügen, um Theorien zu falsifizieren. Erst die Sammlung einer Vielzahl Evidenz bringt uns dazu, Theorien über Bord zu werfen. Wir werden im nächsten Submodul sehen, dass die Idee der Falsifikation mit den Konzepten des p-Wertes und der Power verknüpft werden kann.","code":""},{"path":"statistisches-hypothesentesten.html","id":"stichprobenkennwertverteilungen","chapter":"4 Statistisches Hypothesentesten","heading":"4.3 Stichprobenkennwertverteilungen","text":"diesem Submodul lernst du, Stichprobenkennwertverteilungen sind. Dieses Submodul ist Grundlage der nächsten Submodule. Der Zweck von Stichprobenkennwertverteilungen wird sich erst nach den nächsten beiden Submodulen für dich erschließen. Wir müssen allerdings das Konzept gemeinsam verstehen, damit du den nächsten Submodulen folgen kannst. Das Submodul ist wie folgt aufgebaut:Skalenniveaus und diskrete/stetige VerteilungenSkalenniveaus und diskrete/stetige VerteilungenWas ist eine Stichprobenkennwertverteilung?ist eine Stichprobenkennwertverteilung?NormalverteilungNormalverteilungStandardnormalverteilungStandardnormalverteilungt-Verteilung(en)t-Verteilung(en)","code":""},{"path":"statistisches-hypothesentesten.html","id":"skalenniveaus-und-diskretestetige-verteilungen","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.1 Skalenniveaus und diskrete/stetige Verteilungen","text":"","code":""},{"path":"statistisches-hypothesentesten.html","id":"skalenniveaus","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.1.1 Skalenniveaus","text":"Stell dir vor, du nimmst einem Experiment teil, bei dem dein Intelligenzquotient ermittelt wird. Du erhältst einen Wert von 105. Ebenso wirst du bei dem Experiment nach deinem Geschlecht, deinem Alter und deinem höchsten Bildungsabschluss befragt. Die Forschenden sammeln die Werte dieser Variablen bei 40 Versuchspersonen und tragen die Werte eine Excel-Tabelle ein:Die Excel-Tabelle enthält vier Variablen. Das Geschlecht, das Alter, den Bildungsabschluss und den IQ der Versuchspersonen. Die Variablen haben eine Reihe Unterschieden. Beispielsweise gibt es zwischen dem Alter zweier Personen unendliche Werte (z.B. zwischen 16 und 40). Zwischen dem Bildungsabschluss zweier Personen wiederum gibt es keine unendlichen Werte (z.B. zwischen Abitur und Werksrealschule). Solche Unterschiede können wir durch Skalenniveaus von Variablen beschreiben:Nominalskalierte Variablen haben keine Werte zwischen Ausprägungen. Beispielsweise kommt man entweder aus Bayern oder aus Hessen. Einen Wert dazwischen gibt es nicht.Ordinalskalierte Variablen haben eine Hierarchie von niedrig zu hoch oder von einfach zu schwer. Das Bildungsniveau ist ein klassisches Beispiel für eine ordinalskalierte Variable. Abitur wird als höher eingeschätzt als eine mittlere Reife.Intervallskallierte Variablen haben Werte zwischen Ausprägungen. Beispielsweise gibt es unendlich viele Werte zwischen einem Intelligenzquotienten von 100 und 110. Intervallskalierte haben allerdings keinen Nullpunkt. Zum Beispiel gibt es keinen Intelligenzquotienten von 0.Verhältnisskalierte Variablen haben ebenso unendlich viele Ausprägungen zwischen Variablen und ebenso einen Nullpunkt. Das Alter ist ein Beispiel für eine verhältnisskalierte Variable.","code":""},{"path":"statistisches-hypothesentesten.html","id":"diskrete-und-stetige-verteilungen","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.1.2 Diskrete und stetige Verteilungen","text":"Diskrete Wahrscheinlichkeiten zeichnen sich dadurch aus, dass sie auf Grundlage von nominalskalierten und ordinalskalierten Daten berechnet werden. Beispielsweise können wir die Wahrscheinlichkeit berechnen, beim Würfeln die Augenzahl 5 zu würfen (1/6). Die Augenzahl ist eine ordinalskalierte Variable. Wir werden allerdings diesem Kurs wenige Hypothesen auf Grundlage diskreter Stichprobenkennwertverteilungen testen. Relevant sind diskrete Stichprobenkennwertverteilungen, wenn du beispielsweise testen möchtest, ob einer Gruppe mehr Frauen als Männer sind.Im Unterschied dazu werden stetige Wahrscheinlichkeiten bei Variablen berechnet, die metrisch (intervallskaliert oder verhälnisskaliert) vorliegen. Beispielsweise können wir die Wahrscheinlichkeit berechnen, größer als 1,80 Meter zu sein. Die Wahrscheinlichkeit einzelner Ereignisse, z.B. die Größe 182,331243433454 cm geht gegen Null, da es unendliche viele Ausprägungen zwischen Variablen gibt. Beispiele für stetige Verteilungen sind die Normalverteilung, die Standardnormalverteilung und die t-Verteilung, welche wir gleich kennen lernen werden.","code":""},{"path":"statistisches-hypothesentesten.html","id":"was-ist-eine-stichprobenkennwertverteilung","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.2 Was ist eine Stichprobenkennwertverteilung?","text":"Der Begriff Stichprobenkennwertverteilung umfasst drei Unterbegriffe: Stichprobe, Kennwert und Verteilung. Gehen wir die drei Begriffe zunächst durch:Stichprobe: Eine Stichprobe ist eine Teilmenge aus einer Grundgesamtheit. Zum Beispiel werden Wahlvorhersagen werden auf Grundlage von Stichproben gezogen, da es mühselig wäre, alle Menschen einer Population (die Grundgesamtheit) zu befragen. Daher erheben wir immer nur einen kleinen Anteil der Population und versuchen auf Grundlage dieser Stichprobe auf die Population zu schließen.Stichprobe: Eine Stichprobe ist eine Teilmenge aus einer Grundgesamtheit. Zum Beispiel werden Wahlvorhersagen werden auf Grundlage von Stichproben gezogen, da es mühselig wäre, alle Menschen einer Population (die Grundgesamtheit) zu befragen. Daher erheben wir immer nur einen kleinen Anteil der Population und versuchen auf Grundlage dieser Stichprobe auf die Population zu schließen.Kennwert: Statistische Kennwerte fassen Datenpunkte zusammen. Du kennst bereits mehrere dieser Kennwerte: Der Mittelwert, die Standardabweichung, die Varianz oder der z-Wert. Der Mittelwert gibt den typischen Wert einer Verteilung , die Varianz gibt , wie weit Werte um einen Mittelwert streuen.Kennwert: Statistische Kennwerte fassen Datenpunkte zusammen. Du kennst bereits mehrere dieser Kennwerte: Der Mittelwert, die Standardabweichung, die Varianz oder der z-Wert. Der Mittelwert gibt den typischen Wert einer Verteilung , die Varianz gibt , wie weit Werte um einen Mittelwert streuen.Verteilung: Eine Verteilung ist eine grafische Darstellung des Auftretens einzelner Ausprägung einer Variable. Beispielsweise kennst du unimodale Verteilungen mit nur einem Gipfel, bimodale Verteilungen mit zwei Gipfeln und stetige Verteilungen.Verteilung: Eine Verteilung ist eine grafische Darstellung des Auftretens einzelner Ausprägung einer Variable. Beispielsweise kennst du unimodale Verteilungen mit nur einem Gipfel, bimodale Verteilungen mit zwei Gipfeln und stetige Verteilungen.Eine Stichprobenkennwertverteilung ist eine grafische Verteilung von Kennwerten, die aus mehreren Stichproben gewonnen werden.Aus dieser Definition können wir ein paar Beispiele für Stichprobenkennwertverteilungen finden: Die Verteilung von Mittelwerten, die aus mehreren Stichproben berechnet werden.Die Verteilung von Mittelwerten, die aus mehreren Stichproben berechnet werden.Die Verteilung von Mittelwertsdifferenzen, die aus mehreren Stichproben berechnet werden.Die Verteilung von Mittelwertsdifferenzen, die aus mehreren Stichproben berechnet werden.Die Verteilung von Varianzen, die aus mehreren Stichproben berechnet werden.Die Verteilung von Varianzen, die aus mehreren Stichproben berechnet werden.","code":""},{"path":"statistisches-hypothesentesten.html","id":"simulation-einer-stichprobenkennwertverteilung-des-mittelwerts","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.2.1 Simulation einer Stichprobenkennwertverteilung des Mittelwerts","text":"Um Stichprobenkennwertverteilungen besser zu verstehen, hilft es diese zu simulieren. Stell dir vor, du ziehst eine Stichprobe von 20 Personen aus der Grundgesamtheit aller Menschen Deutschland. Jede Person lässt du einen Intelligenztest durchführen. Aus den Intelligenzquotienten der zwanzig Personen erstellst du ein Histogram:\nFigure 4.3: Verteilung des Intelligenzquotienten der 20 Personen. Mittelwert blau gekennzeichnet\nDer Mittelwert deiner Stichproben, sprich dein Kennwert, beträgt \\(94.62\\). Stell dir als nächstes vor, du wiederholst dieses Vorgehen und ermittelst erneut den Mittelwert aus einer neuen Stichprobe. Stell dir vor, du hast Superkräfte und bist der Lage insgesamt 10.000 Mittelwerte als Kennwerte zu ermitteln. würden sich deine Mittelwerte über die Zeit verteilen:Drei Dinge fallen uns auf:Erstens, je mehr Kennwerte ich sammle, desto unimodaler wird die Verteilung. Bei einer Kennwertgröße von 10000 Stichproben (Kennwerten) erhalte ich eine fast perfekt unimodale Verteilung. Dieses Phänomen wird als zentrales Grenzwerttheorem bezeichnet.Zweitens, die Kennwerte streuen. Selbst wenn der wahre Mittelwert der Population bei 100 liegt, erhalten wir deskriptive Unterschiede des Kennwerts den Stichproben. Beispielsweise einen Mittelwert von 95.Drittens sehen wir, dass manche Mittelwerte wahrscheinlicher sind als andere. Ein Mittelwerte von etwa 100 ist sehr wahrscheinlich, ein Mittelwerte von etwa 90 ist sehr unwahrscheinlich.\nEine solche Verteilung bezeichnen wir als Stichprobenkennwertverteilung. Stichprobenkennwertverteilungen visualisieren die Verteilung von Kennwerten aus Stichproben. unserem Fall visualisieren wir die Verteilung von Mittelwerten aus einer Population aus 10.000 Stichproben mit 20 Personen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"visualisierung-der-stichprobenkennwertverteilung-des-mittelwerts-bei-10000-kennwerten-und-variierenden-stichprobengrößen","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.2.2 Visualisierung der Stichprobenkennwertverteilung des Mittelwerts bei 10000 Kennwerten und variierenden Stichprobengrößen","text":"Versuchen wir etwas anderes als nächstes. Stell dir vor, du bestimmst erneut 10.000 Mittelwerte aus der Population. Nur diesmal variierst du, wie viele Versuchspersonen pro Experiment getestet werden. Genauer testest du jeweils 20, 50, 100 und 500 Personen pro Erhebung. Im Folgenden siehst du, wie sich die Kennwerte diesen vier Versuchsreihen verteilen würden:Offensichtlich wird die Verteilung steiler, wenn du mehr Versuchspersonen pro Erhebung verwendest. Warum? Erstens bist du mit einer größeren Stichprobe eher der Lage, den exakten Mittelwert der Population zu ermitteln. Stell dir ein Extrem vor: Du erhebst aus den 82 Millionen Menschen Deutschland 81 Millionen Menschen. Der Mittelwert der Intelligenz dieser riesigen Stichprobe wird ziemlich sicher ähnlich zu dem Mittelwert der Population sein. Wenn du allerdings nur 100 Personen testest, wirst du vermutlich einen Mittelwert finden, der stärker von dem Populationsmittelwert abweicht. Die zweite Antwort erklärt sich durch das Konzept des Standardfehlers:","code":""},{"path":"statistisches-hypothesentesten.html","id":"der-standardfehler","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.2.3 Der Standardfehler","text":"Der Standardfehler ist definiert als die Standardabweichung einer Stichprobenkennwertverteilung. Die Standardabweichung kennst du bereits:\\[\nsd = \\sqrt{\\frac{\\sum_{=1}^{n} (x_i - \\bar{x})^2}{n - 1}}\n\\]Formel des StandardabweichungDer Standardabweichung ist ein Maß der Streuung. Er ist ein standardisierter Wert, der angibt, wie stark Werte einer Verteilung voneinander streuen. Je größer die Standardabweichung, desto größer ist die Streuung einer Variable. Die Standardabweichung wird sowohl mit s als auch mit sd gekennzeichnet.Du kennst die Standardabweichung vermutlich mit einem n im Nenner. Dies ist korrekt, sofern man die Standardabweichung einer Stichprobe angeben möchte. man hingegen die Standardaweichung der Variable der Population messen, verwendet man n - 1. Dies wird auch als Bessel’s correction bezeichnet.Der Standardfehler ist eine besondere Form der Standardabweichung. Er gibt , wie stark die Kennwerte einer Stichprobenkennwertverteilung streuen. Nehmen wir unser Intelligenzbeispiel erneut zur Hand:Das Bild stellt die Stichprobenkennwertverteilung der Mittelwerte der Intelligenzquotienten bei einer Stichprobengröße von 100 und 10.000 Erhebungen dar. Du siehst, dass es eine Verteilung ist, sprich, es herrscht eine Streuung den Werten. Diese Streuung beschreiben wir durch den Standardfehler.Es gibt zwei Formeln, um den Standardfehler für eine Stichprobenkennwertverteilung zu beschreiben. Eine, die exakt ist und nur zu berechnen ist, wenn man die Standardabweichung der Population kennt und eine, die auf Grundlage der Standardabweichung der Stichprobe geschätzt wird. Beginnen wir mit der exakten Formel:\\[\nse = \\frac{\\sigma}{\\sqrt{n}}\n\\]Exakter StandardfehlerIm Zähler steht die Standardabweichung der Variable der Population. Diesen Werten nennt man Sigma. Im Nenner steht die Wurzel aus der Stichprobengröße. Mit dieser Formel verstehst du nun, warum unserer vorherigen Simulation der Standardfehler mit steigender Stichprobengröße immer kleiner wurde. Nehmen wir , Sigma ist 2 und deine Stichprobengröße sind 10 Personen. Dann wäre der Standardfehler: 2 / Wurzel aus 10 = 0.63. Erhebst du hingegen 50 Personen, wäre der Standardfehler: 2 / Wurzel aus 50 = 0.28. Du siehst daran, dass der Standardfehler eine Funktion der Stichprobengröße ist. Mit steigender Stichprobe sinkt der Standardfehler, sprich die Strichprobenkennwertverteilung des Mittelwertes wird schmaler.\\[\nse = \\frac{s}{\\sqrt{n}}\n\\]Geschätzer StandardfehlerWir kennen allerdings fast nie die Standardabweichung einer Variable der Population. Da wir fast nie die gesamte Population erheben können und somit auch nicht die Standardabweichung der Population kennen, ziehen wir die Standardabweichung der Stichprobe zur Hilfe, indem wir den Standardfehler auf Grundlage der Standardabweichung der Stichprobe (s) schätzen. Dieser Wert wird nicht exakt gleich sein mit dem echten Wert, allerdings eine gute Annährung.","code":"## Warning: Removed 2 rows containing missing values (geom_bar)."},{"path":"statistisches-hypothesentesten.html","id":"unterschied-populationsverteilung-und-stichprobenkennwertverteilung","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.2.4 Unterschied Populationsverteilung und Stichprobenkennwertverteilung","text":"Vergleicht man die Verteilung des Intelligenzquotienten der Population mit einer der vorherigen Stichprobenverteilungen dieser Variablen, fällt einem ein Unterschied auf:Wir haben nun etabliert eine Stichprobenkennwertverteilung ist. Im nächsten Schritt lernen wir ein paar bekannte Stichprobenverteilungen kennen: Die Normalverteilung und die Standardnormalverteilung.","code":""},{"path":"statistisches-hypothesentesten.html","id":"normalverteilung","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.3 Normalverteilung","text":"Die wohl bekanntesten Verteilungen sind die Normalverteilung und die Standardnormalverteilung/z-Verteilung. Beide Verteilungen sind unimodal, das heißt sie haben nur einen Gipfel und beide Verteilung haben die Eigenschaft, dass ihre Fläche genau 1 ist. Dieser Eigenschaft machen wir uns später zunutze, um Wahrscheinlichkeiten zu berechnen.Obwohl wir später weder eine Normalverteilung noch eine Standardnormalverteilung zur Prüfung von Hypothesen verwenden, ist es sinnvoll, diese zunächst zu behandeln. Erstens, da wir auf Grundlage dieser Verteilungen bereits die Idee der Wahrscheinlichkeitsrechnung vorweg nehmen können, die wir später benötigen, um unsere Hypothesen zu testen. Zudem stehen diese Verteilungen Beziehungen zueinander. Beispielsweise werden wir feststellen, dass die t-Verteilung eine besondere Form der Standardnormalverteilung ist.Normalverteilungen treten häufig der Natur auf. Beispielsweise entspricht die Intelligenz von Personen der Regel einer Normalverteilung. Ebenso entspricht die Größe von Personen oder der Blutdruck von Personen einer Normalverteilung. Normalverteilungen sehen ungefähr aus. Achte darauf, dass wir von mehreren Verteilungen sprechen.\nFigure 4.4: Beispiele für Normalverteilungen\nNormalverteilungen zeichnen sich durch folgende Eigenschaften aus:Sie sind unimodal, dass heißt, sie haben nur einen Gipfel.Zudem sind Normalverteilungen immer symmetrisch um das Zentrum der Verteilung. Da die Normalverteilung symmetrisch ist, ist der Mittelwert, der Median und der Modus immer gleich.Eine weitere interessante Eigenschaft der Normalverteilung ist, dass die die Fläche der Verteilung links und rechts um den Mittelwert bei einer Standardabweichung genau 68% beträgt. Bei zwei Standardabweichungen um den Mittelwert beträgt die Fläche ~ 95% und bei drei Standardabweichungen um den Mittelwert ~ 97.5%:","code":""},{"path":"statistisches-hypothesentesten.html","id":"standardnormalverteilung","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.4 Standardnormalverteilung","text":"Die Standardnormalverteilung ist eine besondere Normalverteilung, für die Folgendes gilt: Der Mittelwert der Standardnormalverteilung ist immer 0 und die Standardabweichung der Standardnormalverteilung ist immer 1. Die Standardnormalverteilung wird auch z-Verteilung genannt, Kennwerte der Standardnormalverteilung werden als z-Werte dargestellt.\nFigure 4.5: Darstellung der Standardnormalverteilung\n","code":""},{"path":"statistisches-hypothesentesten.html","id":"wahrscheinlichkeitsberechungen-auf-grundlage-der-standardnormalverteilung","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.4.1 Wahrscheinlichkeitsberechungen auf Grundlage der Standardnormalverteilung","text":"Du fragst dich dieser Stelle vielleicht wir mit diesen Verteilungen anfangen sollen? Um eine Antwort auf diese Frage zu bekommen, stell dir folgendes Szenario vor: Du möchtest wissen, ob du und deine vier Freunde intelligenter im Vergleich zur Gesamtbevölkerung seid? Du weißt, dass der Mittelwert der Population 100 ist, da dieser immer fest definiert wird. Die Standardabweichung der Intelligenzverteilung der Population beträgt 15. Nun stellt ihr fest, dass ihr im Schnitt einen Intelligenzquotienten von 110 habt, also höher als der Durchschnitt. Die Frage ist, wie viel intelligenter seid ihr als die Gesamtbevölkerung? Hierzu können wir euren Mittelwert der Intelligenz zunächst einen z-Wert umrechnen:\\[\nz = \\frac{\\bar{x} - \\mu}{se} = \\frac{110 - 100}{15 / \\sqrt{5}} = 1.49\n\\]Mit dieser Berechnung versuchen wir den Mittelwert deiner Stichprobe zu standardisieren. Achte darauf, dass wir nicht den z-Wert einer Person anhand der der Populationsvariable berechnen, sondern deiner Stichprobe. Daher teilen wir durch den Standardfehler und nicht durch die Standardabweichung. Unser z-Wert ergibt 1.49. Das heißt, die Intelligenz euer Gruppe ist 1.49 Standardabweichungen größer als im Durchschnitt.Diesen z-Wert können wir nun der Standardnormalverteilung abtragen, um heraus zu finden, wie wahrscheinlich es ist bei der Größe eurer Stichprobe einen hohen Intelligenzquotienten zu erhalten. Es stellt sich heraus, dass ein solcher Intelligenzmittelwert oder größer bei einer Stichprobe von 5 Personen nur 6.81% der Fälle auftritt. Sprich, euer Mittelwert ist relativ unwahrscheinlich, wenn man annimmt, dass der Mittelwert der Stichprobenkennwertverteilung der Intelligenz 100 beträgt.Wir könnten uns ebenso fragen, wie wahrscheinlich es ist, einen Mittelwert kleiner als 110 bei einer Stichprobengröße von 5 Personen zu erhalten? Hierfür müssten wir die Fläche links des z-Wertes abtragen:Wie du siehst, ist diese Wahrscheinlichkeit das Komplement der anderen Wahrscheinlichkeit. Die Wahrscheinlichkeit für einen z-Wert kleiner als 1.49 liegt bei 93.19%. Rechnen wir beide Wahrscheinlichkeiten zusammen, erhalten wir 100%: 93.19 + 6.81 = 100%.","code":""},{"path":"statistisches-hypothesentesten.html","id":"zentrale-eigenschaften-der-wahrscheinlichkeitsrechung","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.5 Zentrale Eigenschaften der Wahrscheinlichkeitsrechung","text":"Versuchen wir dieser Stelle einen allgemeineren Blick auf die Berechnungen von Wahrscheinlichkeiten durch Stichprobenkennwertverteilungen zu werfen.Die Wahrscheinlichkeit für ein einziges Ereignis einer stetigen Stichprobenkennwertverteilung liegt bei 0%. Ein z-Wert von exakt 1.49 beispielsweise tritt nie auf, da es unendlich viele Nachkommastellen gibt.Die Wahrscheinlichkeit für irgendein Ereignis beträgt 100%. Wir haben eben gesehen, dass beide Wahrscheinlichkeiten 100% ergeben. Damit haben wir gezeigt, dass die Fläche unter einer Stichprobenkennwertverteilung immer 100% oder 1 beträgt.Wir berechnen die Fläche unter einer Stichprobenkennwertverteilung durch ein Integral.Diese drei Regel gelten für alle Stichprobenkennwertverteilungen. Sie erlauben uns später Aussagen über die Wahrscheinlichkeiten von Ereignissen zu geben. Üben wir diesen Idee als nächstes ein zwei Beispielen:Wie wahrscheinlich ist es einen z-Wert kleiner als 0 zu erhalten? (10%/50%/100%)\nFigure 4.6: Lösung: 50%\nWie wahrscheinlich ist es einen z-Wert zwischen -1 und 2 zu erhalten? (22%/82%/42%/12%)\nFigure 4.7: Lösung: 82%\n","code":""},{"path":"statistisches-hypothesentesten.html","id":"t-verteilungen","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.6 t-Verteilung(en)","text":"Eine besondere Gruppe Stichprobenkennwertverteilung, die mit der Standardnormalverteilung verwandt sind, nennt man t-Verteilungen. Wir verwenden eine t-Verteilung anstatt einer Standardnormalverteilung zur Überprüfung von Hypothesen, wenn wir die Standardabweichung der Population nicht kennen. Dies ist meistens der Fall, daher werden der Sozialforschung selten die Populationsparameter kennen (z.B. Mittelwert und Standardabweichung). Während es nur eine Standardnormalverteilung gibt, gibt es mehrere t-Verteilungen. Die t-Verteilungen ergeben sich aus der Größe der Stichprobe. Im Folgenden siehst du verschiedene t-Verteilungen, welche sich offensichtlich ihrer Breite und Höhe unterscheiden:\nFigure 4.8: Lösung: 82%\n","code":""},{"path":"statistisches-hypothesentesten.html","id":"simulation-einer-t-verteilung-auf-grundlage-einer-stichprobe","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.6.1 Simulation einer t-Verteilung auf Grundlage einer Stichprobe","text":"Eine logische und berechtigte Frage ist, wie kommt man zu einer solchen t-Verteilung? Stell dir erneut vor, du möchtest überprüfen, wie wahrscheinlich es ist, einer Gruppe von 5 Personen einen Intelligenzquotienten von 110 zu erhalten? Diesmal kennst du allerdings nicht die Standardabweichung der Intelligenz der Population. Um den Mittelwert des Intelligenzquotienten eurer Gruppe zu standardisieren, musst du daher den Standardfehler auf Grundlage der Stichprobenstandardabweichung schätzen:\\[\nt_{df} = \\frac{\\bar{x} - \\mu}{se} = \\frac{\\bar{x} - \\mu}{s / \\sqrt{n}}\n\\]Der einzige Unterschied der Berechnung des z-Wertes und des t-Wertes ist, dass du anstatt der Standardabweichung der Population die Standardabweichung der Stichprobe verwendest. Alle anderen Werte sind äquivalent zum z-Wert.Stell dir als nächstes folgende Simulation vor: Du ziehst 10 mal, 100 mal, 1000 mal und 10.000 mal eine Stichprobe mit 10 Personen aus der Population, berechnest ihren durchschnittlichen Intelligenzquotienten und rechnest diesen Mittelwert einen t-Wert um. Deine t-Werte würden sich wie folgt verteilen:Du siehst der Simulation, dass sich die t-Werte auf deiner Simulation mit steigener Stichprobengröße einer t-Verteilung annähern. anderen Worten, t-Verteilungen stellen nichts anderes dar als die t-standardisierte Verteilung von Mittelwerten aus einer Population. Um zu verstehen, weshalb wir bei einer Stichprobe von 10 Personen gerade diese t-Verteilung verwenden, vergleichen wir die simulierte t-Verteilung bei 10.000 Stichproben mit einer t-Verteilung, welche aus einer Stichprobe mit 30 Personen:\nFigure 4.9: Vergleich der t-Verteilung mit einer Stichprobe von 10 (schwarz) und 30 Personen (blau)\nWie du siehst, sind beide t-Verteilungen relativ ähnlich. Allerdings ist die t-Verteilung bei einer Stichprobe von 10 Personen (blau) etwas breiter als die t-Verteilung bei einer Stichprobe von 30 Personen (schwarz). Die passendere Verteilung ist offensichtlich die t-Verteilung mit 10 Personen, wenn auch nur minimal. Um daher die Wahrscheinlichkeit von Mittelwerten auf Grundlage einer t-Verteilung korrekt zu bestimmen, ist es notwendig, dass man die richtige t-Verteilung Abhängigkeit der Stichprobengröße bestimmt.","code":"## Warning: Removed 2 rows containing missing values (geom_bar).\n\n## Warning: Removed 2 rows containing missing values (geom_bar).## Warning: Removed 2 rows containing non-finite values (stat_bin).## Warning: Removed 2 rows containing missing values (geom_bar).## Warning: Removed 10 rows containing non-finite values (stat_bin).## Warning: Removed 2 rows containing missing values (geom_bar)."},{"path":"statistisches-hypothesentesten.html","id":"simulation-einer-t-verteilung-auf-grundlage-von-zwei-stichproben","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.6.2 Simulation einer t-Verteilung auf Grundlage von zwei Stichproben","text":"Wir haben gerade gesehen, dass wir t-Verteilungen und Standardnormalverteilungen verwenden können, um die Wahrscheinlichkeit einzelner Mittelwerte anhand eines Populationsmittelwertes zu testen. Zum Beispiel, indem wir fragen, wie wahrscheinlich es ist, einen Intelligenzquotienten größer als 110 einer Stichprobe zu erhalten.t-Verteilungen können wir allerdings auch verwenden, um heraus zu finden, wie wahrscheinlich der Abstand zweier Stichprobenmittelwerte ist. Zum Beispiel könnten wir uns fragen, wie wahrscheinlich es ist, dass sich der Intelligenzquotient zweier Stichproben um 20 Punkte unterscheidet. Um diese Frage zu beantworten, können wir erneut t-Verteilungen verwenden. Wir müssen allerdings die t-Werte anders berechnen.Stell dir dazu vor, du ziehst zwei Stichproben aus der Population und berechnest den Intelligenzquotienten dieser beider Gruppen. Der t-Wert bei zwei Stichproben ist nichts anderes als der standardisierte Mittelwertsunterschied dieser Stichproben. Standardisiert anhand des Standardfehlers.\\[\nt_{df} = \\frac{\\bar{x}_1 - \\bar{x}_2}{se} = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s^2_1}{N_1} + \\frac{s^2_2}{N_2}}}\n\\]Erneut ziehen wir 10 mal, 100 mal, 1000 mal und 10.000 zwei Stichproben mit je 10 Personen aus der Population. Danach berechnen wir den t-Wert dieser Stichprobenpaaren und visualisieren diese t-Werte als Histogramme:Erneut erkennst du anhand der Simulation, dass sich die t-Werte bei zwei Stichproben einer t-Verteilung annähern. Diese Verteilung zeigt uns, wie wahrscheinlich zwei Mittelwerte voneinander entfernt liegen, sofern sie aus der gleichen Population stammen. Zum Beispiel können wir aufgrund dieser Verteilung berechnen, wie wahrscheinlich es ist, dass der Intelligenzquotienten aus zwei Stichproben mehr als eine Standardabweichug voneinander abweichen. Wir können dies berechnen, indem wir die Fläche rechts und links des t-Wertes -1 und 1 abtragen und zusammen zählen:\nFigure 4.10: Lösung: 82%\nWie du siehst, liegt die Wahrscheinlichkeit bei etwa 33%. Es ist also nicht äußerst unwahrscheinlich, aber auch nicht sehr wahrscheinlich, einen solch großen Unterschied aus einer Population zu finden.","code":"## Warning: Removed 2 rows containing missing values (geom_bar).\n\n## Warning: Removed 2 rows containing missing values (geom_bar).\n\n## Warning: Removed 2 rows containing missing values (geom_bar).## Warning: Removed 1 rows containing non-finite values (stat_bin).## Warning: Removed 2 rows containing missing values (geom_bar)."},{"path":"statistisches-hypothesentesten.html","id":"zusammenfassung-2","chapter":"4 Statistisches Hypothesentesten","heading":"4.3.7 Zusammenfassung","text":"diesem Submodul haben wir gelernt, Stichprobenkennwertverteilungen sind. Zunächst haben wir gelernt, dass Variablen unterschiedlichen Skalenniveaus vorliegen können. Liegen Variablen als nominalskalierte oder ordinalskalierte Verteilungen dar, können wir sie durch diskrete Verteilungen darstellen. Liegen Variablen metrisch vor (intervall- oder verhältnisskaliert), können wir sie durch stetige Verteilungen darstellen. Diese stetigen Verteilungen bildeten den Rest dieses Submoduls. Wir haben gesehen, dass Stichprobenkennwertverteilungen genau das sind, das Wort andeutet: Die Verteilung von Kennwerten aus Stichproben. Dabei haben wir erkannt, dass die Stichprobenkennwertverteilung des Mittelwerts immer eine Normalverteilung annimmt (zentrales Grenzwerttheorem). Die Standardnormalverteilung ist eine besondere Form der Normalverteilung, da sie immer einen Mittelwert von 0 und eine Standardabweichung von 1 hat. Wir haben ebenso gelernt, dass wir die Wahrscheinlichkeit von Kennwerten stetigen Verteilungen wie der Standardnormalverteilung anhand des Integrals unter der Fläche der Verteilungen berechnen können. Diese Berechnungen sind Kern des restlichen Seminars, da wir durch Stichprobenkennwertverteilungen Hypothesen testen können. Zuletzt haben wir die t-Verteilungen kennen gelernt. t-Verteilungen sind eine besondere Form der Standardnormalverteilungen, denen der Standardfehler der t-Werte anders berechnet wird als der Standardfehler der z-Werte. Im nächsten Modul werden wir sehen, wie Stichprobenkennwertverteilungen genutzt werden, um Hypothesen zu testen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"prozesse-des-statistischen-hypothesentestens","chapter":"4 Statistisches Hypothesentesten","heading":"4.4 Prozesse des statistischen Hypothesentestens","text":"diesem Submodul wirst du verstehen, wie Stichprobenkennwertverteilungen verwendet werden um Hypothesen der Bildungsforschung zu testen. Wir werden hierzu jeden einzelnen Schritt von der Hypothese bis zu der statistischen Entscheidung kennen lernen. Dieses Verfahren wird uns das ganze Semester begleiten, indem wir für jede Hypothese den gleichen Prozess durchlaufen. Folgende Inhalte behandelt dieses Submodul:Überblick über den Prozess des statistischen HypothesentestensÜberblick über den Prozess des statistischen HypothesentestensHypothesenpaar aufstellenHypothesenpaar aufstellenStatistische Modellierung des HypothesenpaaresStatistische Modellierung des HypothesenpaaresKennwerte berechnenKennwerte berechnenWahrscheinlichkeit des Kennwertes unter der H0: P(D|H0)Wahrscheinlichkeit des Kennwertes unter der H0: P(D|H0)Statistische EntscheidungenStatistische EntscheidungenAusführliches Beispiel: t-test für eine StichprobeAusführliches Beispiel: t-test für eine StichprobeZusammenfassungZusammenfassung\nFigure 4.11: Lösung: 82%\n","code":""},{"path":"statistisches-hypothesentesten.html","id":"überblick-über-den-prozess-des-statistischen-hypothesentestens","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.1 Überblick über den Prozess des statistischen Hypothesentestens","text":"Beginnen wir mit einem Überblick über den Prozess des statistischen Hypothesentestens (siehe Bild oben). Anfang eines jeden Experiments steht die Hypothese. Genauer ein Hypothesenpaar. Schau dir beispielsweise folgende drei Hypothesen aus drei verschiedenen Fachartikeln :Stull & Mayer (2017): der folgenden Studie haben sich die Wissenschaftler gefragt, ob Lernende aus Lehrbüchern mehr lernen, wenn sie Grafiken teilweise selbst erstellen oder wenn die Grafiken vorgegeben werden.Stull, . T., & Mayer, R. E. (2007). Learning versus learning viewing: Three experimental comparisons learner-generated versus author-provided graphic organizers. Journal Educational Psychology, 99(4), 808-820. https://doi.org/10.1037/0022-0663.99.4.808“purpose Experiment 1 test whether students better understand scientific passage asked generate graphic organizers (following pretraining genreate hierarchies, list, flowcharts, matrices) spaces margin passage contains author-provided graphic organizers.”Müller & Oppenheimer (2014): dieser Studie hatten die Wissenschaftler die Hypothese, dass es lernwirksamer ist einer Vorlesung per Hand als mit dem Laptop mitzuschreiben.Mueller, P. ., & Oppenheimer, D. M. (2014). pen mightier keyboard: Advantages longhand laptop note taking. Psychological Science, 25(6), 1159-1168. <https://doi.org/10.1177/0956797614524581>“Thus, conducted three experiments investigate whether taking notes laptop versus writing long-hand affects academic performance, explore potential mechanism verbatim overlap proxy depth processing.”Hoggerheide et al. (2019): dieser Studie untersuchten die Wissenschaftler*innen, ob es lernwirksamer ist, anderen etwas zu erklären, als Lernmaterial wiederholt zu lernen.Hoogerheide, V., Renkl, ., Fiorella, L., Paas, F., & van Gog, T. (2019). Enhancing example-based learning: Teaching video increases arousal improves problem-solving performance. Journal Educational Psychology, 111(1), 45–56. <https://doi.org/10.1037/edu0000272>“main purpose present study investigate hypothesis initial acquisition phase consisting studying two worked examples solving practice problem, teaching content another example video (teaching condition) improve learning (measured performance isomorphic transfer test problems) compared studying example(control condition).”Müller und Oppenheimer (2014) beispielsweise glaubten, dass es lernwirksamer ist, Informationen aus einer Vorlesung mit der Hand aufzuschreiben als mit einem Laptop. Die Hypothese, welche man testen bzw. falsifizieren möchte, nennt man Alternativhypothese. Die Nullhypothese ist das Gegenstück der Alternativhypothese. Beispiel von Müller und Oppenheimer (2014) wäre die Nullhypothese, dass das Medium mit welchem man mitschreibt, keinen Einfluss auf das Lernen hat. Die Null- und Alternativhypothese bezeichnen wir als Hypothesenpaar.Dieses Hypothesenpaar übersetzen wir als nächstes statistische Modelle. Wir werden statistische Modell im nächsten Modul kennen lernen. Im Kern übersetzen wir bei der statistischen Modellierung unsere sprachlichen Hypothesen eine mathematische Form.Im Anschluss bestimmen wir Kennwerte auf Grundlage der statistischen Modellierung. Mit Kennwerten meinen wir t-Werte, z-Werte als auch F-Werte. Im letzten Submodul haben wir beispielsweise gesehen, dass der t-Wert genutzt werden kann, um heraus zu finden wie wahrscheinlich ein Mittelwert gegeben eines bestimmten Populationsmittelwerts ist.Diese Kennwerte tragen wir ihren Stichprobenkennwertverteilungen ab (z.B. t-Verteilung). Stichprobenkennwertverteilungen geben , wie sich Kennwerte verteilen, wenn die Nullhypothese korrekt ist. Zum Beispiel: Wie würden sich die Mittelwerte zweier Stichproben unterscheiden, wenn Studierende, die per Hand schreiben genau gut lernen wie Studierende, die mit dem Laptop mitschreiben. Dieser Schritt ist wird häufig von Studierenden missverstanden. Wir bestimmen immer wie wahrscheinlich die Daten unter Annahme der Nullhypothese sind (P(D|H)), nicht wie wahrscheinlich die Alternativhypothese gegeben der Daten ist (P(H|D)). Wir kommen gleich ausführlicher auf diese Idee zu sprechen. Zuletzt treffen wir eine statistische Entscheidung auf Grundlage dieser Wahrscheinlichkeit. Ist die Wahrscheinlichkeit für einen Kennwert sehr gering unter Annahme der Nullhypothese (ermittelt anhand der Stichprobenkennwertverteilung) entscheiden wir uns gegen die Nullhypothese. Ist die Wahrscheinlichkeit für einen Kennwert oder größer groß, entscheiden wir uns für die Nullhypothese. dieser Stelle kommt die Idee der Falsifikation zum Tragen. Die Entscheidung betrifft vordergründig der Ablehnung einer Hypothese. Beispielsweise könnten wir auf Grundlage eines Experiments die Alternativhypothese ablehnen. Wir können die Alternativhypothese allerdings nie annehmen.Zuletzt berichten wir den Prozess des statistischen Hypothesentestens, indem wir den Kennwert, die Wahrscheinlichkeit für den Kennwert und unsere statistische Entscheidung berichten. Als nächstes besprechen wir diese Schritte ausführlicher.","code":""},{"path":"statistisches-hypothesentesten.html","id":"hypothesenpaar-aufstellen","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.2 Hypothesenpaar aufstellen","text":"Beginnen wir mit einer Hypothese. Nehmen wir , du glaubst die Lerntypentheorie. Du behauptest, dass Lernende, die von sich behaupten visuell bzw. auditiv zu lernen mit ihrem präferiertem Medium besser lernen als mit ihrem nicht-präferiertem Medium. Zwar stellst du nur eine Hypothese auf (die Unterschiedshypothese), du nimmst allerdings implizit zwei Hypothesen : Eine Nullhypothese (H0), die von keinem Unterschied zwischen den beiden Gruppen ausgeht und eine Alternativhypothese (H1), die von einem Unterschied ausgeht. Vor dem Experiment weißt du nicht, welche der Hypothesen korrekt ist.Solche Hypothesenpaare sind immer der erste Schritt beim statistischen Hypothesentesten. Die Alternativhypothese ist diejenige Hypothese, von der du glaubst, dass sie der Falsifikation stand hält. Die Nullhypothese ist diejenige Hypothese, welche die Alternativhypothese falsifzieren würde.Es gibt verschiedene Typen Hypothesen:Unterschiedshypothese: Mit einer Unterschiedshypothese testest du der Regel, ob sich Gruppen einer Variable voneinander unterscheiden. Beispielsweise, lernen Lernende, die mehr als 7 Stunden schlafen mehr als Lernende die weniger als 7 Stunden schlafen. Oder, ist es wirksamer per Hand oder mit dem Laptop einer Vorlesung mitzuschreiben. der Mitte des Seminars werden wir vor allem Unterschiedshypothesen prüfen.Zusammenhangshypothese: Mit einer Zusammenhangshypothese testest du, ob mehrere Variablen einer Beziehung miteinander stehen. Zum Beispiel: Führt eine höhere Motivation zu mehr Lernen? Oder, steigt der Verkauf von Eis mit dem Anstieg der Temperatur? Zusammenhangshypothesen lernen wir den nächsten Modulen kennen.Veränderungshypothese: Mit einer Verändurungshypothese testest du, ob sich eine Variable über die Zeit verändert. Zum Beispiel: Verringert Entspannungstraining über die Zeit die Aggression von Menschen? Oder, kann man sich durch wiederholtes Meditieren besser konzentrieren. Wir prüfen diesem Seminar allerdings keine Veränderungshypothesen.Für jede Art von Hypothese wird eine Null- und Alternativhypothese aufgestellt. Nimmst du beispielsweise , dass eine höhere Motivation zu mehr Lernen führt (Alternativhypothese), stellst du ebenso die Nullhypothese auf, dass Motivation und Lernen keinem Zusammenhang zueinander stehen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"eigenschaften-von-hypothese","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.2.1 Eigenschaften von Hypothese","text":"Für jede Hypothese gilt, dass sie allgemeingültig und probabilistisch ist.Allgemeingültig bedeutet, dass Hypothesen Aussagen über eine Population treffen, nicht über eine Stichprobe. Wenn ich beispielsweise einem Experiment heraus finde, dass das Mitschreiben mit der Hand lernwirksamer ist als das Mitschreiben mit dem Laptop, treffe ich eine Aussage über eine gesamte Population und nicht über die Stichprobe. Stichproben beschreibt man anhand deskriptiver Daten. Aussagen über die Population macht man anhand der Inferenzstatistik, welche wir diesem Kurs kennen lernen.Ebenso sind Hypothesen probabilistisch. Das bedeutet, wir machen Aussagen über die Tendenz von Gruppen, aber nicht über Einzelwerte von Gruppen. Beispielsweise kann ich auf Grundlage von Experimenten behaupten, dass es lernwirksamer per Hand als mit dem Laptop mitzuschreiben. Ich sage damit allerdings nicht, dass es ausgeschlossen ist, dass eine Perosn, die per Laptop schreibt mehr lernt als eine Person, die mit per Hand schreibt. Dieser Unterschied tritt häufig der Kommunikation mit statistischen Laien auf. Du sagst zum Beispiel, dass langes Schlafen dem Lernen hilft, deine Freundin kennt aber den Onkel Harald, der nur fünf Stunden schläft und trotzdem gut lernt. Onkel Harald ist allerdings ein Einzelfall und kann durchaus trotz wenig Schlaf gut lernen. Onkel Harald falsifiziert anderen Worten deine Hypothese nicht.","code":""},{"path":"statistisches-hypothesentesten.html","id":"statistische-modellierung-des-hypothesenpaares","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.3 Statistische Modellierung des Hypothesenpaares","text":"Sobald wir unser Hypothesenpaar bestimmt haben, müssen wir diese Hypothesen statistisch modellieren. Wir werden im nächsten Modul die statistische Modellierung ausführlicher besprechen, dieser Stelle genügt ein kleines Beispiel, um die statistische Modellierung im Groben zu verstehen.Stell dir vor, du glaubst, dass Studierende im Schnitt mehr als 10 Bücher pro Jahr lesen. Deine Null- und Alternativhypothese würde diesem Fall wie folgt lauten:Nullhypothese: Der Populationsmittelwert ist gleich 10 Bücher pro JahrAlternativhypothese: Der Populationsmittelwert ist größer als 10 Bücher pro JahrStatistisch können wir diese beiden Hypothesen wie folgt darstellen:Nullhypothese: Der Mittelwert der Variable entspricht 10:\\(\\mu = 10\\).Alternativhypothese: Der Mittelwert der Variable ist größer als 10: \\(\\mu > 10\\)Ein statistisches Modell wird nun genutzt, um Werte vorherzusagen. Für jedes Hypothesenpaar erstellen wir zwei Modelle: Das kompakte Modell (\\(MODEL_A\\)) und das erweiterte Modell (\\(MODEL_C\\)).\\[\nMODEL_A : \\hat{Y} = \\mu\n\\]\n\\[\nMODEL_C : \\hat{Y} = 10\n\\]\n- Kompaktes Modell (\\(MODEL_C\\)): unserem Fall besagt das kompakte Modell: Die Anzahl der Bücher für jede Person beträgt 10. Diese Annahme entspricht unserer Nullhypothese (H0). Y-Dach steht für den Wert, welchen das Modell vorhersagt.\n- Erweitertes Modell (\\(MODEL_A\\)): Das Modell für die Alternativhypothese müsste lauten: Die Anzahl der Bücher entspricht dem Mittelwert der Population (μ). Wir gehen davon aus, dass dieser Mittelwert größer als 10 ist. der Grafik ist der Populationsmittelwert durch das Symbol μ (ausgesprochen mü) gekennzeichnet.","code":""},{"path":"statistisches-hypothesentesten.html","id":"kennwerte-berechnen","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.4 Kennwerte berechnen","text":"Auf Grundlage dieser beiden Modelle berechnen wir als nächstes Kennwerte. diesem Kurs werden wir vor allem t- und F-Werte kennen lernen. Im Verlauf des Kurses werden wir sehen, dass t- und F-Werte miteinander verwandt sind. Wir werden daher vor allem F-Werte berechnen. Folgende Verallgemeinerung können wir dieser Stelle bezüglich der Kennwerte treffen:t-Wert: Wie viele Standardabweichungen sind zwei Werte (z.B. Mittelwerte) voneinander entfernt? Zum Beispiel: Wie viele Standardabweichung sind zwei Mittelwerte voneinander entfernt? Wie viele Standardabweichungen ist ein Korrelationskoeffizient von 0 entfernt? Wie viele Standardabweichung lesen Studierende mehr als 10 Bücher?F-Wert: Das kompakte Modell macht Fehler seiner Vorhersagen. Das erweiterte Modell kann bessere Vorhersagen machen, da es Informationen aus mehr Variablen umfasst als das kompakte Modell. Der F-Wert gibt , wie viel besser diese zusätzlichen Variablen die abhängige Variable aufklären als willkürliche andere Variablen. Wenn du diese Ausführungen der Stelle nicht verstehst, nicht schlimm, wir werden es ausführlich den nächsten Kapitel aufbauen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"wahrscheinlichkeit-des-kennwertes-unter-der-h0-pdh_0","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.5 Wahrscheinlichkeit des Kennwertes unter der H0: \\(P(D|H_0)\\)","text":"Als nächstes überprüfen wir wie wahrscheinlich solche Kennwerte sind, unter der Annahme, dass die Nullhypothese korrekt ist. Diese Wahrscheinlichkeit bezeichnen wir als \\(P(D|H_0)\\). Zum Beispiel: Wie wahrscheinlich ist es, dass sich zwei Gruppen um zwei Standardardabweichungen unterscheiden, wenn beide Gruppen aus der gleichen Population stammen? Oder, wie wahrscheinlich ist es, dass der Korrelationskoeffizient zweier Variablen bei r = .80 liegt, wenn diese beiden Variablen Wirklichkeit gar nicht miteinander korrelieren? Oder, wie wahrscheinlich ist es, dass der Intelligenzquotient einer Stichprobe 120 beträgt, während der echte Populationsmittelwert bei 100 liegt?anderen Worten, wir fragen uns immer, ob die Kennwerte unter Annahme der Nullhypothese wahrscheinlich oder unwahrscheinlich sind. Genau diese Feststellung ist mit der Idee der Falsifikation vereinbar. Indem wir sagen, dass ein Kennwert unwahrscheinlich ist, können wir eine Hypothese teilweise falsifizieren. Das heißt aber auch, dass wir keine Aussagen darüber machen, wie wahrscheinlich die Hypothese gegeben den Daten ist: \\(P(H|D)\\). Warum? Da \\(P(H|D)\\) die inverse Wahrscheinlichkeit von \\(P(D|H)\\) ist. Dieser Unterschied wird von Forschenden und Studenten häufig verwechselt. Um zu akzeptieren, dass diese beiden Wahrscheinlichkeiten invers sind, ein Beispiel: Wie hoch ist die Wahrscheinlichkeit innerhalb von zwei Jahren zu sterben, wenn Menschen von einem Krokodil der Kopf abgerissen wird: P(‘zwei Jahren sterben’ | ‘Kopf von Krokodil abgebissen’)? Diese Wahrscheinlichkeit liegt bei 1. Jede Person, der der Kopf von einem Krokodil abgebissen wird, stribt sofort. Wie hoch ist wiederum die Wahrscheinlichkeit, dass man von einem Krokodil den Kopf abgerissen bekommen hat, gegeben dass man innerhalb der letzten zwei Jahre gestorben ist: P( ‘Kopf von Krokodil abgebissen’|‘den letzten zwei Jahren gestorben’)? Du siehst also, dass diese Wahrscheinlichkeiten unterschiedlich sind. Wir sollten daher beide voneinander unterscheiden. der Statistik fragen wir uns immer, wie wahrscheinlich die Daten unter Annahme der Nullhypothese sind: \\(P(D|H_0)\\).\\(P(D|H_0)\\) bezeichnet die Wahrscheinlichkeit eines Kennwertes unter Annahme der Nullhypothese. \\(P(D|H_0)\\) wird auch als p-Wert** bezeichnet.","code":""},{"path":"statistisches-hypothesentesten.html","id":"statistische-entscheidungen","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.6 Statistische Entscheidungen","text":"Zu Beginn dieses Moduls haben wir gesagt, dass die Falsifikation das Herzstück der Statistik ist. Wir können keine Hypothesen bestätigen, sie allerdings widerlegen. Genau das machen wir durch statistische Entscheidungen. Genauer lehnen wir die Nullhypothese ab, wenn der Kennwert unter Annahme der Nullhypothese sehr unwahrscheinlich ist. Ebenso lehnen wir die Alternativhypothese ab, wenn der Kennwert unter Annahme der der Nullhypothese wahrscheinlich ist. Diese Form einer binären Entscheidungen geht auf die Statistiker, Jerzy Neyman und Egon Pearson zurück. Sie sagten, dass man die Nullhypothese bei einer Wahrscheinlichkeit von unter 5% ablehnen (das Alpha-Niveau) sollte und die Nullhypothese bei einer Wahrscheinlichkeit von über 5% vorläufig annehmen sollte:Bei einer Wahrscheinlichkeit eines Kennwertes unter 5% spricht man von einem signifikanten Ereignis. Warum 5%? Der 5% Werte oder das Alpha-Niveau wurde willkürlich von Sir Ronald Fisher gewählt. Signifikanz bedeutet allerdings nicht, dass ein Ergebnis bedeutsam ist, sondern, dass ein Ereignis unter Annahme der Nullhypothese unwahrscheinlich ist.Signifikant bedeutet, dass ein Kennwert unter Annahme der Nullhypothese unwahrscheinlich ist; nicht, dass ein Ergebnis bedeutsam ist.Die Entscheidung für oder gegen die Nullhypothese hilft der Theoriebildung folgendermaßen: Stell dir vor, es werden 100 Experimente zu der Frage durchgeführt, ob die Mitschrift per Hand lernwirksamer ist als die Mitschrift mit dem Laptop. 80 Experimenten entscheiden sich die Forschenden dafür, die Nullhypothese abzulehnen. Das heißt, 80% der Fälle lehnen die Forschenden die Aussage ab, dass es keinen Unterschied zwischen diesen beiden Gruppen gibt. Diese Vielzahl Experimenten deuten also darauf hin, dass die Mitschrift per Hand der Tat lernwirksamer ist die Mitschrift mit dem Laptop. Damit haben die Forschenden relativ überzeugend die Hypothese falsifiziert, dass beide Techniken äquivalent sind.Dieses Beispiel zeigt uns, dass statistische Entscheidungen auf lange Sicht helfen, eine Theorie zu falsifizieren. Im Grunde versuchen wir bei jedem Experiment einen Test zu entwickeln, der uns hilft dieser Schlussfolgerung näher zu kommen. Die Erkenntnis liegt bei diesem Vorgehen nicht einem Experiment, sondern vielen Experimenten. Daher wir diese Art der Statistik auch als Frequentistischer Wahrscheinlichkeitsbegriff bezeichnet. Dieser Ansatz eignet sich, wenn wir für unser Handeln Entscheidungen treffen müssen. Zum Beispiel, sollten Lernende mit ihrem präferiertem Lernmaterial lernen oder nicht? Ist es besser einen Text wiederholt zu lesen, oder sein Wissen frei abzufragen? Stellen wir beispielsweise wiederholt fest, dass die die Annahme wiederholtes Lesen sei gleich effektiv wie die freie Wissensabfrage widerlegt wird, können wir auf Dauer eine Entscheidung treffen, Lernende zu empfehlen, eine bestimmte Lerntechnik einer anderen vorzuziehen. Der frequentistische Wahrscheinlichkeitsbegriff entwickelt Erkentnisse daher erst nach einer Fülle Experimenten.","code":""},{"path":"statistisches-hypothesentesten.html","id":"ausführliches-beispiel-t-test-für-eine-stichprobe","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.7 Ausführliches Beispiel: t-Test für eine Stichprobe","text":"Stell dir vor, du glaubst, dass Studierende pro Jahr mehr als 10 Bücher lesen. Um deine Hypothese zu prüfen, befragst du 30 Studierende willkürlich deiner Universität, wie viel Bücher sie im letzten Jahr gelesen haben. Im Schnitt stellst du fest, dass deine Stichprobe 12.45 Bücher (Mittelwert) im letzten Jahr gelesen hat:Deskriptiv sind es also bereits mehr als 10 Bücher. Allerdings weißt du nicht, ob das unwahrscheinlich mehr Bücher sind als man unter der Nullhypothese (10 Bücher pro Jahr) annehmen würde. Folgendes Hypothesenpaar stellst du auf:Nullhypothese: Die Studierenden lesen 10 Bücher pro JahrAlternativhypothese: Die Studierenden lesen mehr als 10 Bücher pro JahrDie Frage lautet nun, kannst du deine Nullhypothese falsifizieren? anderen Worten, ist es unwahrscheinlich, dass die Studierenden 12.45 Bücher pro Jahr lesen, wenn sie Wirklichkeit im Mittel 10 Bücher pro Jahr lesen?\\[\nH_0 : \\hat{Y}_i = 10\n\\]\\[\nH_0 : \\hat{Y}_i > 10\n\\]Statistische Modellierung deiner HypotheseDeine Null- und Alternativhypothese lassen sich wie folgt modellieren. Das Modell der Nullhypothese (bzw. das kompakte Modell) nimmt , dass Studierende im Schnitt 10 Bücher pro Jahr lesen. Das heißt, das Modell schätzt für jede Person, dass er oder sie 10 Bücher pro Jahr liest. Das Modell der Alternativhypothese (bzw. das erweiterte Modell) sagt voraus, dass eine Person mehr als 10 Bücher pro Jahr liest. Du erwartest daher, dass der Populationsmittelwert größer als 10 ist.\\[\nt_{df} = \\frac{\\bar{x} - 10}{s / \\sqrt{n}} = \\frac{12.45 - 10}{2.73 / \\sqrt{30}} = 4.92\n\\]Bestimmung des KennwertesIm nächsten Schritt bestimmst du den Kennwert. Für den t-Test mit einer Stichprobe können wir einen t-Wert berechnen. Der t-Wert gibt uns , wie viele Standardabweichungen der t-Wert vom Mittelwert der Nullhypothese entfernt liegt. Wir erhalten einen empirischen t-Wert von 4.92.Grafisch können wir den (empirischen) t-Wert der t-Verteilung darstellen:Wahrscheinlichkeit des Kennwertes unter der Nullhypothese: P(D|H0)Als nächstes fragen wir uns, wie wahrscheinlich der t-Wert ist, wenn Wirklichkeit Studierende 10 Bücher pro Jahr lesen. Erinnere dich, dass die t-Verteilung die Verteilung von Mittelwerten aus Stichproben beschreibt, die aus einer Population gewonnen werden, denen die Nullhypothese gilt (Studierende lesen 10 Bücher pro Jahr).Zunächst siehst du, dass der t-Wert weit vom Gipfel der t-Verteilung entfernt liegt. Damit wissen wir, dass der von uns gefundene empirische t-Wert (4.92) sehr unwahrscheinlich ist, wenn der Mittelwert der Population bei 10 liegt. Genauer ist die Wahrscheinlichkeit für einen solchen empirischen t-Wert geringer als 1%.\nDa dieser empirische t-Wert innerhalb des kritischen Bereichs (blau dargestellt) liegt, sprechen wir von einem signifikanten Ereignis.Statistische EntscheidungDa es sich um ein signifikantes Ereignis handelt, lehnen wir die Nullhypothese zu Gunsten der Alternativhypothese ab. Wir entscheiden uns demnach auf Grundlage unseres Experiments dafür, die Annahme, dass Studierende 10 Bücher pro Jahr lesen, inkorrekt ist.Ergebnis berichtenZuletzt berichten wir unser Ergebnis. Hierfür formulieren wir folgenden Textabschnitt:“Um zu prüfen, ob Studierende pro Jahr mehr als 10 Bücher pro Jahr lesen, wurde ein t-Test für eine Stichprobe berechnet. Der t-Test ergab einen signifikanten Effekt, t(29) = 4.91, p < .001, d = 0.90 (großer Effekt), darauf hinweist, dass Studierende mehr als 10 Bücher pro Jahr lesen.”Wie die Ergebnisse berichtet werden, lernen wir im Verlaufe des Seminars ausführlich kennen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"zusammenfassung-3","chapter":"4 Statistisches Hypothesentesten","heading":"4.4.8 Zusammenfassung","text":"diesem Submodul haben wir gelernt, wie man von einer Hypothese zu einem Ergebnis einer Studie kommt. Dieser Prozess umfasst verschiedene Schritte, die wir diesem Kurs immer wieder wiederholen werden. Zu Beginn einer jeden Forschungsfrage steht eine Hypothese, die wir als Hypothesenpaar formulieren. Dieses Hypothesenpaar werden wir statistisch modellieren. Dieser Schritt ist dieser Stelle vermutlich noch unklar, er wird dir allerdings klarer, wenn wir uns mit dem F-Wert beschäftigen, da der F-Wert aus diesen statistischen Modellen berechnet wird. Sobald wir den Kennwert haben, berechnen wir die Wahrscheinlichkeit für den Kennwert unter der Nullhypothese. Kennwerte machen Aussagen über unsere Hypothesen. Ein t-Wert beispielsweise kann eine Aussage über den Mittelwertsunterschied zwischen Gruppen machen. Ein t-Wert kann aber auch sagen, wie viele Standardabweichung eine Korrelation von 0 entfernt ist. Indem wir die Wahrscheinlichkeit dieser Kennwerte unter der Nullhypothese berechnen, geben wir , wie unwahrscheinlich ein Mittelwertsunterschied oder ein standardsierter Unterschied eine Korrelation von 0 ist, wenn es zum Beispiel keinen Mittelwertsunterschied zwischen Gruppen gibt oder wenn es keine Korrelation zwischen zwei Variablen gibt. Auf Grundlage dieser Wahrscheinlichkeit treffen wir eine binäre statistische Entscheidung: Wir lehnen die Nullhypothese ab oder behalten sie. Liegt die Wahrscheinlichkeit für den Kennwert unter 5%, lehnen wir die Nullhypothese ab, liegt die Wahrscheinlichkeit über 5%, akzeptieren wir die Nullhypothese vorläufig. Ende dieses Prozess berichten wir das Ergebnis des Tests.","code":""},{"path":"statistisches-hypothesentesten.html","id":"alpha--und-betafehler-und-power","chapter":"4 Statistisches Hypothesentesten","heading":"4.5 Alpha- und Betafehler und Power","text":"diesem Submodul lernen wir weitere wichtige Begriffe der Statistik kennen, die wir im Verlaufe des ganzen Kurses verwenden werden. Wir werden diesem Submodul lernen, dass die statistischen Entscheidungen, welche wir auf Grundlage des p-Wertes ermitteln, falsch sein können und, dass wir diese Entscheidungen nur auf dem Hintergrund der Power einer Studie interpretiert sollten. Genauer werden wir lernen, dass wir die Stichprobengröße vor einem Experiment mit Bedacht wählen sollten, um der langen Sicht zu richtigen Entscheidungen zu kommen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"alpha--und-betafehler","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.1 Alpha- und Betafehler","text":"unserem letzten Modul haben wir gezeigt, dass wir der Statistik binäre Entscheidungen treffen. Entweder lehnen wir die Nullhypothese ab oder wir behalten sie vorläufig. Ist die Wahrscheinlichkeit eines Kennwertes unter Annahme der Nullhypothese geringer als 5% lehnen wir die Nullhypothese ab, ist die Wahrscheinlichkeit unter Annahme der Nullhypothese höher, akzeptieren wir die Nullhypothese vorläufig. Dieser 5%-Wert ist ein Beispiel für ein Alpha-Niveau. Das Alpha-Niveau gibt , unter welcher Wahrscheinlichkeit wir die Nullhypothese verwerfen, unter der Bedingung, dass es keinen Effekt der Population gibt.Grafisch dargestellt können wir das Alpha-Niveau bei einer gerichteten und ungerichteten Hypothese einer t-Verteilung darstellen. Im unteren Bild siehst du links eine gerichtete Hypothese (M1 > M2), im rechten Bild eine ungerichtete Hypothese (M1 = M2). Wie du siehst, wird das Alpha-Niveau bei einer ungerichteten Hypothese auf zwei Seiten geteilt. Der Kennwert könnte entweder unwahrscheinlich kleiner oder größer gegeben der Nullhypothese sein. Die Summe der beiden Flächen ergibt wiederum 5% (2.5% + 2.5%). Bei der gerichteten Hypothese tragen wir das Alpha-Niveau auf nur einer Seite der t-Verteilung ab. diesem Fall gehen wir davon aus, dass der Mittelwert M1 größer ist als der Mittelwert M2. Daher tragen wir das Alpha-Niveau rechts vom Mittelwert der t-Verteilung ab.passiert nun, wenn die Nullhypothese der Population korrekt ist, aber unser Kennwert innerhalb des Alpha-Niveaus fällt? diesem Fall entscheiden wir uns gegen die Nullhypothese und machen damit einen statistischen Fehler. Wir entscheiden uns gegen die Nullhypothese obwohl die Nullhypothese korrekt ist. Diesen Fehler nennen wir Alpha-Fehler. Das Gegenstück zum Alpha-Fehler ist der Beta-Fehler. Der Beta-Fehler tritt auf, wenn wir uns für die Nullhypothese entscheiden, diese allerdings inkorrekt ist.","code":""},{"path":"statistisches-hypothesentesten.html","id":"die-welt-der-nullhypothese-der-alpha-fehler","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.2 Die Welt der Nullhypothese: Der Alpha-Fehler","text":"Um diese beiden Fehler besser zu verstehen, gehen wir von zwei Welten aus. der einen Welt ist die Nullhypothese korrekt (z.B. es gibt keinen Mittelwertsunterschied zwischen zwei Gruppen). der anderen Welt ist die Nullhypothese falsch (z.B. es gibt einen Mittelwertsunterschied). Die Welt, der wir uns gerade befinden, stelle ich als durchängige Verteilung dar. Die andere Welt, stelle ich als gestrichelte Verteilung dar.der Welt der Nullhypothese (leicht graue Verteilung mit durchgängigem Rand) führt jeder empirisch ermittelte t-Wert, der innerhalb des blauen Bereichs fällt zu einer fälschlichen Ablehnung der Nullhypothese. anderen Worten, immer wenn der empirische t-Wert den blauen Bereich fällt, begehen wir einen Alpha-Fehler. Da wir das Alpha-Niveau vorab bestimmt haben, wissen wir, dass wir 5% der Fälle einen solchen Fehler machen, selbst wenn die Nullhypothese korrekt ist. Oder, 95% der Fälle treffen wir auf lange Sicht die richtige Entscheidung, wenn die Nullhypothese korrekt ist. Sagen wir beispielsweise du wiederholst ein Experiment 100 mal. Stimmt deine Nullhypothese, solltest du etwa 95 Fällen kein signifikantes Ergebnis erhalten. etwa 5 Fällen allerdings solltest du ein signifikantes Ergebnis erhalten und damit einen Alpha-Fehler begehen. Alpha-Fehler sind demnach nicht vermeidbar, selbst wenn die Nullhypothese korrekt ist.Wir können den Alpha-Fehler aber auch einer anderen Art und Weise visualisieren. Stell dir vor, es gibt keinen Unterschied zwischen den Gruppen und du wiederholst das gleiche Experiment vier Versuchsreihen 20000 mal. Die vier Versuchsreihen unterscheiden sich ihrer Stichprobengröße. Du führst je eine Reihe mit 5, 10, 50 und 200 Versuchspersonen pro Experiment durch. Im Folgenden siehst du wie sich die p-Werte bei diesen vier Versuchsreihen den 20000 Experimenten verteilen. Auf der x-Achse siehst du die p-Werte auf der y-Achse die Häufigkeit dieser p-Werte.Wie du erkennst, sehen die Verteilungen gleich aus. Sie sind stetig. Die Botschaft dieser Visualisierung ist, dass der Alpha-Fehler von der Stichprobengröße unabhängig ist. der Welt der Nullhypothese machen wir immer mit einer Wahrscheinlichkeit von 5% einen Alpha-Fehler. Egal, wie groß die Stichprobe ist.","code":""},{"path":"statistisches-hypothesentesten.html","id":"die-welt-der-alternativhypothese-beta-fehler","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.3 Die Welt der Alternativhypothese: Beta-Fehler","text":"der Welt der Alternativhypothese gehen wir davon aus, dass die Nullhypothese inkorrekt ist. Das heißt, wir nehmen beispielsweise , dass es einen Mittelwertsunterschied zwischen zwei Gruppen gib (beispielsweise einen Mittelwertsunterschied von 1 bei einer Standardabweichung von 2.1 zwischen zwei Gruppen der Population). Auch dieser Welt können wir einen Fehler machen. Diesen Fehler nennen wir Beta-Fehler. Der Beta-Fehler tritt auf, wenn wir die Nullhypothese annehmen, obwohl sie inkorrekt ist. Oder, wenn wir die Alternativhypothese ablehnen, obwohl sie korrekt ist.der obigen Visualisierung ist der Betafehler geringer als 50% (braune Fläche) aber nicht viel geringer (daran zu erkennen, dass die braune Fläche nahe Gipfel der Verteilung liegt). Ein solches Experiment wäre nicht sonderlich sensitiv. Gäbe es einen Mittelwertsunterschied der Population und würden wir diesen Effekt mit einer kleinen Stichprobe (~ 20 Versuchspersonen) testen, würden wir ~40% der Fälle eine falsche statistische Entscheidung treffen, selbst wenn unsere Alternativhypothese korrekt ist. Als Folge könnte es beispielsweise sein, dass wir eine Lernmethode nicht empfehlen, obwohl diese wirksam ist.der Regel möchten wir, dass der Beta-Fehler geringer als 20% ist. Das heißt, wir wollen sicher stellen, dass wir auf lange Sicht nicht zu oft eine falsche statistische Entscheidung treffen, sofern unsere Alternativhypothese korrekt ist. Nur, wir machen wir das? Indem wir die Größe der Stichprobe bestimmen.der folgenden Visualisierung siehst du den Beta-Fehler unter vier Bedingungen. Stell dir wieder ein einziges Experiment vor. diesem Experiment möchtest du testen, ob visuell Lernende besser mit visuellem als mit auditivem Lernmaterial lernen. Du glaubst, Lernende, die sich als visuelle Lerner bezeichnen lernen mehr durch visuelles als mitauditivem Lernmaterial. Gehen wir weiterhin davon aus, dass der wirkliche Mittelwertsunterschied dieser beiden Gruppen der Population 1 Punkt beträgt (gemessen durch den Test des Experiments). Zudem liegt die Standardabweichung der beiden Gruppen bei 2.1. Stell dir nun vor, du wiederholst das Experiment mit 5, 10, 50 und 200 Versuchspersonen. der Visualisierung siehst du braun die Wahrscheinlichkeit mit der du bei diesen vier Experimenten einen Beta-Fehler machen würdest.Offensichtlich ändert sich die Wahrscheinlichkeit für einen Beta-Fehler abhängig der Stichprobe. Je größer die Stichprobe ist, desto unwahrscheinlicher tritt ein Beta-Fehler auf. Bei 5 Versuchspersonen machst du mit ziemlicher Sicherheit einen Beta-Fehler, selbst wenn es einen Unterschied zwischen den Gruppen der Population gibt. Liegt die Stichprobengröße bei 200 Versuchspersonen wirst du selten einen Beta-Fehler machen.Die gleiche Botschaft können wir durch eine p-Wert-Verteilung darstellen. Erneut simulieren wir 20.000 Experimente mit unterschiedlichen Stichproben. Du siehst, dass sich die Verteilung der p-Werte ändert, sofern die Alternativhypothese korrekt ist bzw. ein Effekt der Population besteht. Mit steigender Stichprobengröße verringert sich der Beta-Fehler (daran zu erkennen, dass es weniger Balken rechts des roten Strichs gibt):Zur besseren Verständlichkeit können wir beide Visualisierungen miteinander kombinieren und zeigen, dass die Beta-Fehler der t-Verteilung äquivalent zu den Beta-Fehlern der p-Verteilung sind:","code":""},{"path":"statistisches-hypothesentesten.html","id":"vergleich-von-alpha--und-betafehler","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.4 Vergleich von Alpha- und Betafehler","text":"Sowohl der Welt der Nullhypothese als auch der Welt der Alternativhypothese können wir statistische Fehlentscheidungen treffen. Wir nennen diese Fehlentscheidungen Alpha- und Beta-Fehler. Die beiden Fehler werden als Wahrscheinlichkeiten angegeben und geben uns Hinweise darauf, mit welcher Wahrscheinlichkeit wir falsche statistische Entscheidungen treffen. Welche Welt die korrekte ist, wissen wir meist nicht. Wir führen Studien durch, um diese Frage zu beantworten. Wiederholen wir viele Studien mit dem gleichen Versuchsaufbau werden wir auf lange Sicht mit einer bestimmten Wahrscheinlichkeit Fehler machen.Wir haben gesehen, dass die Wahrscheinlichkeit für einen Alpha-Fehler immer bei 5% liegt. Die Wahrscheinlichkeit für einen Beta-Fehler varriiert abhängig der Stichprobe. Je größer die Stichprobe, desto kleiner die Wahrscheinlichkeit für einen Beta-Fehler. Für uns als Wissenschaftler*innen bedeutet dies, dass wir die Stichprobengröße bei einem Experiment mit Bedacht wählen sollten, da wir ansonsten Gefahr laufen, zu häufig einen Beta-Fehler zu machen. Stell dir vor, du führst ein aufwändiges Experiment durch, welches allerdings mit einer Wahrscheinlichkeit von 80% einen Beta-Fehler macht (das weißt du natürlich vorher nicht). nur 20% der Fälle würdest du korrekt schließen, dass es einen Effekt gibt. den meisten Fällen würdest du allerdings fälschlicherweise annehmen, dass es keinen Effekt gibt.","code":""},{"path":"statistisches-hypothesentesten.html","id":"power-teststärke","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.5 Power (Teststärke)","text":"Power oder Teststärke ist das Gegenstück zum Beta-Fehler. Liegt der Beta-Fehler bei 40%, liegt die Power bei 60%. Liegt der Beta-Fehler bei 20%, liegt die Power bei 80%. Kurzum, Power errechnet sich durch 100%- Beta-Fehler.der folgenden Visualisierung beispielsweise siehst du grün dargestellt die Power eines Experiments. Die rechte Verteilung stellt die Alternativhypothese dar, die linke die Nullhypothese. Du kannst aus der Visualisierung erkennen, dass die Power dieser Studie unter 50% liegt. anderen Worten, sollte es einen Effekt der Population geben, wirst du diesen mit einer Wahrscheinlichkeit geringer als 50% einem Experiment finden. Deine Studie hätte eine geringe Power.Power ist die Wahrscheinlichkeit mit der wir bei Korrektheit der Alternativhypothese ein signifikantes Ergebnis erziehenGanz ähnlich wie bei dem Beta-Fehler können wir uns ansehen, wie sich die Power mit steigender Stichprobengröße verändert. Hierfür visualisieren wir uns die Power erneut mit einer Stichprobe von 5, 10, 50 und 200 Personen pro Gruppe:Du siehst, dass die Power mit steigender Stichprobengröße steigt. anderen Worten, je mehr Versuchspersonen du bei einem Experiment erhebst, desto wahrscheinlicher erhältst du ein signifikantes Ergebnis. Erneut erkennen wir also, dass die Power keine feste Größe wie der Alpha-Fehler ist, sondern von der Stichprobengröße einem Experiment abhängt. Da die Power varriabel ist, sollten wir uns Gedanken machen, wie groß die Power sein sollte.der Regel versucht man einer Studie eine hohe Power zu erzielen. Eine Richtgröße ist eine Power von über 80%. Wir wollen Experimente erstellen, denen wir - bei einem bestehenden Effekt - mit einer Wahrscheinlichkeit von über 80% die richtige statistische Entscheidung fällen. Nämlich, dass wir die Nullhypothese ablehnen, da sie inkorrekt ist. Im Umkehrschluss bedeutet dies, dass jeder Effekt bei genügend großer Stichprobe signifikant wird. Selbst wenn es einen minimalen Effekt zwischen zwei Gruppen gibt, kannst du mit einer großen Stichprobe zeigen, dass der Unterschied zwischen den Gruppen signifikant ist. Aus diesem Grund sollte die Stichprobengröße bei einem Experiment nicht willkürlich gewählt werden. Ist deine Power zu klein, hast du geringe Chance, einen Effekt zu erzielen. Wir lernen mit geringer Power quasi gar nichts, da unser Test nicht sensitiv genug ist, einen Effekt zu finden. Liegt deine Power bei 100%, wirst du selbst bei trivialen Unterschieden zu signifikanten Ergebnissen kommen.","code":""},{"path":"statistisches-hypothesentesten.html","id":"power-analysen-ein-exkurs","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.6 Power-Analysen: Ein Exkurs","text":"Gehen wir zurück zu unserem ursprünglichen Experiment. Du hast geglaubt, dass visuelle Lernende besser mit visuellem als mit auditivem Lernmaterial lernen. Um diese Hypothese zu prüfen, entscheidest du dich pro Gruppe (visuelle Lerner mit visuellem Material und visuelle Lerner mit auditivem Material) 20 Personen zu testen, ohne vorab eine Power-Analyse zu machen. du nicht weißt, ist, dass der Effekt sehr sehr klein ist. Genauer gibt es folgende Kennwerte der Population: Würde man alle Lernende die Tests durchführen lassen, würde die Gruppe mit dem präferiertem Lernmaterial 6.1 Punkte bei einer Standardabweichung von 1.6 bekommen und die Gruppe mit dem nicht-präferiertem Lernmaterial 6.0 Punkte bei einer Standardabweichung von 1.6. Die Frage ist nun, wie hoch ist deine Power bei einer Stichprobengröße von 20 Personen pro Gruppe?Ein cleveres Tool für die Analyse von Power ist G*Power. G*Power wird von zahlreichen Wissenschaftlern verwendet, um vor einem Experiment die Stichprobengröße für das Experiment zu bestimmen. Zunächst ermittelst du die Größe des Effekts durch G*Power:Größe des Effekts bestimmenDu erkennst, dass auf der rechten Seite die deskriptiven Daten der Population eingegeben werden. G*Power sagt dir, dass der Population ein Effekt von d = 0.06 besteht. Wir bezeichnen einen solchen Effekt als klein. Der Effekt ist klein, dass man davon ausgehen kann, dass die Gruppen faktisch identisch sind.Stichprobengröße für eine Power von 80%G*Power sagt uns nun, dass wir 6334 Versuchspersonen erheben müssten, um eine Power von 80% zu erzielen. Der Effekt ist klein, dass wir eben erst mit ganz vielen Versuchspersonen zu signifikanten Ergebnissen kommen würden. Das heißt, euer Experiment mit 20 Personen wird sogut wie nie einen signifikanten Effekt erzielen. Ihr werdet fast immer nicht-signifikante Ergebnisse erzielen. Das liegt daran, dass ihr entweder einen zu großen Effekt erwartet oder eine zu kleine Stichprobe für den minimalen Effekt gewählt habt.Power bei einer Stichprobe von insgesamt 40 VersuchspersonenWir können ebenso die tatsächliche Power deines Experiments bestimmen. Diese liegt bei 20 Personen pro Gruppe bei 8%. Somit wirst du nur 8% der Fälle (solltet ihr das Experiment häufig wiederholen) ein signifikantes Ergebnis erzielen. Du wirst demnach mit ziemlicher Sicherheit zu dem Schluss kommen, dass es keinen Unterschied zwischen den Gruppen gibt. Dies Feststellung ist auch korrekt, da der Unterschied minimal und damit zu vernachlässigen ist.","code":""},{"path":"statistisches-hypothesentesten.html","id":"zusammenfassung-4","chapter":"4 Statistisches Hypothesentesten","heading":"4.5.7 Zusammenfassung","text":"diesem Submodul haben wir uns ausführlicher mit Fehlschlüssen statistischen Entscheidungen befasst. Aus dem letzten Submodul haben wir erfahren, dass wir der Statistik binäre Entscheidungen treffen. Wir entscheiden uns für oder gegen die Nullhypothese. diesem Submodul haben wir gelernt, dass wir für diese beiden Entscheidungen Fehler machen können. (1) Wir können uns gegen die Nullhypothese entscheiden, obwohl diese korrekt ist (Alpha-Fehler); und (2) wir können uns für die Nullhypothese entscheiden, obwohl sie inkorrekt ist (Beta-Fehler). Der Alpha-Fehler ist fixiert, das heißt er wird per Konvention auf einen bestimmten Wert definiert. der Lehr- und Lernforschung verwendet man ein Alpha-Niveau von 5%. Der Beta-Fehler ist varriabel und hängt unter anderem von der Stichprobengröße ab. Beide Fehler werden als Wahrscheinlichkeiten angegeben. Wiederholt man das gleiche Experiment hunderte Male, wird man diese Wahrscheinlichkeiten erhalten. Das Gegenstück vom Beta-Fehler ist die Power. Die Power kennzeichnet die Wahrscheinlichkeit ein signifikantes Ergebnis zu erzielen. der Regel versucht man durch die richtige Wahl der Stichprobengröße die Power auf über 80% zu halten.","code":""},{"path":"statistisches-hypothesentesten.html","id":"die-effektstärke-cohens-d","chapter":"4 Statistisches Hypothesentesten","heading":"4.6 Die Effektstärke Cohen’s d","text":"","code":""},{"path":"statistisches-hypothesentesten.html","id":"was-sagen-uns-signifikanztests","chapter":"4 Statistisches Hypothesentesten","heading":"4.6.1 Was sagen uns Signifikanztests?","text":"Bevor wir das Modul abschließen, ist es noch wichtig, dass wir den Begriff der Effektstärken und insbesondere die Effektstärke Cohen’s d kennen lernen. Wir haben mittlerweile etabliert, dass wir bei dem statistischen Hypothesentesten prüfen, ob ein Kennwert unter der Annahme der Nullhypothese unwahrscheinlich ist. Dieser Prozess hilft uns auf die lange Sicht, Entscheidungen zu treffen. Zum Beispiel, ob wir eine Lernmethode einer anderen bevorzugen sollen. Oder, ob zwei Variablen miteinander korrelieren (z.B. Rauchen und Lungenkrebs). Das bedeutet Signifikanztests zeigen uns, wie wir handeln sollen.Signifikanztests geben , wie wir handeln sollten; Effektstärken zeigen, wie groß ein Effekt ist und ob er praktisch nützlich ist.","code":""},{"path":"statistisches-hypothesentesten.html","id":"was-sagen-uns-effektstärken","chapter":"4 Statistisches Hypothesentesten","heading":"4.6.2 Was sagen uns Effektstärken?","text":"Effektstärken wiederum beantworten uns eine andere Frage. Effektstärken geben uns , wie groß ein Effekt ist. Beispielsweise mag es sein, dass eine Lernmethode effektiver ist als eine andere, aber wie viel effektiver ist sie? Ebenso mag es sein, dass zwei Variablen miteinander korrelieren, aber wie hoch korrelieren diese beiden Variablen miteinander? Während uns Signifikanztests auf Dauer helfen, Entscheidungen zu treffen, helfen uns Effektstärken einzuschätzen, ob Entscheidungen praktisch nützlich sind. Stell dir beispielsweise vor, du findest dass eine Lernmethode minimal besser ist als eine andere Lernmethode B. Lernmethode ist allerdings deutlich teurer. diesem Fall macht es viellicht Sinn trotz des minimalen Vorteils der Lernmethode , sich für Lernmethode B zu entscheiden. Andererseits kann es sein, dass ein Deliktinterventionsprogramm bei Jugendlichen minimal wirksam ist (siehe Wilson et al., 2003). Wenn aber nur 3 aus 100 Jugendlichen aufgrund dieses Programms keine Straftat begehen, werden weniger Menschen verletzt, oder gar umgebracht. Der geringe Effekt hat demnach eine praktische Bedeutsamkeit, da selbst der minimal Effekt fundamentale Auswirkungen auf wenige Menschen hat.Wir werden diesem Kurs verschiedene Effektstärken kennen lernen (PRE, R-Quadrat, Eta-Quadrat, partielles Eta-Quadrat und Cohen’s d). Da wir bisher lediglich Tests kennen gelernt haben, mit der man Mittelwertsunterschiede zwischen einer Gruppe und einem festen Wert bzw. zwischen zwei Gruppen testen kann, beschäftigen wir uns diesem Submodul mit der Effektstärke Cohen’s d, welche für solche Mittelwertsunterschiede verwendet wird.","code":""},{"path":"statistisches-hypothesentesten.html","id":"cohens-d","chapter":"4 Statistisches Hypothesentesten","heading":"4.6.3 Cohen’s d","text":"Cohen’s d gibt , wie viele Standardabweichungen zwei Mittelwerte voneinander entfernt liegen. Die Formel für Cohen’s d lautet wie folgt:\\[\nd = \\frac{\\bar{x}_1 - \\bar{x}_2}{s}\n\\]\n#### Cohens’ d bei nur einer StichprobeStell dir beispielsweise vor, du möchtest die Effektstärke bei einem t-Test für eine Stichprobe testen. diesem Fall hast du nur eine Stichprobe und damit auch nur einen Mittelwert. Im letzten Modul beispielsweise haben wir getestet, ob Studierende mehr als 10 Bücher pro Jahr lesen. Der Mittelwert der Stichprobe betrug 12.49. Nehmen wir nun , dass die Standardabweichung der Stichprobe der 30 Studierenden bei 3 lag.\\[\nd = \\frac{\\bar{x}_1 - \\bar{x}_2}{s} = \\frac{12.49 - 10}{2.74} = 0.90\n\\]\ndiesem Fall berechnet sich Cohen’s d wie folgt: Du ziehst den erwarteten Mittelwert (10 von deinem empirischen Mittelwert ab. Diese Differenz teilst du durch die Standardaweichung deiner Stichprobe. Cohen’s d beträgt demnach 0.90.","code":""},{"path":"statistisches-hypothesentesten.html","id":"cohens-d-bei-zwei-stichproben","chapter":"4 Statistisches Hypothesentesten","heading":"4.6.3.1 Cohens’ d bei zwei Stichproben","text":"Stell dir nun vor, du vergleichst den Mittelwert von zwei Gruppen miteinander. Du möchtest wissen, ob Studierende, die eine Concept-Map erstellen mehr lernen als Studierende, die einen Text erneut lesen. Dein Test hat maximal 10 Punkte. Folgende deskriptive Daten erhälst du:c_map_vergleichCohen’s d berechnet sich nun aus dem Mittelwertsunterschied dieser beiden Gruppen durch die gepoolte Standardabweichung der beiden Gruppen. Die gepoolte Standardabweichung berechnet sich wie folgt:\\[\ns_{pooled} = \\sqrt{\\frac{(n_1 - 1) * s^2_1 + (n_2 - 1) * s^2_2}{(n_1 + n_2 - 2)}} = \\sqrt{\\frac{(22 - 1) * 1.8^2 + (20 - 1) * 2.1^2}{(22 + 20 - 2)}} = 1.95\n\\]\nGepoolte StandardabweichungDie genaue Berechnung der gepoolten Standardabweichung ist dieser Stelle nicht wichtig. Entscheidend ist, dieser Wert bedeutet. Die gepoolte Standardabweichung ist eine Art Mittelwert der Standardabweichungen der beiden Gruppen. Der Mittelwert ist die Stichprobengröße der Stichproben adjustiert. Du siehst, dass die gepoolte Standardabweichung bei diesem Beispiel 1.95 beträgt.\\[\nd = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}} = \\frac{12.53 - 10}{1.95} = 1.21\n\\]\nCohen’s d zwei StichprobenCohen’s d berechnet sich nun aus dem Mittelwertsunterschied der beiden Gruppen und der gepoolten Standardabweichung. Du siehst, dass wir diesem Fall ein Cohen’s d von 1.21 erhalten.","code":""},{"path":"statistisches-hypothesentesten.html","id":"einordnung-der-größe-von-cohens-d","chapter":"4 Statistisches Hypothesentesten","heading":"4.6.4 Einordnung der Größe von Cohen’s d","text":"Jede Effektsgröße wird normalerweise Größen eingeteilt. Man spricht dann von einem kleinen, mittleren und großen Effekt. Folgende Einteilung hat sich für Cohen’s d etabliert.Unser obiger Effekt von 1.21 kann daher als großer Effekt bezeichnet werden. Zwar werden Effekte häufig mit der praktischen Bedeutsamkeit gleichgesetzt, allerdings sollte die Effektstärke immer auf dem Hintergrund der jeweiligen Disziplin gedeutet werden.","code":""},{"path":"statistische-modellierung.html","id":"statistische-modellierung","chapter":"5 Statistische Modellierung","heading":"5 Statistische Modellierung","text":"","code":""},{"path":"statistische-modellierung.html","id":"einführung-3","chapter":"5 Statistische Modellierung","heading":"5.1 Einführung","text":"Dieses Modul beschäftigt sich ausführlicher mit der statistischen Modellierung im Prozess des statistischen Hypothesentestens. Du wirst diesem Modul lernen, wie du die Null- und Alternativhypothese mathematische Modelle übertragen kannst und wie diese Modelle genutzt werden, um Hypothesen zu testen. Erneut werden wir uns mit Konzepten beschäftigen, die uns das ganze Semester begleiten werden. Je solider dieses Fundament sitzt, desto einfacher werden für dich die nächsten Module. Und erneut testen wir diesem Modul die Fragestellung aus dem letzten Modul:Lesen Studierende mehr als 10 Bücher pro Jahr?Genauer werden wir diesem Modul den t-Test für eine Stichprobe, welche wir im vorherigen Modul berechnet haben, anhand der statistischen Modellierung durchführen. diesem Modul werden wir zeigen, wie wir diese Hypothese statistisch modellieren können und anhand des F-Wertes prüfen können. Im Verlaufe dieses Prozesses werden wir uns mit folgenden zentralen Konzepten beschäftigen:Statistische Modelle: Wie können sprachliche Hypothesen mathematische Modelle übertragen werden?Statistische Modelle: Wie können sprachliche Hypothesen mathematische Modelle übertragen werden?Freiheitsgrade: Wir werden lernen, dass Freiheitsgrade anzeigen, wie viele Parameter noch ein Modell hinzugefügt werden können.Freiheitsgrade: Wir werden lernen, dass Freiheitsgrade anzeigen, wie viele Parameter noch ein Modell hinzugefügt werden können.Fehler Modellen: Wir werden die Konzepte SSEA, SSEC und SSR einführen, welche die Fehler beschreiben, die unsere Modelle noch der Vorhersage der wahren Werte machen. Wir werden lernen, dass wir Fehler quadrieren, da dies vorteilhafte Eigenschaften hat.Fehler Modellen: Wir werden die Konzepte SSEA, SSEC und SSR einführen, welche die Fehler beschreiben, die unsere Modelle noch der Vorhersage der wahren Werte machen. Wir werden lernen, dass wir Fehler quadrieren, da dies vorteilhafte Eigenschaften hat.PRE (Proportional Reduction Error): PRE ist ein Maß der Effektstärke. Wir werden lernen, dass PRE angibt, wie viele Prozent der Fehler des kompakten statistischen Modells das erweiterte Modell vorhersagt. PRE (Proportional Reduction Error): PRE ist ein Maß der Effektstärke. Wir werden lernen, dass PRE angibt, wie viele Prozent der Fehler des kompakten statistischen Modells das erweiterte Modell vorhersagt. F-Wert: Der F-Wert ist eine Erweiterung von PRE und gibt , wie viel besser die Parameter des erweiterten Modells im Vergleich zu willkürlichen Parametern sind, die keinen Beitrag zur Vorhersage der abhängigen Variable leisten.F-Wert: Der F-Wert ist eine Erweiterung von PRE und gibt , wie viel besser die Parameter des erweiterten Modells im Vergleich zu willkürlichen Parametern sind, die keinen Beitrag zur Vorhersage der abhängigen Variable leisten.Äquivalenz F und t: Wir werden lernen, dass der F-Wert und der t-Wert nah verwandt sind und Beispiel des t-Test für eine Stichprobe diese Äquivalenz aufzeigen.Äquivalenz F und t: Wir werden lernen, dass der F-Wert und der t-Wert nah verwandt sind und Beispiel des t-Test für eine Stichprobe diese Äquivalenz aufzeigen.Tabelle der Ergebnisse: Wir werden lernen, wie diese zentralen Konzepte der Regel tabellarisch Statistiksoftwares ausgegeben werden. Dies hilft uns später, den Output von Jamovi bzw. anderen Softwares besser zu verstehen.Tabelle der Ergebnisse: Wir werden lernen, wie diese zentralen Konzepte der Regel tabellarisch Statistiksoftwares ausgegeben werden. Dies hilft uns später, den Output von Jamovi bzw. anderen Softwares besser zu verstehen.Notation statistische Modelle: Zum Schluss werden wir das Vokabular der statistischen Modellierung vertiefen, indem wir lernen, welche Symbole für stehen.Notation statistische Modelle: Zum Schluss werden wir das Vokabular der statistischen Modellierung vertiefen, indem wir lernen, welche Symbole für stehen.","code":""},{"path":"statistische-modellierung.html","id":"übersicht-statistische-modellierung-und-prozess-des-statistischen-hypothesentestens","chapter":"5 Statistische Modellierung","heading":"5.2 Übersicht statistische Modellierung und Prozess des statistischen Hypothesentestens","text":"drei Videos versuche ich, dir zwei zentrale Ideen dieses Kurses zu erklären: Wie wir Hypothesen statistisch modellieren und wir diese Modelle nutzen, um Hypothesen zu testen.","code":""},{"path":"statistische-modellierung.html","id":"statistische-modellierung-1","chapter":"5 Statistische Modellierung","heading":"5.2.1 Statistische Modellierung","text":"TODO: Einfügen VideoTODO: Einfügen Datei: statistical_models.pdfTODO: Einfügen Video","code":""},{"path":"statistische-modellierung.html","id":"statistische-modellierung-2","chapter":"5 Statistische Modellierung","heading":"5.2.2 Statistische Modellierung","text":"TODO: Einfügen VideoTODO: Einfügen Datei: statistisches_hypothenthesten.pdf","code":""},{"path":"statistische-modellierung.html","id":"statistische-modellierung-der-null--und-alternativhypothese","chapter":"5 Statistische Modellierung","heading":"5.3 Statistische Modellierung der Null- und Alternativhypothese","text":"","code":""},{"path":"statistische-modellierung.html","id":"fragestellung-dieses-moduls","chapter":"5 Statistische Modellierung","heading":"5.3.1 Fragestellung dieses Moduls","text":"Im letzten Modul hatten wir die Fragestellung getestet, ob Studierende mehr als 10 Bücher pro Jahr lesen. Hierzu hatten wir 30 Studierende willkürlich gefragt, wie viele Bücher sie letztes Jahr gelesen haben. Wir fanden einen signifkanten Effekt und konnten damit zeigen, dass die Annahme, Studierende lesen 10 Bücher pro Jahr gegeben der Daten sehr unwahrscheinlich ist. Daher hatten wir die Nullhypothese abgelehnt. diesem Modul wiederholen wir den gleichen Test, nur dass wir diesemal statistische Modelle verwenden, um die Hypothese zu beantworten. Ende des Moduls werden wir zeigen, dass wir mit diesem Verfahren zu den gleichen Ergebnissen wie mit dem t-Test für eine Stichprobe kommen. Zur Erinnerung, dies war das Ergebnis unseres Tests:“Um zu prüfen, ob Studierende pro Jahr mehr als 10 Bücher pro Jahr lesen, wurde ein t-Test für eine Stichprobe berechnet. Der t-Test ergab einen signifikanten Effekt, t(29) = 4.91, p < .001, d = 0.90 (großer Effekt), darauf hinweist, dass Studierende mehr als 10 Bücher pro Jahr lesen.”Achte darauf, dass wir momentan noch nicht wissen, die Zahl 29 diesem Output bedeutet. Wir werden Ende dieses Submoduls nochmal darauf zu sprechen kommen.","code":""},{"path":"statistische-modellierung.html","id":"null--und-alternativhypothese-der-fragestellung","chapter":"5 Statistische Modellierung","heading":"5.3.2 Null- und Alternativhypothese der Fragestellung","text":"Zu Beginn eines jeden statistischen Tests müssen wir eine Null- und Alternativhypothese aufstellen. Bei unserer Hypothese handelt es sich zunächst um eine Unterschiedshypothese. Wir glauben, dass Studierende mehr als 10 Bücher pro Jahr lesen. Die Null- und Alternativhypothese lauten folgendermaßen:Nullhypothese: Der Populationsmittelwert ist gleich 10 Bücher pro JahrNullhypothese: Der Populationsmittelwert ist gleich 10 Bücher pro JahrAlternativhypothese: Der Populationsmittelwert ist größer als 10 Bücher pro JahrAlternativhypothese: Der Populationsmittelwert ist größer als 10 Bücher pro Jahr","code":""},{"path":"statistische-modellierung.html","id":"data-model-error","chapter":"5 Statistische Modellierung","heading":"5.3.3 DATA = MODEL + ERROR","text":"Die statistische Modellierung kann einem Satz zusammen gefasst werden: DATA = MODEL + ERROR. anderen Worten, die wahren Werte setzten sich immer aus unserem mathematischen Modell und den Fehlern, die dieses Model macht, zusammen.Mit DATA bezeichnen wir die abhängige Variable, jene Werte, die wir vorhersagen möchten. Mit MODEL bezeichnen wir das mathematische Modell auf Grundlage dessen wir die abhängige Variable vorhersagen möchten.Da mathematische Modelle nie perfekt sind, gibt es immer Fehler der Vorhersage. Diese Fehler nennen wir ERROR. Wenige Studierende lesen exakt 10 Bücher pro Jahr. anderen Worten ist die abhängige Variable immer die Kombination aus einem mathematischen Modell und dem Fehler, den wir mit diesem Modell machen.","code":""},{"path":"statistische-modellierung.html","id":"statistische-modellierung-der-null--und-alternativhypothese-1","chapter":"5 Statistische Modellierung","heading":"5.3.4 Statistische Modellierung der Null- und Alternativhypothese","text":"Das Ziel der statistischen Modellierung ist es, das sprachliche Hypothesenpaar ein mathematisches Hypothesenpaar zu überführen. Beginnen wir mit der Frage, wie das kompakte und das erweiterte Modell statistisch modelliert werden.Wir nennen das statistische Modell der Nullhypothese das kompakte Modell und das statistische Modell der Alternativhypothese das erweiterte Modell.","code":""},{"path":"statistische-modellierung.html","id":"statistisches-modell-der-nullhypothese-das-kompakte-modelle","chapter":"5 Statistische Modellierung","heading":"5.3.4.1 Statistisches Modell der Nullhypothese: Das kompakte Modelle","text":"Die Nullhypothese besagt, dass Studierende pro Jahr 10 Bücher lesen. Wir werden im Folgenden verschiedene Möglichkeiten beschreiben, diese Nullhypothese als kompaktes Modell statistisch darzustellen:Geschätze Anzahl der Bücher pro JahrDieses Modell gibt , dass jede Person pro Jahr 10 Bücher liest. Das Y mit dem Dach kennzeichnet einen geschätzten Wert. Wir nennen diesen Wert abhängige Variable. Das statistische Modell ist rechts des = Zeichens. Unser Modell besagt, dass jede Person exakt 10 Bücher pro Jahr liest.Tatsächliche Anzahl der Bücher pro JahrDieses Modell gibt , wie viele Bücher jede Person pro Jahr tatsächlich liest. Achte darauf, dass die abhängige Variable kein Dach mehr hat. Damit sagen wir, dass dies der reale Wert der Anzahl der Bücher ist. Den realen Wert können wir nur korrekt schätzen, da wir ɛ (Epsilon) Ende des Modells hinzufügen. ɛ steht für den Fehler (ERROR), den wir der Schätzung der Anzahl der Bücher für jede Person machen. Wenn zum Beispiel Hans 12 Bücher pro Jahr liest, müsste ɛ den Wert 2 haben, damit wir für Hans exakt 12 Bücher pro Jahr vorhersagen.Tatsächliche Anzahl der Bücher pro JahrDieses Modell ist äquivalent zum vorherigen, nur dass wir anstatt von 10 B0 schreiben. Ein großes B steht immer für Werte, welche wir nicht auf Grundlage der Daten berechnen, sondern vorgeben. Die Aussage dieses Modells bleibt die gleiche: Der reale Wert setzt sich aus dem Modell und dem Fehler zusammen, den wir mit dem Modell machen.Annahme B0 und β0Bei der Nullhypothese nehmen wir , dass der vorgegebene Wert 10 oder B0 dem Populationsmittelwert β0 entspricht. anderen Worten, wir glauben bei der Nullhypothese, dass alle Studierenden (die Population) im Schnitt 10 Bücher pro Jahr lesen. βsteht daher immer für Kennwerte der Population. diesem Fall den Gruppenmittelwert der Population.","code":""},{"path":"statistische-modellierung.html","id":"statistisches-modell-der-alternativhypothese-das-erweiterte-modelle","chapter":"5 Statistische Modellierung","heading":"5.3.4.2 Statistisches Modell der Alternativhypothese: Das erweiterte Modelle","text":"Die Alternativhypothese besagt, dass Studierende mehr als 10 Bücher pro Jahr lesen. Wie viel mehr? Das sagt uns der Mittelwert der Stichprobe.Geschätzte Anzahl der Bücher auf Grundlage des erweiterten ModellsDas erweiterte Modell schätzt, dass jede Person 12.45 Bücher pro Jahr liest. 12.45, da dies der Mittelwert der Stichprobe der 30 Studierenden ist. Erneut ist dieses Modell natürlich nicht absolut genau, da manche Personen mehr oder weniger Bücher lesen. Genau deswegen sprechen wir von Y-Dach, um zu sagen, dass die abhängige Variable auf Grundlage des Modells geschätzt wird.Geschätzte Anzahl der Bücher auf Grundlage des erweiterten ModellsDieses Modell ist exakt gleich zum vorherigen Modell. Nur, diesem Fall sprechen wir von b0 und nicht von 12.45. Ein kleines b steht immer für Parameter, die wir auf Grundlage der Daten schätzen. unserem Fall ist der Parameter der Mittelwert der Stichprobe.Tatsächliche Anzahl der Bücher auf Grundlage des erweiterten ModellsDieses Modell gibt die tatsächliche Anzahl der Bücher , die jede Person pro Jahr gelesen hat. Du siehst, dass Y kein Dach mehr hat und dass wir einen Fehlerterm hinzugefügt haben (ei). Wir verwenden ein kleines e bei Fehlern, wenn wir die Fehler auf Grundlage unserer geschätzten und nicht der wahren Parameter verwenden. unserem Fall haben wir b0 geschätzt und verwenden daher ei.","code":""},{"path":"statistische-modellierung.html","id":"freiheitsgrade","chapter":"5 Statistische Modellierung","heading":"5.3.5 Freiheitsgrade","text":"dieser Stelle müssen wir einen neuen Begriff einführen. Den Begriff der Freiheitsgrade. Um zu verstehen, ein Freiheitsgrad ist, müssen wir zwei Feststellungen treffen:","code":""},{"path":"statistische-modellierung.html","id":"feststellung-jedes-modell-kann-so-viele-parameter-aufnehmen-wie-es-datenpunkte-gibt","chapter":"5 Statistische Modellierung","heading":"5.3.5.1 1. Feststellung: Jedes Modell kann so viele Parameter aufnehmen, wie es Datenpunkte gibt","text":"Ein Parameter ist ein Koeffizient einem statistischen Modell, welchen wir auf Grundlage der Daten schätzen und die Modelle integrieren. Zum Beispiel:Dieses Modell hat beispielsweise einen Parameter β0. Wir kürzen die Parameter des erweiterten Modells ab sofort mit PA ab. unserem Beispiel steht β0 für die Anzahl der Bücher, die die Population der Studierenden pro Jahr liest. Als Faustregel: Alle Koeffizenten, die entweder mit einem β oder einem kleinen b geschrieben werden, sind Parameter. Alle Koeffizienten, die mit einem großen B geschrieben werden, sind keine Parameter.Zum Vergleich: Das kompakte Modell, welches wir aus unserer Nullhypothese generiert haben, hat keine Parameter, da wir B0 nicht schätzen, sondern vorgegeben haben. Wir kürzen die Parameter des kompakten Modells ab sofort mit PC ab.Nun, da wir wissen Parameter sind, können wir zu unserer ersten Feststellung kommen: Es können nur viele Parameter ein Modell integriert werden, wie es Datenpunkte gibt. unserem Fall haben wir 30 Datenpunkt bzw. Personen den Daten. Das größtmöglichste Modell hätte daher maximal 30 Parameter. Warum? Da wir durch ein solches Modell die abhängige Variable perfekt vorhersagen könnten (wie das geht, besprechen wir dieser Stelle nicht; die Lösung wäre, indem wir eine Dummykodierung verwenden - siehe einfaktorielle Varianzanalyse).","code":""},{"path":"statistische-modellierung.html","id":"feststellung-wir-können-nur-so-viele-parameter-hinzufügen-bis-die-maximale-anzahl-an-parametern-ausgeschöpft-ist.","chapter":"5 Statistische Modellierung","heading":"5.3.5.2 2. Feststellung: Wir können nur so viele Parameter hinzufügen, bis die maximale Anzahl an Parametern ausgeschöpft ist.","text":"Stell dir dazu erneut unsere Modelle bei 30 Versuchspersonen vor:Erweitertes ModellDas Modell hat einen Parameter bei 30 Versuchspersonen. Das bedeutet, wir können noch 29 Parameter hinzufügen.Kompaktes ModellDas kompakte Modell hat keine Parameter bei 30 Versuchspersonen. Das bedeutet, wir können noch 30 Parameter hinzufügen.Wir haben gezeigt, dass das erweiterte Modell einen Parameter mehr hat als das kompakte Modell. Das wird im folgenden immer der Fall sein. Daher gilt:Das erweiterte Modell heißt erweitertes Modell, da es mehr Parameter hat als das kompakte Modell.Fassen wir dieses Ergebnis zusammen:Die Anzahl der Parameter, welche wir noch ein Modell integrieren können, nennen wir Freiheitsgrade. Freiheitsgrade sind daher immer abhängig von der Anzahl der Datenpunkte einem Datensatz.Nun können wir auflösen, die Zahl 29 unserem Output bedeutet. Die Zahl 29 steht innerhalb der Klammer des t-Wertes. Die Zahl steht für den Freiheitsgrad des erweiterten Modells. Bei einem t-Test berichten wir immer nur den Freiheitsgrad des erweiterten Modells. Später bei dem F-Test, werden wir zwei Freiheitgrade der Klammer berichten.“Um zu prüfen, ob Studierende pro Jahr mehr als 10 Bücher pro Jahr lesen, wurde ein t-Test für eine Stichprobe berechnet. Der t-Test ergab einen signifikanten Effekt, t(29) = 4.91, p < .001, d = 0.90 (großer Effekt), darauf hinweist, dass Studierende mehr als 10 Bücher pro Jahr lesen.”","code":""},{"path":"statistische-modellierung.html","id":"zusammenfassung-5","chapter":"5 Statistische Modellierung","heading":"5.3.6 Zusammenfassung","text":"Wir haben nun etabliert, welchen unterschiedlichen Formen statistische Modelle aufgeschrieben werden können. Wir haben gelernt, dass die Nullhypothese ein kompaktes Modell und die Alternativhypothese ein erweitertes Modell übersetzt wird. Das erweiterte Modell heißt , da es immer mehr Parameter hat als das kompakte Modell. Ebenso haben wir erfahren, dass der Begriff Freiheitsgrad angibt, wie viele Parameter noch ein Modell hinzufügt werden können. Im nächsten Submodul werden wir diese beiden Modelle visualisieren und man diesen Modellen unter Fehlern versteht.","code":""},{"path":"statistische-modellierung.html","id":"fehler-in-statistischen-modellen-sse_a-sse_c-ssr-und-pre","chapter":"5 Statistische Modellierung","heading":"5.4 Fehler in statistischen Modellen: SSE_A, SSE_C, SSR und PRE","text":"Wir haben im letzten Modul bereits angedeutet, dass unsere Modelle nicht perfekt sind. Wenn wir vorhersagen, dass alle Studierende 10 Bücher pro Jahr liest, werden wir selten richtig liegen. Manche werden mehr lesen, manche werden weniger lesen. Ebenso haben wir gelernt, dass jedes Modell der Formel DATA = MODEL + ERROR beschrieben werden kann. diesem Submodul werden wir uns genauer mit dem Begriff des ERRORs auseinandersetzen und lernen, dass wir die Fehler berechnen, indem wir die quadrierte Abweichung der Fehler berechnen.","code":""},{"path":"statistische-modellierung.html","id":"fehler-im-kompakten-modell","chapter":"5 Statistische Modellierung","heading":"5.4.1 Fehler im kompakten Modell","text":"Beginnen wir mit einer Visualisierung. der folgenden Visualisierung siehst du für alle Studierende, wie akkurat das kompakte Modell die Anzahl der gelesenen Bücher geschätzt hat. Für die Studentin mit der ID 2 beispielsweise hat das kompakte Modell 10 Bücher geschätzt, die Studentin hat aber Wirklichkeit 15 Bücher gelesen (siehe y-Achse).Die ID der Personen wird sowohl durch die x-Achse als auch durch die Zahl über jeder einzelnen Visualisierungen dargestellt.Das Problem mit einem solchen Fehlerterm ist allerdings, dass sich positive und negative Werte aufheben können. Stell dir vor, es gibt nur zwei Versuchspersonen. Der Fehler der ersten Person ist 10 und der Fehler der zweiten Person ist -10. Die Summe dieser beiden Fehler wäre 0. Dieser Art von Fehler ist daher nicht zufriedenstellend. Stattdessen werden wir die quadrierte Abweichung der geschätzten und der realen Werte berechnen. Grafisch können wir uns die quadrierte Abweichung wie folgt vorstellen:Du siehst anhand der Visualisierung, dass wir im kompakten Modell die Anzahl der gelesenen Bücher im Schnitt unterschätzen (das kompakte Modell liegt meist unter den realen Punkten). Bei Person 22 beispielsweise ist der quadrierte Fehler größten (das Quadrat ist größten). Für andere Personen schätzen wir die Anzahl der gelesenen Bücher hingegen perfekt. Person 27 beispielsweise liest 10 Bücher pro Jahr, genauso viele, wie wir vorhergesagt haben.SSECDie Fehler des kompakten Modells definieren wir daher als die Summe der quadrierten Abweichungen der realen Werte von den geschätzten Werten des kompakten Modells. Im Bilde der obigen Visualisierung gesprochen, summieren wir die Fläche der blauen Quadrate (der Fehler) auf.","code":""},{"path":"statistische-modellierung.html","id":"fehler-im-erweiterten-modell","chapter":"5 Statistische Modellierung","heading":"5.4.2 Fehler im erweiterten Modell","text":"Das Gegenstück der Fehler im kompakten Modell ist der Fehler im erweiterten Modell. Erinnere dich, dass das erweiterte Modell vorhergesagt hat, dass jede studierende Person jeweils 12.45 Bücher pro Jahr liest. Im unteren Bild haben wir dieses Modell als orangene Linie dargestellt. Die real gelesenen Bücher pro Person sind als orangener Punkt dargestellt. Die orangenen Flächen kennzeichnen die quadrierten Fehler für jede Person:Wie du siehst, macht auch das erweiterte Modell Fehler. Die Berechnung der Fehler des erweiterten Modells ist ähnlich zur der Berechnung der Fehler des kompakten Modells:SSEADie Fehler des erweiterten Modells definieren wir daher als die Summe der quadrierten Abweichungen der realen Werte von den geschätzten Werten des erweiterten Modells. Im Bilde der obigen Visualisierung gesprochen,summieren wir die Fläche der orangenen Quadrate (der Fehler) auf.","code":""},{"path":"statistische-modellierung.html","id":"ssr-reduktion-des-fehlers","chapter":"5 Statistische Modellierung","heading":"5.4.3 SSR: Reduktion des Fehlers","text":"Legen wir nun beide Fehler übereinander und vergleichen diese miteinander. Uns fällt auf, dass das kompakte Modell größere Fehler macht als das erweiterte Modell. Beispielsweise ist der Fehler im kompakten Modell bei Person 2, 7, 9, 12 und 14 größer als im erweiterten Modell (die blauen Quadrate sind größer als die orangenen Quadrate)Tatsächlich wird der Fehler im kompakten Modell immer größer sein als der Fehler im erweiterten Modell. Dies liegt daran, dass wir mit mehr Parametern immer eine bessere Vorhersage der abhängigen Variable treffen können. Da das erweiterte Modell immer mehr Parameter hat als das kompakte Modell, werden die Fehler des erweiterten Modells immer kleiner sein als die Fehler des kompakten Modells.Wir können daher einen neuen Term etablieren: SSR. SSR gibt , welcher Anteil der Fehler des kompakten Modells durch das erweiterte Modell aufgeklärt wurde:SSR berechnet sich aus der Differenz zwischen den Fehlern des kompakten Modells und den Fehlern des erweiterten Modells. SSEC steht immer vor SSEA, da SSEC immer größer ist als SSEA.Je größer SSR ist, desto genauer bildet das erweiterte Modell die echten Daten ab, oder, desto besser kann das erweiterte Modell die Daten im Vergleich zum kompakten Modell vorhersagen. Beachte allerdings, dass bei gleichem SSR ein erweitertetes Modell mit wenigen Parametern beeindruckender ist als ein erweitertes Modell mit vielen Parametern. Wir wissen, das mehr Parameter zu einer besseren Vorhersage der abhängigen Variable führen. Wenn also ein Modell mit einem weiteren Parameter die Fehler gleich stark reduziert wie ein Modell mit fünf weiteren Parametern, werden wir das erweiterte Modell mit weniger Parametern bevorzugen, da es einfacher ist als das komplexere Modell.","code":""},{"path":"statistische-modellierung.html","id":"pre-proportional-reduction-in-error","chapter":"5 Statistische Modellierung","heading":"5.4.4 PRE (Proportional Reduction in Error)","text":"Als nächstes lernen wir den Begriff PRE kennen, welcher uns im Verlaufe des Seminars anderen Worten immer wieder über den Weg laufen wird. PRE steht für Proportional Reduction Error und ist ein Maß, welches angibt, wie viel Prozent der Fehler des kompakten Modells durch das erweiterte Modell aufgeklärt werden. Beispielsweise könnte PRE den Wert .80 annehmen. Dieser Wert würde bedeutet, dass das erweiterte Modell 80% der Fehler des kompakten Modells reduziert. Berechnet wird PRE wie folgt:PRE berechnet sich aus dem Quotienten aus SSR und SSEC. anderen Worten standardisieren wir die Fehler, des erweiterten Modell durch die Fehler des kompakten Modells.Zwei Dinge sind bei der Berechnung von PRE wichtig. Erstens, wir müssen SSEA von SSEC abziehen und nicht umgekehrt, da wir wissen, dass der Fehler des erweiterten Modells immer kleiner ist als der Fehler des kompakten Modells (da das erweiterte Modell mehr Parameter als das kompakte Modell hat), ansonsten würden wir einen negativen Wert erhalten. Zweitens teilen wir das Resultat aus der Subtraktion von SSEA − SSEC durch SSEC, um ein relatives Maß zu erhalten. Relativ abhängig vom kompakten Modell. PRE kann Werte zwischen 0 und 1 annehmen. 1 würde bedeuten, dass das erweiterte Modell alle Fehler des kompakten Modells erklärt. Nicht jedes PRE ist jedoch gleich beeindruckend. Nehmen wir , du erhältst ein PRE von .02. Das erweiterte Modell hat fünf Parameter mehr als das kompakte Modell. Welches Modell ist nun besser? Wir gehen davon aus, dass das Modell, welches mit den wenigsten Parametern ähnliche Ergebnisse erzielt und daher sparsamer ist, besser ist. Aus diesem Grund würden wir diesem Beispiel sagen, dass das kompakte Modell besser ist, schließlich hat es deutlich weniger Parameter als das erweitertes Modell und wir erhalten ein geringes PRE. Nur, ab welchem Wert ist PRE groß genug oder klein genug? Dies hängt von mehreren Faktoren ab. Wenn PRE substantiell durch nur einen Parameter reduziert wird, ist dies besser, als wenn PRE durch mehrere Parameter reduziert wird. Schließlich suchen wir sparsame Modelle mit wenigen Parametern.","code":""},{"path":"statistische-modellierung.html","id":"tabellarische-darstellung-der-ergebnisse","chapter":"5 Statistische Modellierung","heading":"5.4.5 Tabellarische Darstellung der Ergebnisse","text":"Fassen wir zum Schluss dieses Submoduls unsere Ergebnisse zusammen. Ich habe die Werte für dich berechnet. der ersten Spalte stehen die drei verschiedenen Arten von Fehlern. SSR steht für die Fehler des kompakten Modells, welche durch das erweiterte Modell reduziert werden. Ebenso gibt es die Fehler, die das erweiterte Modell noch macht, SSEA. Zum Schluss, die Fehler, die das kompakte Modell macht. Zudem haben wir einen Freiheitsgrad, der sich aus PA - PC berechnet. Dieser Wert gibt , wie viele Parameter das erweiterte Modell mehr hat als das kompakte Modell. PRE beläuft sich bei unserem Beispiel auf 0.45. Das heißt, das erweiterte Modell klärt 45% der Fehler im kompakten Modell auf.","code":""},{"path":"statistische-modellierung.html","id":"zusammenfassung-6","chapter":"5 Statistische Modellierung","heading":"5.5 Zusammenfassung","text":"diesem Submodul haben wir die Begriffe SSEC, SSEA, SSR und PRE etabliert. Fortan bezeichnen wir mit diesen Begriffen die Fehler, welche das kompakte und das erweiterte Modell machen. Mit SSR bezeichnen wir die Reduzierung der Fehler des kompakten Modells durch das erweiterte Modell.","code":""},{"path":"statistische-modellierung.html","id":"f-wert-und-f-verteilungen","chapter":"5 Statistische Modellierung","heading":"5.6 F-Wert und F-Verteilungen","text":"Im letzten Modul haben wir verschiedene Fehler des kompakten und erweiterten Modells kennen gelernt. unserem Prozess des statistischen Hypothesentestens müssen wir als nächstes einen Kennwert aus diesen Modellen berechnen. Wir werden fortan F- und t-Werte für unsere Hypothesen berechnen und sehen, dass beide äquivalent zueinander sind. diesem Submodul werden unsere bisherige Bücherhypothese anhand der F-Verteilung prüfen. Das heißt, wir vollziehen den kompletten Prozess des statistischen Hypothesentestens und treffen eine statistische Entscheidung für oder gegen die Nullhypothese.","code":""},{"path":"statistische-modellierung.html","id":"die-größe-der-fehler-abhängig-der-parameter-des-modells","chapter":"5 Statistische Modellierung","heading":"5.6.1 Die Größe der Fehler abhängig der Parameter des Modells","text":"Bisher haben wir die quadrierten Fehler des kompakten Modells (SSEC) und die quadrierten Fehler des erweiterten Modells (SSEA) beschrieben. Zudem haben wir SSR als ein Maß definiert, welches angibt, wie viel Fehler des kompakten Modells durch das erweiterte Modell aufgeklärt werden. Versuchen wir ein Gedankenexperiment. Stell dir vor, dein erweitertes Modell hat fünf Parameter mehr als das kompakte Modell und es reduziert die Fehler des kompakten Modells um den Wert 30. Stell dir ebenso ein erweitertes Modell mit nur einem weiteren Parameter als das kompakte Modell vor und stell dir vor, dass dieses Modell ebenso die Fehler des kompakten Modells um den Wert 30 reduziert. Welches Modell würden wir bevorzugen? Das sparsamere Modell mit nur einem Parameter mehr. Dieser eine Parameter ermöglicht eine deutlich bessere Vorhersage als das Modell mit den fünf weiteren Parametern. Wie beeindruckend die Fehlerreduktion ist hängt daher von der Anzahl der Parameter ab, die das erweiterte Modell zusätzlich hat.Aus diesem Grund ist es sinnvoll, SSR nach der Anzahl der Parameter zu standardisieren. Diesen Fehlerterm nennen wir MSR:MSR gibt , wie viele Fehler die zusätzlichen Parameter des erweiterten Modells im Schnitt von den Fehlern des kompakten Modells aufklären. Bei nur einem SSR von 30 beispielsweise und nur einem Parameter beläuft sich MSR auf 30. Bei fünf weiteren Parametern auf 30/5 = 6. Die durchschnittliche Fehlerreduktion bei dem erweiterten Modell mit nur einem weiteren Parameter ist daher größer als mit dem erweiterte Modell mit fünf weiteren Parametern.unserer Bücherstudie belief sich SSR auf 180.63. Das erweiterte Modell hatte einen Parameter mehr als das kompakte Modell (1). Das heißt, dieser weitere Parameter klärte den Wert 180.63 der Fehler im kompakten Modell auf.MSR sagt uns also, wie viele Fehler die zusätzlichen Parameter im Durchschnitt reduzieren. Wir haben allerdings noch die restlichen Fehler des erweiterten Modells (SSEA). Auch diesen Fehler können wir standarisieren. Wir tun dies, indem wir SSEA durch die Anzahl der Parameter teilen, die wir noch das erweiterte Modell hinzufügen können.MSE gibt uns folgende Aussage: Wie viele Fehler klären die restlichen Parameter, die wir noch das erweiterte Modell hinzufügen können, durchschnittlich auf?Unser bisheriges erweitertes Modell hatte noch 29 Parameter, die wir das Modell hinzufügen können. SSEA belief sich auf 217.38. MSE läge daher bei 7.5. Das heißt, bei einem willkürlichen weiteren Parameter würden wir erwarten, dass dieser den Wert 7.5 der Fehler im kompakten Modell aufklärt.","code":""},{"path":"statistische-modellierung.html","id":"der-f-wert","chapter":"5 Statistische Modellierung","heading":"5.6.2 Der F-Wert","text":"Nun kommen wir zu unserem eigentlichen Kennwert, dem F-Wert. Der F-Wert hat folgende Definition:Definition F-Wert:Wie viel besser klären die zusätzlichen Parameter des erweiterten Modells die Fehler des kompakten Modells auf als willkürliche Parameter, die noch das erweiterte Modell hinzugefügt werden können.Lass uns diese Definition Stück für Stück aufschlüsseln. Zunächst müssen wir uns die Formel des F-Wertes ansehen:Umfangreiche Formel für FIn unserem Beispiel klärt der zusätzliche Parameter des erweiterten Modells die Fehler des kompakten Modells 24 mal besser auf als willkürliche Parameter. Das heißt, der Parameter ermöglicht eine deutlich bessere Vorhersage als wir für irgendeinen Parameter erwarten würden.Der F-Wert ergibt sich aus dem Quotienten von MSR und MSE. anderen Worten, wie gut ist dieser Parameter im Vergleich zu anderen willkürlichen Parametern? Ein Wert über eins sagt uns, dass dieser Parameter mehr Fehler aufklären als willkürliche Parameter. Ein Wert geringer als 1 sagt uns, dass diese Parameter weniger Fehler aufklären als willkürliche Parameter.Zusammengefasst können wir die Ergebnisse einer Tabelle festhalten:","code":""},{"path":"statistische-modellierung.html","id":"f-verteilung","chapter":"5 Statistische Modellierung","heading":"5.6.3 F-Verteilung","text":"Um diesen Wert von einer anderen Sichtweise zu verstehen, lass uns zurück zu unserer Hypothese gehen. Unsere Nullhypothese besagt, dass Studierende im Schnitt 10 Bücher pro Jahr lesen. Versuchen wir dieser Stelle eine Simulation. Stell dir vor, es gibt wirklich keinen Effekt und Studierende lesen 10 Bücher pro Jahr. Dein erweitertes Modell würde diesem Fall den meisten Fällen b0 um die 10 bestimmen (ungefähr der Mittelwert der Population). diesem Fall wäre dein erweitertes Modell fast identisch mit dem kompakten Modell. Das erweiterte Modell sollte von daher die Fehler des kompakten Modells nicht viel besser aufklären können als das kompakte Modell. jedem Fall wird es die Fehler besser aufklären können, da das erweiterte Modell einen Parameter mehr hat als das kompakte Modell. Wir würden allerdings keinen großen F-Wert erwarten. Aus folgendem Grund: Der F-Wert kann auch folgendermaßen verstanden werden: Wie ist das Verhältnis zwischen den Fehlern, die das erweiterte Modell aufklären konnte und den Fehlern, die noch bleiben? Da beide Modelle unserem Gedankenspiel fast identisch sind, sollte dieses Verhältnis gering sein. Das erweiterte Modell wird, da es fast identisch ist, die Fehler des kompakten Modells nicht deutlich aufklären. Und genau das zeigt sich, wenn wir F-Werte simulieren.Bleiben wir bei der Idee, dass es keinen Effekt gibt: Wir wiederholen die gleiche Studie (wir befragen 30 Studierende danach, wie viel Bücher sie pro Jahr lesen) unterschiedlich oft. 10 mal, 100 mal, 1000 mal und 10000 mal. Jedes Mal berechnen wir den F-Wert. Folgende Verteilungen ergeben sich daraus:Du siehst, dass wir mit steigender Anzahl Studierenden eine rechtschiefe Verteilung erhalten. Diese Verteilung nennen wir F-Verteilung. Die F-Verteilung zeigt uns , wie das Verhältnis zwischen den aufgeklärten Fehlern und den übrigen Fehlern im kompakten Modell wäre, sollte die Nullhypothese stimmen. Du siehst der Verteilung, dass wir der Regel Werte zwischen 0 und 1 erwarten würden. Das heißt, der zusätzliche Parameter im erweiterten Modell sollte meist nicht besser sein als ein Parameter, der keinen Beitrag zur Fehleraufklärung leistet. Ganz selten erhalten wir F-Wete größer als 4 oder 5. anderen Worten, F-Werte über 5 sind sehr ungewöhnlich, die Parameter leisten einen besseren Beitrag zur Fehlerreduktion als wir erwarten würden.","code":""},{"path":"statistische-modellierung.html","id":"beispiele-f-verteilungen","chapter":"5 Statistische Modellierung","heading":"5.6.4 Beispiele F-Verteilungen","text":"Ganz ähnlich zu der t-Verteilung gibt es unterschiedliche F-Verteilungen. Wie die F-Verteilung aussieht, hängt mit den beiden Freiheitsgraden des kompakten und des erweiterten Modells zusammen. der nächsten Visualisierung siehst du beispielsweise drei verschiedene F-Verteilungen, welche sich ihren Freiheitsgraden unterscheiden:Wie du siehst, sind alle Verteilungen rechtsschief, das heißt, F-Werte über 4 sind der Regel sehr selten. Wie diese F-Verteilungen aussehen, ist für diesen Kurs nicht wichtig, entscheidend ist allerdings, dass du verstehst, dass diese F-Verteilungen eine Stichprobenkennwertverteilung darstellen, anhand derer wir die Wahrscheinlichkeit des F-Wertes unter Annahme der Nullhypothese testen können.","code":""},{"path":"statistische-modellierung.html","id":"ermittlung-von-pdh0-auf-grundlage-von-f","chapter":"5 Statistische Modellierung","heading":"5.6.5 Ermittlung von P(D|H0) auf Grundlage von F","text":"Wir haben nun unseren Kennwert F. Als nächstes müssen wir uns fragen, wie wahrscheinlich dieser F-Wert unter Annahme der Nullhypothese (10 Bücher pro Jahr) ist. Unser F-Wert beträgt 24.01.Wenn wir nun unseren empirischen F-Wert der F-Verteilung abtragen, sehen wir, dass ein solcher F-Wert unter der Annahme der Nullhypothese äußerst unwahrscheinlich ist. Wir sprechen daher von einem signifikanten Ereignis und lehnen die Nullhypothese ab.Die Wahrscheinlichkeit für einen solchen Kennwert ist verschwindent gering. Erinnere dich daran, dass wir die Wahrscheinlichkeit als die Fläche unter dem Kennwert und größer als dem Kennwert berechnet haben. unserem Fall ist diese Wahrscheinlichkeit deutlich unter 1%. Der p-Wert ist daher < .001. Auf Grundlage dieses Ergebnisses lehnen wir daher die Annahme ab, dass Studierende 10 Bücher pro Jahr lesen. Vermutlich lesen sie mehr.dieser Stelle führen wir einen weiteren neuen Begriff ein: Eta-Quadrat (η2). Eta-Quadrat ist ein Effektstärkenmaß und ist identisch mit PRE:unserem Fall belief sich PRE auf 0.45. Das heißt, das erweiterte Modell war der Lage, 45% der Fehler im kompaten Modell aufzuklären.","code":""},{"path":"statistische-modellierung.html","id":"tabellarische-darstellung-der-ergebnisse-1","chapter":"5 Statistische Modellierung","heading":"5.6.6 Tabellarische Darstellung der Ergebnisse","text":"Wir sind damit das Ende unseres Tests gekommen. Begonnen haben wir mit der Frage, ob Studierende mehr als 10 Bücher pro Jahr lesen. Mit Hilfe der statistischen Modellierung haben wir den F-Wert berechnet und sind zu dem Schluss gekommen, dass der Kennwert unter der Nullhypothese sehr unwahrscheinlich und damit signifikant ist. Wir verwerfen daher die Nullhypothese und gehen davon aus, dass Studierende mehr als 10 Bücher pro Jahr lesen. Fassen wir die Ergebnisse einer Tabelle zusammen:","code":""},{"path":"statistische-modellierung.html","id":"zusammenfassung-7","chapter":"5 Statistische Modellierung","heading":"5.6.7 Zusammenfassung","text":"Wir haben diesem Submodul den F-Wert und die F-Verteilung kennen gelernt. Fortan werden wir für alle Hypothesen einen F-Test rechnen und die gleichen Berechnungen mit ein paar Unterschieden ausführen. Den F-Wert haben wir diesem Submodul als einen Wert kennen gelernt, der das Verhältnis zwischen den aufklärten Fehlern durch die weiteren Parameter und den restlichen Fehlern des kompakten Modells angibt. Hohe F-Werte sind unter der Annahme der Nullhypothese unwahrscheinlich. F-Werte unter 1 bedeuten, dass die zusätzlichen Parameter nicht viel besser sind als willkürliche Parameter, die keinen wesentlichen Beitrag zur Fehlerreduzierung leisten. Im nächsten Submodul werden wir zeigen, dass der F-Wert und der t-Wert äquivalent sind.","code":""},{"path":"statistische-modellierung.html","id":"äquivalenz-f-und-t","chapter":"5 Statistische Modellierung","heading":"5.7 Äquivalenz F und t","text":"diesem Submodul werden wir zeigen, dass der F- und der t-Wert äquivalent sind. Genauer werden wir zeigen, dass der t-Wert die Wurzel aus dem F-Wert ist. Für uns bedeutet dies, dass wir herkömmliche t-Tests immer als F-Tests darstellen können und damit den Prozess des statistischen Hypothesentestens, welchen wir diesem Modul kennen gelernt haben, auch für Fragestellungen verwenden können, die herkömmlicherweise durch einen t-Test gelöst werden. Ebenso werden wir zeigen, wie man einen F-Test berichtet.","code":""},{"path":"statistische-modellierung.html","id":"ergebnis-des-bisherigen-t-tests-für-eine-stichprobe","chapter":"5 Statistische Modellierung","heading":"5.7.1 Ergebnis des bisherigen t-Tests für eine Stichprobe","text":"Beginnen wir dazu mit dem Ergebnis des t-Tests für eine Stichprobe, welchen wir im vorherigen Modul berechnet haben:“Um zu prüfen, ob Studierende pro Jahr mehr als 10 Bücher pro Jahr lesen, wurde ein t-Test für eine Stichprobe berechnet. Der t-Test ergab einen signifikanten Effekt, t(29) = 4.91, p < .001, d = 0.90 (großer Effekt), darauf hinweist, dass Studierende mehr als 10 Bücher pro Jahr lesen.”Würden wir die gleiche Hypothese Jamovi rechnen, bekämen wir folgendes Ergebnis:Bei dem Bericht des Ergebnisses haben wir demnach die Informationen aus Jamovi einer bestimmten Schreibweise übertragen. Genauer haben wir den t-Test folgendermaßen berichtet:Zunächst schreiben wir ein t und Klammern die restlichen Parameter, die das erweiterte Modell noch aufnehmen kann (df2). Anschließend schreiben wir die Wahrscheinlichkeit für diesen t-Wert unter der Nullhypothese auf (PWERT). Dann berichten wir die Effektgröße Cohen’s d (DWERT). Zudem werden sowohl der Buchstabe t, p als auch d kursiv geschrieben.Du siehst demnach, dass wir damals bei dem t-Test für eine Stichprobe bereits Informationen verwendet haben, die wir diesem Modul gelernt haben. Genauer berichten wir bei dem t-Test immer die Freiheitsgrade des erweiterten Modells, das heißt die Anzahl der Parameter, die das erweiterte Modell noch aufnehmen kann. Zudem ist der t-Wert mit dem F-Wert verwandt.","code":""},{"path":"statistische-modellierung.html","id":"t-ist-die-wurzel-aus-f","chapter":"5 Statistische Modellierung","heading":"5.7.2 t ist die Wurzel aus F","text":"Unser F-Test aus dem letzten Submodul hat folgende Ergebnisse erbracht. Zusätzlich habe ich der Tabelle den t-Wert und die Effektgröße Cohen’s d hinzugefügt. Ich deine Aufmerksamkeit auf die Spalten F und t lenken.Der F-Wert ist 24.1 und der t-Wert ist 4.91. Der t-Wert ist demnach nichts anderes als die Wurzel aus dem F-Wert. Wir haben damit gezeigt, dass F und t direkt miteinander verwandt sind.Ob wir nun einen F-Test oder einen t-Test berechnen, macht für die Ergebnisse keinen Unterschied. Außer mit einer kleinen Ausnahme, zu der wir jetzt zu sprechen kommen.","code":""},{"path":"statistische-modellierung.html","id":"der-f-test-testet-ungerichtet","chapter":"5 Statistische Modellierung","heading":"5.7.3 Der F-Test testet ungerichtet","text":"Hypothesen können entweder gerichtet oder ungerichtet getestet werden. Unsere Bücherhypothese war gerichtet, das heißt wir nahmen , dass Studierende mehr als 10 Bücher pro Jahr lesen. Stellen wir uns ausnahmsweise vor, der empirische t-Wert lag bei dem Wert 2:Die Wahrscheinlichkeit für ein t-Wert größer als 2 liegt bei 5.69%. Allerdings bei einer gerichteten Hypothese. Hätten wir ungerichtet getestet und wäre der empirische t-Wert bei 2, müssten wir auch die andere Annahme hinzufügen, dass Studierende weniger als 10 Bücher pro Jahr lesen:diesem Fall läge die Wahrscheinlichkeit für P(D|H0) bei 5.69 * 2 = 11.38%. Während wir nun bei einem t-Test gerichtet als auch ungerichtet testen können, testet der F-Test immer nur ungerichtet. Das heißt, der p-Wert, welchen wir durch unseren F-Test erhalten haben, gibt uns , wie wahrscheinlich es ist, dass Studierende mehr oder weniger als 10 Bücher pro Jahr lesen, sollte es stimmen, dass Studierende im Schnitt nur 10 Bücher pro Jahr lesen. Wir können den p-Wert bei einem F-Test teilen, wenn folgende Bedingung vorherrscht:Der Mittelwert der Stichprobe ist größer als der angenommene Mittelwert. Da der Mittelwert der Stichprobe bei 12.45 lag und wir einen Mittelwert von 10 angenommen haben, dürfen wir den p-Wert teilen. Achte daher bei jedem F-Test darauf, ob du eine gerichtete oder ungerichtete Hypothese testest. F-Tests berichten dir Jamovi und SPSS immer ungerichtete Hypothesen. Es ist allerdings legitim, bei einer gerichteten Hypothese unter bestimmten Bedinungen den p-Wert bei einem F-Test zu teilen.","code":""},{"path":"statistische-modellierung.html","id":"f-tests-berichten","chapter":"5 Statistische Modellierung","heading":"5.7.4 F-Tests berichten","text":"Zuletzt wollen wir noch lernen, wie der F-Test Fachartikeln berichtet wird. Formulieren wir dazu ein Beispiel für unseren Test aus:“Um zu prüfen, ob Studierende pro Jahr mehr als 10 Bücher pro Jahr lesen, wurde ein t-Test für eine Stichprobe berechnet. Der F-Test ergab einen signifikanten Effekt, F(1, 29) = 24.1, p < .001, d = 0.89 (großer Effekt), darauf hinweist, dass Studierende mehr als 10 Bücher pro Jahr lesen.”Avani SadanaDu siehst, dass wir bei einem F-Test sowohl den Unterschied den Parametern des kompakten und des erweiterten Modells angeben als auch den Freiheitsgrad des erweiterten Modells angeben. Allgemein können wir die Schreibweise wie folgt darstellen:","code":""},{"path":"statistische-modellierung.html","id":"zusammenfassung-8","chapter":"5 Statistische Modellierung","heading":"5.7.5 Zusammenfassung","text":"diesem Submodul haben wir gezeigt, dass wir für jeden t-Test auch einen F-Test rechnen können und dass beide Kennwerte miteinander verwandt sind. Genauer haben wir festgestellt, dass der t-Wert die Wurzel des F-Wertes ist. Wir können daher jeden t-Test eine F-Test übersetzen. Fortan werden wir allerdings hauptsächlich F-Tests zur Überprüfung von Hypothesen verwenden.","code":""},{"path":"statistische-modellierung.html","id":"notation-statistische-modelle","chapter":"5 Statistische Modellierung","heading":"5.8 Notation statistische Modelle","text":"Dieses Submodul fasst die wesentlichen Notationen der statistischen Modelle zusammen. Verwende diese Seite als Nachschlagewerk, wenn wir den nächsten Wochen immer statistische Modellpaare aufstellen.Steht für den Einzelwert von DATA, den Werten, welche wir vorhersagen, beziehungsweise den Werte unserer abhängigen Variable. Das kleine steht für das Untersuchungsobjekt, welches wir gerade betrachten. der Regel sind das einzelne Menschen beziehungsweise Probanden.Steht für unseren auf Grundlage des Modells vorhergesagten Werte. Der reale Wert setzt sich aus der Schätzung und dem Fehler zusammen.Steht für die Variablen, welche wir unser Modell hinzufügen. steht für das Untersuchungsobjekt, j steht für die Nummer der Variable (wir werden später mehrere dieser Variablen unseren Modellen haben).Steht für die Parameter unseres Modells, welche wir finden möchten. Wir werden diese Werte allerdings nie exakt bestimmen können, da wir nie Daten von ganzen Populationen haben. Als Faustregel gilt: Sobald ein Epsilon der Gleichung enthalten ist, spricht man von Parametern, die der Population gelten.Stehen für die Parameter, welche man auf Grundlage der Stichproben berechnet. Beispielsweise schätzt man den Mittelwert der Population auf Grundlage des Mittelwerts einer Stichprobe.Steht für keinen Parameter, sondern für einen Koeffizienten einem Modell, den wir -priori annehmen. Zum Beispiel, dass Studierende im Schnitt 10 Bücher pro Jahr lesen.Stehen für die Fehler, die wir aus dem Modell berechnen. e wird also immer im Zusammenhang mit b verwendet und nie mit β und wird immer im Zusammenhang mit Stichproben verwendet.Steht für den Fehler, der sich ergibt, wenn man βi kennt. Da sich βi von bi unterscheidet, unterscheidet sich auch e von ɛ . ɛ wird immer verwendet, wenn wir von der Population sprechen.Mittelwert der Population Mittelwert der StichprobeStandardabweichung der PopulationStandardabweichung der Stichprobe ","code":""},{"path":"statistische-modellierung.html","id":"berechnung-in-jamovi","chapter":"5 Statistische Modellierung","heading":"5.9 Berechnung in Jamovi","text":"diesem Submodul zeige ich dir, wie du einen t-Test für eine Stichprobe Jamovi und R berechnen kannst. Den Datensatz findest du hier:TODO: Einfügen Dokument books.csvTODO: Einfügen Video","code":""},{"path":"statistische-modellierung.html","id":"konfidenzintervalle","chapter":"5 Statistische Modellierung","heading":"5.10 Konfidenzintervalle","text":"TODO: Das Kapitel war vorher schon drin, soll das bleiben?anhand der Parameter erklären und sie bedeutenhttps://thenewstatistics.com/itns/2020/07/04/3-easy-ways--obtain-cohens-d---ci/http://www.tqmp.org/RegularArticles/vol14-4/p242/p242.pdf","code":""},{"path":"einfache-lineare-regression.html","id":"einfache-lineare-regression","chapter":"6 Einfache lineare Regression","heading":"6 Einfache lineare Regression","text":"","code":""},{"path":"einfache-lineare-regression.html","id":"einführung-4","chapter":"6 Einfache lineare Regression","heading":"6.1 Einführung","text":"diesem Modul beschäftigen wir uns mit der Frage, wie wir Zusammenhangshypothesen testen können. Genauer werden wir diesem Modul folgende Fragestellung zu beantworten versuchen:Erinnern sich Studierende mehr die Inhalte eines Vortrages, je mehr Worte sie während des Vortrags mitschreiben?Solche eine Zusammenhangshypothese können wir anhand eines erweiterten Modells testen, dass wir gemeinhin als einfache lineare Regression bezeichnen. Eine Besonderheit dieser Modelle zum bisherigen Modell des t-Tests für eine Stichprobe ist, dass dieses Modell einen Prädiktor umfasst. Prädiktoren sind Variablen, die wir die statistischen Modelle einfügen und uns individuelle Informationen über Versuchspersonengeben. unserem Beispiel ist der Prädiktor die Anzahl der Wörter, die Studierende ihren Notizen während der Vorlesung aufschreiben. Der restliche Verlauf des statistischen Hypothesentestens bleibt , wie wir es den letzten beiden Modulen kennen gelernt haben.","code":""},{"path":"einfache-lineare-regression.html","id":"datensatz-dieses-moduls","chapter":"6 Einfache lineare Regression","heading":"6.1.1 Datensatz dieses Moduls","text":"Wir werden diesem Modul einen echten Datensatz verwenden, der der Studie von Morehead, Dunlosky und Rawson (2014) erhoben wurde. dieser Studie wiederholten Morehead und Kollegen eine Studie, die ursprünglich von Mueller und Oppenheimer (2014) durchgeführt wurde. beiden Studien wurde untersucht, ob die Mitschrift einer Vorlesung mit verschiedenen Medien einen Einfluss auf die Erinnerungsleistung von Studierenden hat. Mueller und Oppenheimer führten die erste Studie durch und fanden, dass Studierende, die Notizen mit dem Laptop anfertigten, ein geringeres konzeptuelles Wissen erwarben als Studierende, die die Mitschrift per Hand anfertigten. Ebenso schrieben Studierende, die per Laptop mitschrieben, mehr wörtliche Zitate aus der Vorlesung auf als Studierende, die per Hand mitschrieben. Morehead und Kollegen wollten diese Hypothese genauer prüfen und führten eine Replikation dieser Studie durch. dieser Studie prüften sie die Studierenden nicht nur direkt nachdem sie die Notizen aufschrieben, sie testeten die Studierenden ebenso zwei Tage später, um zu testen, ob der Effekte des Schreibmediums von Dauer ist. Ebenso liesen sie Studierende mit einem digitalen Medium (eWriter) schreiben, welches Mueller und Oppenheimer nicht prüften. Ihre Ergebnisse zeigten, dass das Medium keinen Einfluss auf die Erinnerungsleistung der Studierenden hatte. Damit stellten sie die von Mueller und Oppenheimer gefunden Ergebnisse Frage und erweiterten die Diskussion um den Einfluss von Schreibmedien auf das Lernen.","code":""},{"path":"einfache-lineare-regression.html","id":"hypothese-und-datensatz-dieses-moduls","chapter":"6 Einfache lineare Regression","heading":"6.1.2 Hypothese und Datensatz dieses Moduls","text":"Wir werden diesem Modul die Daten der Studie von Morehead und Kollegen verwenden, um heraus zu finden, ob Studierende mehr aus einer Vorlesung lernen, je mehr sie während der Vorlesung mitschreiben. Morehead und Kollegen haben die Ergebnisse ihrer Studie online auf der Plattform OSF zur Verfügung gestellt. diesem Datensatz gibt es zwei Variablen, die wir für dieses Modul verwenden werden:wordcount: Die Anzahl der Wörter der Mitschrift der Studierenden.wordcount: Die Anzahl der Wörter der Mitschrift der Studierenden.test1tot: Prozentueller Anteil der korrekten Fragen des Tests direkt nach dem Aufschreiben der Notizen.test1tot: Prozentueller Anteil der korrekten Fragen des Tests direkt nach dem Aufschreiben der Notizen.Den folgenden Datensatz habe ich für unsere Zwecke aus dem originalen Datensatz von Morehead und Kollegen ein wenig gereinigt. Beispielsweise umfasst der Datensatz nur die Daten des ersten Experiments von Morehead und Kollegen. Ebenso umfasst der Datensatz nur Versuchspersonen, die Notizen während des Betrachtens der Vorlesungen angefertigt haben und Versuchspersonen, die sowohl den sofortigen als auch den Tests zwei Tage nach dem Experiment durchführten. Insgesamt gibt es 84 Versuchspersonenin dem Datensatz. Lade dir den Datensatz besten direkt herunter. Wir werden später Jamovi die Ergebnisse unserer Tests mit diesem Datensatz berechnen.TODO: Einfügen Datei morehead_experiment1.csvDer Datensatz umfasst zudem sehr viele Variablen. Wenn du einen Überblick haben möchtest (ich erwarte das nicht von dir diesem Modul), schau dir folgende Datei mit den Variablen im Detail .TODO: Einfügen Doc variablen.docxIm folgenden Modul werden wir die Fragestellung ausführlich testen und die uns bekannten Methoden verwenden, um diese Hypothese zu testen.","code":""},{"path":"einfache-lineare-regression.html","id":"das-statistische-modell-der-einfachen-linearen-regression","chapter":"6 Einfache lineare Regression","heading":"6.2 Das statistische Modell der einfachen linearen Regression","text":"","code":""},{"path":"einfache-lineare-regression.html","id":"darstellung-der-regressionsgeraden-der-einfachen-linearen-regression","chapter":"6 Einfache lineare Regression","heading":"6.2.1 Darstellung der Regressionsgeraden der einfachen linearen Regression","text":"Beginnen wir mit einem Streudiagram. folgendem Bild siehst du ein Streudiagram, bei dem auf der x-Achse die Anzahl der Wörter abgetragen sind, die die Studierenden der Vorlesung mitgeschrieben haben und bei der auf der y-Achse die Anzahl der Punkte im Test direkt nach der Mitschrift der Vorlesung dargestellt sind.Wie würdest du den Zusammenhang dieser beiden Variablen beschreiben? Ich erkenne beispielsweise einen leichten Trend, dass Studierende, die mehr schreiben, besser im Test abschneiden. Ich erkenne diesen Trend, da es wenige Studierende gibt, die viel schreiben und schlecht im Test abschneiden. Es gibt hingegen deutlich mehr Studierende, die wenig mitschreiben und wenig Punkte im Test hatten. Eine Möglichkeit, diesen Zusammenhang mathematisch zu beschreiben, ist die Regressionsgerade. Diese sieht unserem Fall aus:Die Regressionsgerade stellt grafisch dar, wir gerade sprachlich versucht haben zu beschreiben. Sie beschreibt den Zusammenhang zweier Variablen x und y. diesem Fall ist die Steigung der Geraden positiv. Die Regressionsgerade zeigt damit , dass Studierende besser im Test abschnitten, je mehr Wörter sie mitschreiben. Allerdings nur bedingt. Erstens ist die Vorhersage der Punktzahl auf Grundlage der Anzahl der Wörter nicht perfekt. Fast alle Punkte liegen nicht auf der Regressionsgerade. Eine Regressionsgerade stellt nämlich nie einen deterministischen (“wird es auf jeden Fall sein”), sondern einen probabilistischen Zusammenhang (“wird es wahrscheinlich sein”) dar.","code":""},{"path":"einfache-lineare-regression.html","id":"vorhersagen-auf-grundlage-der-regressionsgeraden","chapter":"6 Einfache lineare Regression","heading":"6.2.2 Vorhersagen auf Grundlage der Regressionsgeraden","text":"Alle statistischen Modelle, auch die Regressionsgerade, erlauben uns Vorhersagen für abhängige Variablen (das Kriterium) zu machen. Beispielsweise können wir auf Grundlage der Anzahl der Wörter, die eine Studentin während einer Vorlesung aufschreibt vorher sagen, wie gut diese Person einem Test abschneiden wird. Nehmen wir einmal , eine Studentin schreibt 200 Wörter während der Vorlesung auf. Unser Modell besagt, dass diese Studentin 31.1% der Punkte im Test erreichen wird. Um diese Vorhersage zu erhalten, suchen wir uns der x-Achse den Wert 200 und schauen, auf welcher Höhe die Gerade dieser Stelle auf der y-Achse liegt:Wird diese Person wirklich 31.1% der Punkte im Test erreichen? Nein, da es ein probabilistisches Modell ist. Genau deswegen sprechen wir von einem Modell. Wir versuchen damit, die Daten gut wir können zu beschreiben.","code":""},{"path":"einfache-lineare-regression.html","id":"vergleich-des-modells-der-einfachen-linearen-regression-mit-dem-mittelwert-der-abhängigen-variable-als-modell","chapter":"6 Einfache lineare Regression","heading":"6.2.3 Vergleich des Modells der einfachen linearen Regression mit dem Mittelwert der abhängigen Variable als Modell","text":"Vergleichen wir als nächstes das Modell der einfachen linearen Regression mit dem erweiterten Modell, welches wir im letzten Modul beim t-Test für eine Stichprobe kennen gelernt haben. Erinnere dich, dass das erweiterte Modell beim t-Test für eine Stichprobe die abhängige Variable einer Person auf Grundlage des Mittelwerts dieser abhängigen Variable vorhergesagt hat.Du siehst, dass beide Modelle unterschiedliche Vorhersagen bei einer Person machen, die 200 Wörter während der Vorlesung mitgeschrieben hat. Das Modell der einfachen linearen Regression sagt voraus, dass eine solche Person 31.1% der Punkte erreichen wird, das Modell mit dem Mittelwert der abhängigen Variable sagt voraus, dass eine solche Person 27.9% der Punkte erreichen wird. Dieses Beispiel zeigt, dass die Wahl des Modells zu unterschiedlichen Vorhersagen führt. Ich zeige dir diesen Vergleich, da wir ihn im nächsten Submodul benötigen werden. Genauer werden wir im nächsten Modul sehen, dass wir zum Testen von Zusammenhangshypothesen das Modell der einfachen linearen Regression als erweitertes Modell und das Modell des Mittelwerts der abhängigen Variable als kompaktes Modell verwenden werden.","code":""},{"path":"einfache-lineare-regression.html","id":"statistisches-modell-der-einfachen-linearen-regression","chapter":"6 Einfache lineare Regression","heading":"6.2.4 Statistisches Modell der einfachen linearen Regression","text":"Bisher haben wir das Modell der einfachen linearen Regression grafisch als Linie dargestellt. Als nächstes werden wir diese Linie als statistisches Modell darstellen. Und sieht das Modell für unsere Daten aus:Um das Modell zu verstehen, beginnen wir mit dem Prädiktor Xi: Und wir stellen uns erneut unsere Studentin vor, die 200 Wörter während der Vorlesung aufgeschrieben hat. Für diese Studentin würden wir für den Prädiktor Xi die Zahl 200 einsetzen. Für diese Studentin würden wir eine Punktzahl von ungefähr 31% vorhersagen.Wir haben eben einen neuen Begriff etabliert: Den Begriff Prädiktor. Auch dieser Begriff wird uns immer wieder begegnen, wir müssen ihn zudem vom Begriff des Parameters unterscheiden.Parameter (bzw. Koeffizienten) werden statistischen Modellen als ß oder b dargestellt. Sie werden auf Grundlage der Daten berechnet. Prädiktoren werden statistischen Modellen als X dargestellt und werden auch als unabhängige Variablen bezeichnet.Das Modell der einfachen linearen Regression hat daher einen Prädiktor und zwei Parameter. Nun, da wir Prädiktoren von Parametern unterscheiden können, müssen wir die beiden anderen Parameter im Modell der einfachen linearen Regression verstehen.Allgemeine Darstellung des ModellsDie beiden Parameter im Modell nennen wir b0 und b1. Da es kleine bs sind, meinen wir damit die Parameter, die wir auf Grundlage unserer Daten ermittelt haben. Nicht die Parameter, die sich aus der gesamten Population ergeben. Achte ebenso darauf, dass wir bei diesem Modell ein Y mit einem Dach verwenden. Damit meinen wir die Werte, welche wir auf Grundlage des Modells schätzen. Nicht die tatsächlichen Werte einer jeden Person.Beginnen wir mit dem Parameter b1. b1 bezeichnen wir als Steigungskoeffizienten. Dieser Parameter gibt , wie steil die Regressionsgerade ist. unserem berechneten Modell beläuft sich der Steigungskoeffizient auf 0.0005387. Das bedeutet, für jedes weitere Wort, welches eine Person aufschreibt, sollte diese Person 0.05% mehr Punkte im Test erhalten (0.05%, da der Wert 0.0005387 mal 100 berechnet werden muss, um Prozente zu erhalten). Grafisch können wir uns diese Steigung folgendermaßen vorstellen (siehe nächste Grafik). Schreibt eine Person 100 Worte mehr im Test, erwarten wir, dass diese Person 5.387% mehr Punkte im Test erhält. 5.387%, da wir 0.0005387 mal 100 rechnen müssen (= 0.05387) um den prozentuellen Anteil zu erhalten und nochmal mal 100 rechnen müssen um die Prozentangabe zu erhalten (=5.387%).b0 wiederum kennzeichnet den y-Achsenabschnitt. Der y-Achsenabschnitt ist die Stelle, bei welcher die y-Achse durch die Regressionsgerade abgeschnitten wird. Bei unserer Regressionsgerade liegt dieser Wert bei 0.2037:Wir haben damit etabliert, wie das statistische Modell der einfachen linearen Regression aussieht. Das Modell umfasst einen Prädiktor (Xi) und zwei Parameter (b0 und b1). Dieses Modell können wir als Gerade darstellen.","code":""},{"path":"einfache-lineare-regression.html","id":"berechnung-der-regressionsgeraden","chapter":"6 Einfache lineare Regression","heading":"6.2.5 Berechnung der Regressionsgeraden","text":"Nun, warum ist diese blaue Gerade die “richtige” Regressionsgerade? Ich hätte unendlich viele solcher Regressionsgeraden wählen können. Beispielsweise folgende:Manche der roten Geraden bilden die Daten besser ab als andere. Dennoch, die blaue Gerade ist die “beste,” da sie eine Eigenschaft hat, die die anderen Geraden nicht haben: Die blaue Regresssionsgerade minimiert die quadrierten Abweichungen der einzelnen Punkte von der Regressionsgerade.Ordinal Least SquaresIn einer Formel dargestellt, suchen wir daher diejenige Gerade, welche die quadrierten Fehler zwischen dem echten Wert (Yi) und dem vorhergesagten Wert (Y-Dachi) maximal minimiert. Wir nennen diesen Prozess Ordinal Least Squares Methode.Die beste Regressionsgeraden sagt Yi allerdings nicht perfekt voraus. Es ist schlicht die beste aller möglichen Regressionsgeraden. Es gibt nun verschiedene Methoden, diese beste Gerade zu finden. Nehmen wir zwei. Wir können die Gerade entweder R berechnen oder anhand der Korrelation und der Standardabweichungen der beiden Variablen berechnen. R können wir die Funktion lm verwenden, um die Gerade direkt zu erhalten:Intercept steht für die Stelle, der die Regressionsgerade die y-Achse schneidet. wordcount steht für die Variable, welche die Anzahl der Worte der Mitschrift umfasst.Linksder Tilde ~ tragen wir die abhängige Variable ein, rechts der Tilde den Prädiktor. Zusätzlich müssen wir angeben, aus welchem Datensatz wir die Variablen ziehen. Wie du siehst, erhält man mit der Funktion das gleiche Modell, welches wir weiter oben beschrieben haben.Eine weitere Möglichkeit zur Berechnung der Parameter bei einer einfachen linearen Regression liefern folgende Formeln:b1 können wir berechnen, indem wir den Quotienten der Standardaweichung der abhängigen Variable (sy) und der unabhängigen Variable (sx) mit der Korrelation der beiden Variablen (r) multiplizieren.b1 können wir anhand dieser Formel beispielsweise selbst R berechnen:b0 können wir berechnen, indem wir das Produkt aus b1 und dem Mittelwert des Prädiktors von dem Mittelwert der abhängigen Variable abziehen.Erneut können wir den Koeffizienten R berechnen und erhalten das gleiche Ergebnis, das wir weiter oben dargestellt haben:","code":""},{"path":"einfache-lineare-regression.html","id":"zusammenfassung-9","chapter":"6 Einfache lineare Regression","heading":"6.2.6 Zusammenfassung","text":"diesem Submodul haben wir gezeigt, wie das statistische Modell der einfachen linearen Regression aussieht und wie es berechnet wird. Das Modell kann als Gerade einem Koordinatensystem dargestellt werden. Die Koeffizienten oder Parameter des Modells kennzeichnen den y-Achsenabschnitt und die Steigung der Gerade (auch Intercept genannt). Der erste Parameter b0 kennzeichnet die Stelle, der die Regressionsgrade die y-Achse schneidet. Der Parameter b1 kennzeichnet die Steigung der Regressionsgeraden. Xi im Modell kennzeichnet die unabhängige Variable oder das Kriterium, die wir das Modell für jeden Datenpunkt einfügen. Die Regressionsgerade wird ermittelt, indem man diejenige Gerade findet, welche die geringsten Quadrierten Abweichungen der echten Punkte und der vorhergesagten Punkte hat. Diese Methode nennt man Ordinal Least Squares Methode. Zuletzt haben wir gesehen, wie diese Parameter berechnet werden können. Als nächstes werden wir statistische Hypothesen auf Grundlage dieses Modells testen.","code":""},{"path":"einfache-lineare-regression.html","id":"statistisches-hypothesentesten-1","chapter":"6 Einfache lineare Regression","heading":"6.3 Statistisches Hypothesentesten","text":"diesem Modul werden wir die Fragestellung prüfen, ob Studierende, die mehr einer Vorlesung aufschreiben, auch mehr aus dieser Vorlesung lernen. Wir werden hierfür den Datensatz von Morehead, Dunlosky und Rawson (2014) verwenden, wie wir ihn zu Beginn dieses Moduls vorgestellt haben. Der Datensatz umfasst Daten von 84 Studierenden. Folgendermaßen werden wir vorgehen: Wir werden zunächst anhand einer Poweranalyse untersuchen, wie sensitiv unser Test ist, sprich, welche Effekte wir überhaupt durch die Größe unserer Stichprobe finden können. Anschließend werden wir unsere Hypothese statistisch modellieren und ein kompaktes und erweitertes Modell aufstellen. Von dort werden wir den empirischen F-Wert berechnen und prüfen, ob wir die Nullhypothese auf Grundlage der Daten ablehnen oder nicht. diesem Zug werden wir ebenso zeigen, dass wir diese Fragestellung mit einem t-Test prüfen können und erklären warum. Zuletzt zeigen wir, wie die Ergebnisse des Tests einem Fachartikel berichtet werden können.","code":""},{"path":"einfache-lineare-regression.html","id":"poweranalyse","chapter":"6 Einfache lineare Regression","heading":"6.3.1 Poweranalyse","text":"Mit Power haben wir die Wahrscheinlichkeit bezeichnet, mit der wir bei einem Test die Nullhypothese korrekterweise ablehnen werden, sollte die Alternativhypothese gelten. Wir haben ebenso gesagt, dass wir der Regel versuchen, eine Power größer als 80% einem Test zu erzielen. Das bedeutet, sollte die Alternativhypothese stimmen, möchten wir 80% der Fälle die richtige statistische Entscheidung treffen und die Nullhypothese zu Gunsten der Alternativhypothese ablehnen. der Regel überlegen wir uns daher auf Grundlage vorheriger Forschung, welchen Effekt wir erwarten und bestimmen anschließend die Größe der Stichprobe. unserem Fall ist die Stichprobengröße bereits bestimmt (84 Studierende). Wir können allerdings die Fragestellung umdrehen und uns überlegen, für welche Effekte, sprich Korrelationskoeffizienten, wir eine Power von 80% erreichen werden. Hierdurch können wir herausfinden, wie sensitiv unser Test ist, um bestimmte Zusammenhänge zwischen zwei Variablen zu prüfen. Ein Test der nämlich eine zu geringe Power hat, kann uns keine Aufschlüsse über unsere Hypothesen geben.","code":""},{"path":"einfache-lineare-regression.html","id":"poweranalyse-mit-gpower","chapter":"6 Einfache lineare Regression","heading":"6.3.2 Poweranalyse mit G*Power","text":"G*Power können wir die Sensitivität unseres Tests bestimmen, indem wir unter Test Family: Exact, unter Statistical Test Correlation: Bivariate normal model und unter Type Power analysis: Sensitivity eingeben. Folgendermaßen sieht die Eingabe G*Power aus:Das Ergebnis dieser Poweranalyse sagt uns nun folgendes: Nur bei einem Korrelationskoeffizienten von r = .268 oder größer der Population werden wir bei einer Stichprobengröße von 84 Personen eine Power von 80% erzielen. anderen Worten, ist der Korrelationskoeffizient der Population geringer als r = .268, schwindet unsere Power zunehmend. Bei einem Korrelationskoeffizienten von r = .11 beispielsweise der Population würden wir lediglich eine Power von 46% erzielen. Unsere Studie wäre diesem Fall nicht sensitiv genug, den Effekt durch unser Verfahren des frequentistischen Wahrscheinlichkeitsbegriffs zu finden. Oder, wir könnten aus unserem Test nichts über die Gültigkeit unserer Nullhypothese lernen. Das heißt wiederum, dass unser Test mit 84 Personen nur zur Erkenntnisgewinnung hilfreich ist, sofern der Korrelationskoeffizient der beiden Variablen der Population größer als .268 ist. Das allerdings wissen wir nicht.","code":""},{"path":"einfache-lineare-regression.html","id":"statistische-modellierung-der-hypothesen","chapter":"6 Einfache lineare Regression","heading":"6.3.3 Statistische Modellierung der Hypothesen","text":"Bevor wir unsere Fragestellung statistisch testen, beginnen wir mit einer Grafik. Im folgenden siehst du die statistischen Verfahren, die wir diesem Kurs kennenlernen werden. Bisher haben wir den t-Test für eine Stichprobe kennengelernt. Die Grafik besagt, dass das statistische Modell (sprich das erweiterte Modell) bei diesem Test keine Prädiktoren umfasst (X). Ebenso kannst du erkennen, dass wir bei der einfachen linearen Regression ein erweitertes Modell mit einem kontinuierlichem Prädiktor definieren. Kontinuierlich bedeutet, dass wir für X dem Modell metrische (intervall- und verhältnisskalierte) Variablen einsetzen. unserem Fall wird X die Anzahl der Wörter sein, die die Studierenden während der Vorlesung aufschreiben.Das erweiterte Modell bei der einfachen linearen Regression haben wir im letzten Submodul bereits beschrieben. Wiederholen wir es dieser Stelle erneut.Erweitertes Modell (augmented)Das erweiterte Modell, welches wir annehmen, umfasst einen Prädiktor Xi und zwei Parameter (hier Populationsparameter ß0 und ß1). Genauer beschreibt der Parameter ß1 denZusammenhang der beiden Variablen.Kompaktes Modell (compact)Das kompakte Modell der Nullhypothese umfasst keinen Prädiktor. Wir nennen es Nullhypothese, da die Parameter, die wir prüfen möchten, dem dazugehörigen Modell auf Null gesetzt werden. diesem Fall nehmen wir im kompakten Modell , dass die Korrelation der beiden Variablen, welche durch ß1 kodiert ist, 0 beträgt. Das kompakte Modell schätzt daher die abhängige Variable auf Grundlage des Mittelwerts der abhängigen Variable (ß0).Um diesen Vergleich noch einmal genauer darzustellen, vergleichen wir das erweiterte und das kompakte Modell grafisch. Links siehst du das aus den Daten berechnete erweiterte Modell blau dargestellt. Rechts siehst du das berechnete kompakte Modell blau dargestellt. Du siehst, dass wir für jeden Wert X im kompakten Modell die gleiche Vorhersage für Y machen. Diese Idee ist konform mit unserem oben dargestellten kompakten Modell, da wir dort den Prädiktor X aus der Gleichung entfernt haben, indem wir ß1 auf 0 gesetzt haben.Eine solche horizontale Linie, wie sie durch das kompakte Modell dargestellt ist, beschreibt eine nicht-existierende Korrelation zwischen zwei Variablen. Schau dir dazu folgende Simulation von Kristoffer Magnussen .Besteht eine Korrelation von 0 zwischen zwei Variablen, ist die abhängige Variable unbeeinflusst vom Prädiktor X. Oder, das Wissen um die unabhängige Variable gibt uns keine Informationen über die abhängige Variable. Oder: Wie viel Worte einer Person einer Vorlesung mitschreibt, hat keinen Einfluss auf das Abschneiden im späteren Test dieser Person.Besteht jedoch eine Korrelation zwischen zwei Variablen, sprich ist der Steigungskoeffizient nicht null, gibt uns die unabhängige Variable X Informationen über die abhängige Variable Y. unserem Fall zeigt die Korrelation der beiden Variablen, dass das Abschneiden dem Test teils durch die Anzahl der Wörter, die Studierende bei einer Vorlesung mitschreiben, erklärt werden kann. Wir werden später erklären, wofür die Prozentzahl 5.3 der Grafik links steht.Wir haben nun auf verschiedenen Wegen gezeigt, dass das kompakte Modell und das erweiterte Modell unsere Annahmen über die Null- und Alternativhypothese darstellen. Wir haben damit einen formalen Weg gefunden, unsere Hypothesen statistische Modelle zu übertragen. Als nächstes können wir den empirischen F-Wert berechnen, auf Grundlage dessen wir unsere Hypothese testen.","code":""},{"path":"einfache-lineare-regression.html","id":"empirischer-f-wert-ermitteln","chapter":"6 Einfache lineare Regression","heading":"6.3.4 Empirischer F-Wert ermitteln","text":"Als nächstes werden wir den empirischen F-Wert ermitteln. Der F-Wert wird uns zeigen, wie viel besser der Parameter b1 ist als willkürliche weitere Parameter, die keinen substantiellen Beitrag leisten, Y aufzuklären. Hierzu müssen wir die entsprechenden Werte der folgenden Tabelle finden. Beginnen wir mit den Freiheitsgraden der beiden Modelle. Das erweiterte Modell hat insgesamt 2 Parameter bei 84 Datenpunkten. Das heißt, dieses Modell können noch 84 - 2 = 82 Parameter hinzugefügt werden. Das kompakte Modell hat insgesamt 1 Parameter bei 84 Datenpunkten (df2). Das heißt, das kompakte Modell können noch 84 - 1  = 83 Parameter hinzugefügt werden. Zuletzt können wir feststellen, dass das erweiterte Modell einen Parameter mehr hat als das kompakte Modell (df1).Als nächstes müssen wir die Fehler beiden Modellen ermitteln und berechnen, wie viel mehr Fehler das kompakte Modell im Vergleich zum erweiterten Modell macht. Beginnen wir mit SSEC und SSEA. ","code":""},{"path":"einfache-lineare-regression.html","id":"ssec","chapter":"6 Einfache lineare Regression","heading":"6.3.5 SSEC","text":"Zunächst müssen wir die Fehler ermitteln, die das kompakte Modell macht. Im nächsten Bild sind diese Fehler als Quadrate für jede Person dargestellt. Die Summe dieser Quadrate kennzeichnet SSEC.Die Summe dieser Quadrate und damit die Fehler dieses kompakten Modells belaufen sich auf SSEC = 2.136042.","code":""},{"path":"einfache-lineare-regression.html","id":"ssea","chapter":"6 Einfache lineare Regression","heading":"6.3.6 SSEA","text":"Ebenso macht das erweiterte Modell Fehler. Da das erweiterte Modell allerdings einen Prädiktor mehr hat als das kompakte Modell, wird dieses Modell insgesamt weniger Fehler machen als das kompakte Modell. Visuell können wir uns die Fehler erneut als den quadrierten Abstand der realen Werte von den vorhergesagten Werten des Modells vorstellen:Die Fehler belaufen sich auf ingesamt 2.026016 und sind damit wie erwartet kleiner als beim kompakten Modell.","code":""},{"path":"einfache-lineare-regression.html","id":"ssr-pre-und-tabellarische-darstellung","chapter":"6 Einfache lineare Regression","heading":"6.3.7 SSR, PRE und tabellarische Darstellung","text":"Für SSR ergibt sich daher folgender Wert:Das erweiterte Modell reduziert daher 0.11 der Fehler des kompakten Modells. Nun, da wir SSR kennen, können wir ebenso berechnen, wie viel Prozent der Fehler des kompakten Modells das erweiterte Modell reduziert:PRE liegt bei 5.15%. Das bedeutet, das erweiterte Modell reduziert 5.15% der Fehler des kompakten Modells. Beachte, dass PRE im Kontext der einfachen und multiplen linearen Regression auch als R2 bezeichnet wird. der Berechnung ist es allerdings nichts anderes als PRE. Ebenso werden wir später sehen, dass die Effektgröße η2 nichts anderes ist als PRE.Unsere Ergebnisse können wir nun tabellarisch zusammenfassen:","code":""},{"path":"einfache-lineare-regression.html","id":"f-wert-und-wahrscheinlichkeit-für-f-berechnen","chapter":"6 Einfache lineare Regression","heading":"6.3.8 F-Wert und Wahrscheinlichkeit für F berechnen","text":"Nun, da wir die Fehlerwerte kennen, sind wir im Stande MSR, MSE und F zu berechnen. Erneut fragen wir uns, wie viel besser unser Parameter b1 ist als ein willkürlicher Parameter, welchen wir noch das erweiterte Modell hinzufügen könnten?Es zeigt sich, dass der Parameter b1, welcher für den Zusammenhang der beiden Variablen steht, 4.45 mal besser ist als wir bei einem willkürlichen Parameter erwarten würden. Als Faustregel gilt, liegt der empirische F-Wert zwischen 4 und 5, wird der Test der Regel signifikant. Prüfen wir dies als nächstes:R können wir die Wahrscheinlichkeit für diesen Kennwert relativ schnell durch die Funktion pf ermitteln. Wir müssen hierfür lediglich den empirischen F-Wert sowie die beiden Freiheitsgrade eingeben. Um die Fläche rechts des empirischen F-Wertes zu erhalten, müssen wir das Ganze von 1 abziehen:Wir sehen, dass die Wahrscheinlichkeit für einen solchen Kennwert bei 3.78% liegt. Wir erhalten damit ein signifikantes Ergebnis. Die Annahme, dass es keinen Zusammenhang zwischen diesen beiden Variablen gibt, muss daher widerlegt werden. Wir müssen anbetracht von R2 allerdings auch sagen, dass der Effekt der Anzahl der Wörter auf die Lernleistung relativ gering ist. Er klärt lediglich 5% der Varianz im kompakten Modell auf. Es müssen daher andere Faktoren deutlich besser die Leistung dem Test erklären können als lediglich die Anzahl der Worte der Mitschrift. Fassen wir die Ergebnisse zusammen:","code":""},{"path":"einfache-lineare-regression.html","id":"äquivalenz-zum-t-test","chapter":"6 Einfache lineare Regression","heading":"6.3.9 Äquivalenz zum t-Test","text":"Selten wird bei einer Korrelation ein F-Test berichtet. Viel häufiger ist der t-Test. Wir wissen allerdings jetzt, dass der F-Test und der t-Test die gleichen Ergebnisse liefern (zumindest für ungerichtete Hypothesen). Nichtsdestotroz sollten wir dies dieser Stelle noch einmal zeigen.t-Wert auf Grundlage von F ermittelnZunächst ist der t-Wert nichts anderes als die Wurzel aus F. Der t-Wert ist daher 2.11.t-Wert auf Grundlage des Korrelationskoeffizienten der beiden VariablenEbenso können wir die Korrelation der beiden Variablen verwenden und erhalten den gleichen t-Wert.","code":""},{"path":"einfache-lineare-regression.html","id":"effektgröße-cohens-d-berechnen","chapter":"6 Einfache lineare Regression","heading":"6.3.10 Effektgröße Cohen’s d berechnen","text":"Wir haben bereits mit R2 eine Effektgröße kennen gelernt, die wir für diesen Test berichten können. Allerdings wird bei einem t-Test eher die Effektgröße Cohen’s d berichtet. Wir haben die Formel für Cohen’s d bereits vorherigen Modul kennen gelernt. Allerdings ist diese Formel geeignet, um Cohen’s d aus Mittelwerten zu ermitteln. Für die einfache lineare Regression kann folgende Formel verwendet werden (siehe Rosnow et al., 2003):Wie du siehst, berechnet sich Cohen’s d aus dem empirischen t-Wert und dem Quotienten aus der Wurzel des Freiheitsgrades des erweiterten Modells und der Zahl 2. unserem Fall handelt es sich bei uns um einen kleinen Effekt (siehe auch hier).","code":""},{"path":"einfache-lineare-regression.html","id":"ergebnis-berichten","chapter":"6 Einfache lineare Regression","heading":"6.3.11 Ergebnis berichten","text":"Nun haben wir alle Ergebnisse zusammen und können die Ergebnisse unseres Tests berichten:“Um unsere Hypothese zu prüfen, wurde eine einfache lineare Regression berechnet. Als abhängige Variable wurde die Punktzahl der Probanden im Test direkt nach der Mitschrift und als unabhängige Variable die Anzahl der Wörter der Mitschrift verwendet. Wir fanden eine signifikante Korrelation, t(82) = 2.11, p = .038, d = 0.47 (kleiner Effekt), darauf hindeutet, dass die Anzahl der Wörter einem positiven Zusammenhang mit der Punktzahl im Test steht.”","code":""},{"path":"einfache-lineare-regression.html","id":"zusammenfassung-10","chapter":"6 Einfache lineare Regression","heading":"6.3.12 Zusammenfassung","text":"Wir haben diesem Submodul statistisch getestet, ob zwei Variablen miteinander korrelieren. Zunächst haben wir die Sensitivität unseres Tests gegeben der Stichprobe von 84 Probanden ermittelt. Wir fanden dabei heraus, dass wir bei dieser Stichprobengröße erst eine Power von 80% erzielen, wenn die wahre Korrelation der beiden Variablen bei 0.268 liegt. Danach haben wir unseren F-Test berechnet und herausgefunden, dass die Korrelation der beiden Variablen signifikant ist. Das bedeutet, die Annahme, beide Variablen korrelieren nicht miteinander, ist unter Anbetracht unserer Daten nicht zu halten. Wir verwerfen diesem Fall die Nullhypothese. Zuletzt haben wir gezeigt, dass der F-Test auch als t-Test dargestellt werden kann und gezeigt, wie wir die Ergebnisse des Tests einem Fachartikel berichten können.","code":""},{"path":"einfache-lineare-regression.html","id":"konfidenzintervalle-bei-der-einfachen-linearen-regression","chapter":"6 Einfache lineare Regression","heading":"6.4 Konfidenzintervalle bei der einfachen linearen Regression","text":"Signifikanztest erlauben uns Aussagen darüber, wie unwahrscheinlich bestimmte Daten unter Annahme der Nullhypothese sind: P(D|H0). Finden wir vielen Experimenten häufig, dass ein Ergebnis unter Annahme der Nullhypothese unwahrscheinlich ist, haben wir guten Grund zu denken, dass beispielsweise zwei Variablen miteinander korrelieren. wir allerdings meist wissen möchten ist, wie stark diese Werte miteinander korrelieren? Konfidenzintervalle helfen uns, dieser Frage näher zu kommen und erweitern damit unseren statistischen Werkzeugkasten. Folgende Information liefert uns ein Konfidenzintervall:95 von 100 Fällen befindet sich der wahre Populationsparameter innerhalb des Konfidenzintervalls.Konfidenzintervalle sagen damit nicht, dass sich der Populationsparameter zu 95% innerhalb des Konfidenzintervalls befinden. Diese Wahrscheinlichkeit ist entweder 0 oder 1. Zudem habe ich gerade willkürlich bestimmt, dass der Wert 95% festgeschrieben wird. Genausogut gibt es 99%ige oder 90%ige Konfidenzintervalle.","code":""},{"path":"einfache-lineare-regression.html","id":"simulation-von-konfidenzintervallen","chapter":"6 Einfache lineare Regression","heading":"6.4.1 Simulation von Konfidenzintervallen","text":"Versuchen wir Konfidenzintervalle einem Beispiel genauer zu beschreiben. der nächsten Visualisierung siehst du 100 Konfidenzintervalle. Stell dir vor, wir wiederholen die gleiche Studie, welche wir diesem Modul untersucht haben, 100 mal. Jedes Mal werden wir ein leicht anderes erweitertes und kompaktes Modell erhalten. Für jede Studie werden wir zudem ein anderes Konfidenzintervall erhalten. der folgenden Visualisierung sind die Konfidenzintervalle als schwarze und rote Striche gekennzeichnet. Der blaue vertikale Strich kennzeichnet den wahren Populationsparameter ß1. Zudem liegt die wahre Korrelation der beiden Variablen bei r = 0.27. Bei einem 95%-igen Konfidenzintervall sollten wir 95% der Fälle erwarten, dass der wahre Populationsparameter innerhalb des Intervalls liegt. 5% der Fälle allerdings erwarten wir, dass der Populationsparameter außerhalb des Intervalls liegt. Rote Striche kennzeichnen daher Konfidenzintervalle, bei denen der wahre Populationsparameter nicht im Konfidenzintervall liegt. Sobald zudem einer der schwarzen Linien die schwarze gestrichelete Linie beim Wert 0 umschließt, begehen wir einen Betafehler und nehmen fälschlicherweise die Nullhypothese . Beginnen wir mit einer Simulation von 100 Studien mit je einer Stichprobengröße von 84 Personen:Folgendes erkennen wir aus der Simulation. drei Fällen liegt der wahre Populationsparameter außerhalb des Konfidenzintervalls. Würden wir unendlich viele Studien erhalten, würde dies 5% der Fälle passieren. unserer Simulation tritt dies 3% der Fälle auf. Wir sehen zudem, dass wir 25 von 100 Fällen einen Beta-Fehler begehen, da das Konfidenzintervall den Wert 0 umschließt. Auf Grundlage dieser Simulation müssten wir daher davon ausgehen, dass unsere Studie mit 84 Probanden eine Power von etwa 75% hat. Variieren wir als nächstes die Stichprobengröße, um zu sehen, wie sich die Konfidenzintervalle mit einer unterschiedlichen Stichprobengröße verändern. Und simulieren wir eine Stichprobe von 30, 100, 200 und 300 Probanden:Je größer die Stichprobe wird, desto schmaller wird das Konfidenzintervall. Das heißt, mit steigender Stichprobengröße können wir den wahren Populationsparameter genauer erahnen. Zudem sehen wir, dass wir mit steigender Stichprobengröße weniger Beta-Fehler machen, sprich eine größere Power erhalten. Das sehen wir, da die Konfidenzintervalle mit steigender Stichprobengröße immer seltener den Wert 0 (keine Korrelation der beiden Variablen) schneiden. Bei einer Stichprobengröße von 300 und einem wahren Korrelationskoeffizient von r = 0.27 hätten wir damit fast eine Power von 100%. Ebenso sehen wir, dass bei einem 95%-igen Konfidenzintervall der wahre Populationsparameter der Tat etwa 95% der Fälle innerhalb des Intervalls liegt. Insgesamt haben wir 400 Konfidenzintervalle dieser Simulation berechnet. 24 der Fälle liegt der Populationsparameter außerhalb des Konfidenzintervalls. Das entspricht 6% der Fälle und kommt der 5%-Marke sehr nahe.","code":""},{"path":"einfache-lineare-regression.html","id":"berechnung-des-konfidenzintervalls-bei-der-einfachen-linearen-regression","chapter":"6 Einfache lineare Regression","heading":"6.4.2 Berechnung des Konfidenzintervalls bei der einfachen linearen Regression","text":"Berechnet wird das Konfidenzintervall bei einer einfachen linearen Regression durch folgende Formel:Wir erhalten durch die Formel das untere und obere Ende des Konfidenzintervalls (upper/lower). Zum Verständnis der Formel, hilft es, die einzelnen Komponenten zu klären:b1: Der Steigungskoeffizient der unabhängigen Variable x1b1: Der Steigungskoeffizient der unabhängigen Variable x1Fcrit: Der kritische F-Wert, welcher zu einem signifikanten Ergebnis führt. Diesen kann man mit der Funktion qf R berechnen: qf(0.95, df1 = 1, df2 = 84) = 3.95Fcrit: Der kritische F-Wert, welcher zu einem signifikanten Ergebnis führt. Diesen kann man mit der Funktion qf R berechnen: qf(0.95, df1 = 1, df2 = 84) = 3.95MSE: Die Fehler des erweiterten Modells, die die weiteren Parameter des erweiterten Modells durchschnittlich aufklärenMSE: Die Fehler des erweiterten Modells, die die weiteren Parameter des erweiterten Modells durchschnittlich aufklärenn: Die Anzahl der Untersuchungsobjekten: Die Anzahl der Untersuchungsobjektesx2: Die Varianz der unabhängigen Variable Xsx2: Die Varianz der unabhängigen Variable XSetzen wir diese Werte die Formel ein, erhalten wir folgende Konfidenzintervalle:Wir haben daher eine starke Annahme, dass der wahre Populationsparameter ß1 zwischen den Werten 0.0000309 und 0.0010 liegt. Da das Konfidenzintervall den Wert 0 nicht schneidet, wissen wir zudem, dass das Ergebnis unseres Tests signifikant ist.Da b1 nichts anderes ist als der Steigungskoeffizient der einfachen linearen Regression, können wir das Konfidenzintervall ebenso grafisch darstellen. Im folgenden ist grau das obere und untere Konfidenzintervall dargestellt.Die Visualisierung zeigt uns damit, welchem Bereich sich der Zusammenhang der Population vermutlich befinden wird.","code":""},{"path":"einfache-lineare-regression.html","id":"standardisiertes-konfidenzintervall","chapter":"6 Einfache lineare Regression","heading":"6.4.3 Standardisiertes Konfidenzintervall","text":"Wie aber können wir diese Werte interpretieren? Die haben keinen Bezug zu Werten, die wir kennen. Um daher das Konfidenzintervall besser zu verstehen, können wir die abhängige und unabhängige Variable z-standardisieren.Indem wir die beiden Variablen standardisieren, erhalten wir folgendes erweitertes Modell. Der Koeffizient b1 ist hierdurch der Korrelationskoeffizient der beiden Variablen.Ein Konfidenzintervall von b1 hilft uns daher zu sagen, der wahre Korrelationskoeffizient der Population ist. Berechnen wir erneut einen F-Test mit den standardisierten Daten, erhalten wir folgenden Korrelationskoeffizienten:Die Korrelation der beiden Variablen bewegt sich daher vermutlich zwischen r = 0.013 und r = 0.441. Die Spannweite des Konfidenzintervalls ist noch relativ weit. Würden wir allerdings deutlich mehr Probanden erheben, würde sich die Breite des Konfidenzintervalls schmälern und wir könnten eine besser Aussage über ß1 treffen.","code":""},{"path":"einfache-lineare-regression.html","id":"zusammenfassung-11","chapter":"6 Einfache lineare Regression","heading":"6.4.4 Zusammenfassung","text":"diesem Submodul haben wir zum ersten Mal Konfidenzintervalle kennengelernt. Wir haben gelernt, dass Konfidenzintervalle Aussagen über den wahren Populationsparameter machen können. Bei einem 95%-igen Konfidenzintervall liegt 95% der Fälle der wahre Populationsparameter innerhalb des Intervalls. Ebenso haben wir gesehen, dass Konfidenzintervalle genutzt werden können, um Hypothesen zu testen. Liegt wie unserem Fall der Wert 0 innerhalb des Intervalls, handelt es sich um ein nicht-signifikantes Ereignis. Konfidenzintervalle liefern daher die gleichen Informationen wie der F-Test. Dann haben wir gesehen, wie ein Konfidenzintervall bei einer einfachen linearen Regression berechnet werden kann. Wir haben ebenso gesehen, dass wir durch die Standardisierung der Variablen heraus finden können, welchem Bereich die wahre Korrelation der beiden Variablen vermutlich liegt.","code":""},{"path":"einfache-lineare-regression.html","id":"berechnung-in-jamovi-1","chapter":"6 Einfache lineare Regression","heading":"6.5 Berechnung in Jamovi","text":"Zum Ende des Moduls zeige ich dir, wie die einfache lineare Regression Jamovi berechnet wird. Du wirst gleich sehen, dass alle Ergebnisse Jamovi identisch mit den Werten sind, die wir diesem Modul berechnet haben. Falls du den Datensatz nochmal brauchst, du findest ihn hier:TODO: Einfügen Datei morehead_experiment1.csvTODO: Einfügen Video","code":""},{"path":"einfache-lineare-regression.html","id":"weitere-ressourcen","chapter":"6 Einfache lineare Regression","heading":"6.6 Weitere Ressourcen","text":"https://www.r-bloggers.com/2020/12/robust-regression/","code":""},{"path":"multiple-lineare-regression.html","id":"multiple-lineare-regression","chapter":"7 Multiple lineare Regression","heading":"7 Multiple lineare Regression","text":"","code":""},{"path":"multiple-lineare-regression.html","id":"einführung-5","chapter":"7 Multiple lineare Regression","heading":"7.1 Einführung","text":"Im letzten Modul haben wir herausgefunden, dass sich Studierende besser die Inhalte eines Vortrags erinnern können, je mehr sie während des Vortrags mitschreiben. Wir haben allerdings auch heraus gefunden, dass der Effekt klein ist, da er nur 5% der Varianz der Erinnerungsfähigkeit aufklären konnte. Nun möchten wir zwei Zusammenhangsypothesen testen. Du hast beobachtet, dass viele deiner Kommilitonen eine wortwörtliche Mitschrift des Vortrags anfertigen. Sie kopieren sozusagen die Worte der Professorin exakt ab wie die Professorin spricht. Du hast allerdings gehört, dass Organisations- und Elaborationsstrategien hilfreich sind, um sich viel aus einer Vorlesung zu merken. Indem man zum Beispiel das neue Wissen mit dem bestehenden Wissen verbinden (Elaboration) oder die Konzepte für sich strukturiert (Organisation). Du glaubst daher, dass die wörtliche Überlappung der Mitschrift einen negativen Einfluss auf die Erinnerungsfähigkeit aus der Vorlesung haben sollte. Oder anderen Worten, je mehr Überlappung es gibt, desto schlechter sollten Studierende bei einem späteren Test abschneiden. Nun könntest du erneut eine einfache lineare Regression mit der Überlappung als Prädiktor testen. Besser wäre es jedoch beide Fragestellungen gleichzeitig einem Modell zu kodieren und zu testen. Und dies sind die Fragestellungen, die wir diesem Modul testen werden:Lernen Studierende mehr aus einem Vortrag je mehr Worte sie während dem Vortrag aufschreiben und je weniger sie den Wortlaut der vortragenden Person ihrer Mitschrift übernehmen?Die Lösung, um diese beiden Fragestellungen statistisch zu modellieren, ist die multiple lineare Regression. Die multiple lineare Regression ist sehr ähnlich zur einfachen linearen Regression, allerdings mit ein paar zentralen Besonderheiten. Wir werden beispielsweise sehen, dass die Koeffizienten bei einer multiplen linearen Regression eine andere Bedeutung haben. Ebenso werden wir sehen, dass wir bei einer multiplen linearen Regression mehrere F-Tests berechnen müssen. Bei der einfachen linearen Regression mussten wir nur einen F-Test berechnen. Erneut verwenden wir diesem Modul die Studie von Morehead, Dunlosky und Rawson (2014) aus dem letzten Modul. Diesmal interessieren uns drei Variablen des Datensatzes:wordcount: Die Anzahl der Wörter der Mitschrift der Studierenden.wordcount: Die Anzahl der Wörter der Mitschrift der Studierenden.overlap: Anteil wörtliche Überlappung zwischen Notizen und dem Vortragoverlap: Anteil wörtliche Überlappung zwischen Notizen und dem Vortragtest1tot: Prozentueller Anteil der korrekten Fragen des Tests direkt nach dem Aufschreiben der Notizen.test1tot: Prozentueller Anteil der korrekten Fragen des Tests direkt nach dem Aufschreiben der Notizen.Den Datensatz findest du hier:TODO: Einfügen Datei morehead_experiment1.csvDie Erklärung der Variablen findest du hier:TODO: Einfügen Doc variablen.dox","code":""},{"path":"multiple-lineare-regression.html","id":"statistisches-modell-der-multiplen-regression","chapter":"7 Multiple lineare Regression","heading":"7.2 Statistisches Modell der multiplen Regression","text":"Im letzten Modul haben wir das Modell der einfachen linearen Regression kennen gelernt. Der Parameter ß1 des Modells kodierte die Korrelation der abhängigen und unabhängigen Variable. Zudem hatte das Modell einen metrischen Prädiktor X1.Durch dieses Modell können wir prüfen, ob zwei Variablen miteinander korrelieren. Zum Beispiel hat die Lernzeit von Schülerinnen und Schülern einen Einfluss auf deren Schulnote? Haben intelligente Eltern intelligente Kinder? Sind Studierende, die mehr schlafen, weniger gestresst? Oder: Lernen Studierende weniger aus einem Vortrag, je mehr sie wörtlich aus dem Vortrag mitschreiben? Beziehungsweise, lernen Studierende mehr aus einem Vortrag, je mehr sie während des Vortrags mitschreiben? Um diese beiden Fragestellungen zu beantworten, könnten wir zwei einfache Regressionsmodelle berechnen. Die multiple lineare Regression erlaubt uns allerdings beide Fragestellungen gleichzeitig zu testen, indem wir mehrere metrische Prädiktoren das Modell einfügen. Im Prinzip könnten wir unendlich viele Prädiktoren das Modell einpflegen. Im nächsten Bild siehst du allgemeine Formel der multiplen linearen Regression:Yi steht erneut für die abhängige Variable und ϵi steht für die Fehler, welche unser Modell nicht erklären kann. Xi steht für die Werte unserer metrischen abhängigen Variablen, beispielsweise Anzahl der Wörter der Mitschrift. βi steht für die partiellen Regressionskoeffizienten. Wir werden später ausführlich darüber reden, weshalb diese Koeffizienten partiell heißen. Für jetzt genügt es zu wissen, dass diese partiellen Regressionskoeffizienten von den anderen Prädiktoren abhängig sind und sich abhängig davon ändern, welche und wie viele andere Parameter im Modell sind. Nun möchten wir zwei Zusammenhänge testen: Steht die wörtliche Überlappung und die Anzahl der Wörter einem Zusammenhang mit der Erinnerungsfähigkeit aus dem Vortrag? Um diese Fragestellungen zu testen, benötigen wir eine multiple lineare Regression mit zwei Prädiktoren.X1 steht für die Variable wordcount und gibt die Anzahl der Wörter der Mitschrift . X2 steht für die Variable overlap und gibt die wörtliche Überlappung der Mitschrift mit dem Vortrag .Im Unterschied zur einfachen lineraen Regression können wir uns dieses Modell nicht mehr als Linie vorstellen. Bei zwei Prädiktoren kann man das Modell hingegen als eine Fläche darstellen. Bei mehr als zwei Prädiktoren lässt sich die multiple lineare Regression nicht mehr grafisch darstellen.","code":""},{"path":"multiple-lineare-regression.html","id":"berechnung-des-modells","chapter":"7 Multiple lineare Regression","heading":"7.2.1 Berechnung des Modells","text":"Für die Berechnung der Regressionskoeffizienten gilt erneut, dass wir das Modell mit den Parametern suchen, welches die quadrierten Fehler maximal reduziert:Ich werde dieser Stelle nicht erklären, wie diese Koeffizienten berechnet werden, da wir hierfür Verfahren der linearen Algebra verwenden müssten (wenn es dich interessiert, wie es funktioniert, schaue hier). Eines sollten wir dieser Stelle nochmal klären: Egal, welches statistische Modell wir diesem Kurs formulieren werden, Y-Dach steht der Formel immer für dieses Modell. Wir könnten die Logik der Ordinal-Least-Squares Methode daher ebenso wie folgt für unser Zwei-Prädiktor-Modell formulieren:anderen Worten fragen wir uns erneut, welche unterschiedlichen Vorhersagen macht unser Modell im Vergleich zu den tatsächlichen Daten der abhängigen Variable. Das Modell, welches auf Grundlage der zwei Prädiktoren die besten Vorhersagen macht, ist folgendes:Du kannst du Parameter des Modells sehr schnell berechnen, indem du folgendem Code R folgst:Der Output der Funktion Im gibt die Werte der Parameter zurück.Wir haben nun etabliert, die multiple Regression von der einfachen linearen Regression unterscheidet. Als nächstes werden wir heraus finden, wie wir die Koeffzienten dieses Modells interpretieren können.","code":""},{"path":"multiple-lineare-regression.html","id":"partielle-regressionskoeffizienten","chapter":"7 Multiple lineare Regression","heading":"7.3 Partielle Regressionskoeffizienten","text":"","code":""},{"path":"multiple-lineare-regression.html","id":"b1-der-einfachen-regression-ist-nicht-b1-der-multiplen-regression-mit-dem-gleichen-prädiktor","chapter":"7 Multiple lineare Regression","heading":"7.3.1 b1 der einfachen Regression ist nicht b1 der multiplen Regression mit dem gleichen Prädiktor","text":"Würden wir der Logik der einfachen linearen Regression aus dem letzten Modul folgen, müssten wir die Parameter unserem Modell der multiplen linearen Regression etwa wie folgt interpretieren: Durch jedes weitere Wort der Mitschrift steigt die Punktzahl dem Test um 0.00061 Prozenpunkte. Und, durch jedes Prozent weitere Überlappung der Mitschrift mit dem Vortrag steigt die Erinnerungsleistung aus dem Vortrag um 0.061134%.Diese Interpretation der Parameter ist allerdings falsch. Der Grund hierfür ist, dass die Parameter oder Koeffizienten bei der multiplen linearen Regression partiell sind. Nun heißt das? Stell dir vor, du möchtest den Parameter der Variable wordcount interpretieren. Bei einer einfachen linearen Regression erhältst du für den Parameter b1 den Wert 0.0005387:Wie du siehst, bekommst du bei der einfachen linearen Regression den Parameter 0.0005387 und bei der multiplen linearen Regression den Parameter 0.00061. Offensichtlich sind beide Parameter unterschiedlich. Die Interpretation, dass die Punktzahl bei jedem weiteren Wort um 0.00053% steigt, gilt daher nicht mehr für die multiple lineare Regression.","code":""},{"path":"multiple-lineare-regression.html","id":"bedeutung-von-b1-und-b2-bei-der-multiplen-linearen-regression","chapter":"7 Multiple lineare Regression","heading":"7.3.2 Bedeutung von b1 und b2 bei der multiplen linearen Regression","text":"bedeutet dann allerdings b1 der multiplen linearen Regression? Wir müssen die Regressionskoeffizienten bei der multiplen linearen Regression immer Abhängigkeit der anderen Prädiktoren interpretieren. Für b1 gilt folgende Aussage:Für jedes Wort, welches eine Studentin Anbetracht der Überlappung ihrer Mitschrift mehr schreibt, erwarten wir, dass diese Studentin 0.00061 Prozentpunkte besser im Test abschneidet als man für die Überlappung ihrer Mitschrift erwarten würde.Stellen wir uns zum besseren Verständnis eine Studentin mit dem Namen Simone vor. Simone hat 40 Worte aufgeschrieben und 18% ihrer Mitschrift ist identisch mit dem Vortrag. der folgenden Visualisierung siehst du den Regressionskoeffizienten b1 der multiplen linearen Regression als einfache lineare Regression dargestellt. Die Visualisierung sagt folgendes: Simone schreibt etwa 37 Worte weniger auf als man für die Überlappung ihrem Text erwarten würde. Ebenso schneidet Simone etwa um 8%-Punkte besser ab als man für die Überlappung ihrem Text erwarten würde. Achte darauf, dass sowohl die unabhängige Variable (Anzahl der Worte) als auch die abhängige Variable (Prozentzahl im Test) Abhängigkeit des anderen Prädiktors definiert wird.Der Regressionskoeffizient b1 der multiplen linearen Regression ist demnach nichts anderes als der Steigungskoeffizient einer linearen Regression welche das Verhältnis zwischen der Anzahl der Worte der Mitschrift und der Punktzahl im Test Abhängigkeit davon angibt, man Anbetracht der Überlappung der Mitschrift erwarten würde. Ebenso müssen wir b2 Abhängigkeit der anderen Variable definieren. Diese würden wir wie folgt definieren: Für jedes Prozent Überlappung, welches eine Studentin Anbetracht der Worte ihrer Mitschrift mehr hat, erwarten wir, dass diese Studentin 0.061134 Prozentpunkte besser abschneidet als man für die Anzahl der Wörter der Mitschrift erwarten würde.","code":""},{"path":"multiple-lineare-regression.html","id":"zusammenfassung-12","chapter":"7 Multiple lineare Regression","heading":"7.3.3 Zusammenfassung","text":"Wir haben diesem Submodul gezeigt, dass der Regressionskoeffizient einer einfachen linearen Regression bei dem gleichen Prädiktor nicht mit dem Regressionskoeffizient einer multiplen linearen Regression gleichzusetzen ist. Dies liegt darin, dass Prädiktoren der Regel miteinander korrelieren und daher einen Teil der Varianz der abhängigen Variable gemeinsam aufklären. wir der multiplen linearen Regression erhalten sind partielle Regressionskoeffizienten. Das bedeutet, die Regressionskoeffizienten der multiplen linearen Regression werden immer Abhängigkeit des anderen Prädiktors definiert. Im statistischen Sprachgebrauch würden wir auch sagen, wir kontrollieren für einen anderen Prädiktor. Das heißt, wir fragen uns, welchen Einfluss ein Prädiktor auf die abhängige Variable hat, wenn der andere Prädiktor gleich gehalten wird. Für die Interpretation der statistischen Tests macht diese veränderte Definition der Koeffizienten keinen Unterschied. Indem wir die Prädiktoren bei der Nullhypothese auf Null setzen, können wir immer noch den Zusammenhang zweier Variablen testen.","code":""},{"path":"multiple-lineare-regression.html","id":"statistisches-hypothesentesten-2","chapter":"7 Multiple lineare Regression","heading":"7.4 Statistisches Hypothesentesten","text":"Nun, da wir wissen, wie das statistische Modell der multiplen linearen Regression aussieht, können wir Hypothesen mit Hilfe dieses Modells testen. Genauer werden wir diesem Submodul drei Hypothesen testen. Zunächst werden wir testen, ob beide Prädiktoren des Modells die Fehler des kompakten Modells besser aufklären als man erwarten würde, wenn weitere Prädiktoren keinen substantiellen Beitrag zur Fehlerreduktion des kompakten Modells leisten. Ebenso werden wir sehen, dass wir die Effektgröße R2 bei einem Test, welcher mehr als einen Prädiktor mehr hat als das kompakte Modelle, anpassen müssen. Der allgemeine F-Test gibt uns allerdings keine Antwort auf unsere eigentliche Frage: Gibt es einen Zusammenhang der beiden Variablen mit dem Erinnerungsvermögen aus dem Vortrag? Daher werden wir zwei weitere Tests rechnen, bei denen wir jeweils einen Prädiktor des erweiterten Modells auf 0 schalten. Indem wir nur einen Prädiktor auf 0 schalten und da die Parameter den Zusammenhang der beiden Variablen kodieren, können wir mit diesen Tests prüfen, ob die Anzahl der Worte bzw. die wörtliche Überlappung der Mitschrift mit der Erinnerungsleistung im Test im Zusammenhang steht. Wir werden ebenso sehen, dass wir für diese beiden Tests einen t-Test rechnen können, da beiden Tests das erweiterte Modell genau einen Parameter mehr hat als das kompakte Modell (das ist eine Grundbedingung für den t-Test).","code":""},{"path":"multiple-lineare-regression.html","id":"allgemeiner-f-test-für-beide-prädiktoren","chapter":"7 Multiple lineare Regression","heading":"7.4.1 Allgemeiner F-Test für beide Prädiktoren","text":"Beginnen wir mit einem Test, welcher die folgenden beiden Modelle miteinander testet. Wir bezeichnen diesen Test als allgemeinen F-Test, da dieser Test prüft, ob die weiteren beiden Parameter des erweiterten Modells die Fehler des kompakten Modells substantiell reduzieren. Wir werden durch diesen Test allerdings nicht den Einfluss einzelner Parameter auf die abhängige Variable testen können.Wie du siehst, umfasst das erweiterte Modell (Model ) zwei Prädiktoren und drei Parameter. Das kompakte Modell umfasst keinen Prädiktor und einen Parameter. Das kompakte Modell repräsentiert daher die Nullhypothese, bei der beide Parameter auf 0 gesetzt sind. Durch dieses Modellpaar können wir testen, ob die Annahme, dass beide Parameter nicht im Zusammenhang zu der abhängigen Variable stehen, inkorrekt ist.Hypothesen, die auf diesem Modellpaar beruhen, sind allerdings nicht sonderlich aussagekräftig. Zunächst kann es sein, dass nur einer der beiden Prädiktoren signifikant ist und der zweite Prädiktor die abhängige Variable kaum aufklärt. Zweitens ist das Ergebnis nicht eindeutig. Wir erfahren aus den Ergebnissen nicht, ob der eine oder der andere oder beide Prädiktoren einen signifkanten Effekt auf die abhängige Variable hat. Dieses Problem wird umso größer, je mehr Prädiktoren im erweiterten Modell sind. Kurzum, der allgemeine F-Test kann zwar mit Jamovi und anderen Softwares berechnet werden, er gibt uns allerdings nicht die Informationen, die wir erfahren möchten. Rechnen wir diesen Test, erhalten wir folgendes Ergebnis:Wir erhalten ein nicht-signifikantes Ergebnis. Wir behalten demnach die Annahme, dass der Zusammenhang aller Prädiktoren mit der abhängigen Variable gleich ist.","code":""},{"path":"multiple-lineare-regression.html","id":"angepasstes-r2-adjusted-r2","chapter":"7 Multiple lineare Regression","heading":"7.4.2 Angepasstes R2 (adjusted R2)","text":"Sobald wir mehrere Prädiktoren eine multiple Regression hinzu nehmen, sollten wir vorsichtig sein, R2 zu interpretieren. Denn, mit jedem Parameter, den wir die multiple Regression hinzufügen, verbessert sich R2 automatisch. Ein trickreiche Forscherin könnte daher künstlich ein hohes R2 schaffen, indem sie viele Parameter das Modell hinzufügt. Um diesem Trick zu entgehen, müssen wir einen Weg finden, ein R2 zu finden, welches unabhängig der Anzahl der weiteren Parameter des erweiterten Modells ist. Folgende Formel ermöglicht diese Anpassung:\nBerechnen wir das angepasste R2 erhalten wir einen Wert von 4.5%.Das angepasste R2 ist daher kleiner als R2. Es ist allerdings dem herkömmlichen R2 vorzuziehen, da es für die Anzahl der weiteren Parameter kontrolliert. Wenn du zukünftig daher eine multiple lineare Regression aufstellst, ist es wichtig das angepasste R2 zu verwenden.","code":""},{"path":"multiple-lineare-regression.html","id":"der-zusammenhang-zwischen-der-anzahl-der-worte-und-der-erinnerungsleistung-aus-dem-vortrag","chapter":"7 Multiple lineare Regression","heading":"7.4.3 Der Zusammenhang zwischen der Anzahl der Worte und der Erinnerungsleistung aus dem Vortrag","text":"Unsere eigentliche Frage allerdings der Zusammenhang der beiden Variablen mit der Erinnerungsleistung aus dem Vortrag. Beginnen wir mit dem Zusammenhang zwischen der Anzahl der Worte und der Erinnerungsleistung. Wir wissen, dass der Parameter b1 für den Zusammenhang zwischen der Variable wordcount und der Erinnerungsleistung aus dem Vortrag steht. Indem wir nur diesen Parameter im kompakten Modell auf Null setzen, können wir den Zusammenhang der beiden Variablen testen. Wir werden immer wieder diesem Kurs vorgehen: Parameter kodieren unsere Fragestellungen den Datensatz. Bei der einfachen und multiplen Regression kodieren die Parameter den Zusammenhang zweier Variablen. Die Nullhypothese nimmt , dass dieser Zusammenhang 0 beträgt, daher setzen wir den Parameter im kompakten Modell auf 0. Tun wir dies, erhalten wir folgendes Modellpaar:Mit diesen Modellen können wir als nächstes die Kennwerte berechnen, um heraus zu finden, ob wir die Nullhypothese ablehnen oder nicht. folgender R-Datei habe ich dir die einzelnen Schritte zur Berechnung der Werte aufgeschrieben. Du musst nicht alle Befehle dieser Datei kennen, aber ich lade dich ein, die Berechnung von F einmal selbst durchzuführen und die Schritte nachzuvollziehen:TODO: Einfügen test_wordcount.RTODO: Einfügen VideoZusammengefasst lauten die Ergebnisse des Tests folgendermaßen:Aufgrund des signifikanten Ergebnisses gehen wir nun davon aus, dass die Annahme, dass die beiden Variablen nicht miteinander korrelieren, falsch ist. Wir entscheiden uns daher gegen die Nullhypothese.","code":""},{"path":"multiple-lineare-regression.html","id":"t-test-als-alternative","chapter":"7 Multiple lineare Regression","heading":"7.4.4 t-Test als Alternative","text":"Wie immer können wir bei einem erweiterten Modell, welches einen Parameter mehr hat als das kompakte Modell einen t-Test berechnen. t ist die Wurzel aus F, daher beträgt t 2.34. Der p-Wert ändert sich durch diese Umstellung nicht, da wir eine ungerichtete Hypothese haben; es gibt einen Zusammenhang, wir sagen nicht, welche Richtung der Zusammenhang liegt. Wir können daher das Ergebnis berichten:“Um zu testen, ob die Anzahl der Worte der Mitschrift mit der Erinnerungsleistung des Vortrags im Zusammenhang steht, wurde eine multiple lineare Regression mit der Anzahl der Worte als unabhängige und dem Erinnerungsleistungstest als abhängige Variable gerechnet. Wir fanden einen signifikanten Zusammenhang, t(81) = 2.34, p = .022, R2= 0.63.”","code":""},{"path":"multiple-lineare-regression.html","id":"der-zusammenhang-zwischen-der-anzahl-der-worte-und-der-erinnerungsleistung-aus-dem-vortrag-1","chapter":"7 Multiple lineare Regression","heading":"7.4.5 Der Zusammenhang zwischen der Anzahl der Worte und der Erinnerungsleistung aus dem Vortrag","text":"Als nächstes möchten wir heraus finden, ob die wörtliche Überlapppung den Texten einem negativen Zusammenhang mit der Erinnerungsleistung im Test steht. Wir sind davon ausgegangen, dass Lernende durch das wörtliche Abschreiben des Vortrags wenige Elaborations- und Organisationsstrategien verwenden und daher weniger von der Mitschrift profitieren sollten als Lernende, die wenig wörtlich mitschreiben.Um diese Hypothese zu testen, setzen wir im kompakten Modell den Parameter β2 auf 0:Ist ß2 wirklich 0, sprich gibt es keine Zusammenhang der beiden Variablen, sollten wir nur 5% der Fälle ein signifikantes Ergebnis bei diesem Test erhalten. Folgende Ergebnisse erhalten wir durch diesen Test:Das Ergebnis zeigt uns, dass unsere Annahme inkorrekt ist. Der p-Wert ist nicht signifikant und liegt bei 23.48%. Dieses Ergebnis ist unter Annahme der Nullhypothese durchaus vorstellbar.Aber: Der F-Test testet immer ungerichtet, unsere Hypothese ist allerdings gerichet. Wir sind davon ausgegangen, dass die Erinnerungsleistung sinkt, je mehr ich aus dem Vortrag wörtlich abschreibe. Wir erwarten daher eine gerichtete negative Korrelation. Das heißt, wir müssen den p-Wert entsprechend anpassen. Um zu verstehen wie, müssen wir zunächst den empirischen t-Wert ermitteln. Dieser beträgt 1.19 und ist die Wurzel aus dem F-Wert. Der t-Wert liegt rechts des Gipfels der t-Verteilung:Testen wir ungerichtet, messen wir die Fläche links des negativen Wertes und rechts des positiven Wertes berechnen:Wenn du beide Wahrscheinlichkeiten zusammen rechnest, erhältst du den p-Wert, welchen wir beim F-Test erhalten haben: p = .234 oder 23.4% (11.7% * 2). Im Bilde des t-Tests haben wir daher eine ungerichtete Hypothese getestet. Allerdings sind wird davon ausgegangen, dass der Korrelationskoeffizient negativ ist (je mehr Überlappung, desto geringer die Erinnerungsleistung). Wir müssen daher die Wahrscheinlichkeit links des empirischen t-Wertes abtragen:Wir sind davon ausgegangen, dass der Korrelationskoeffizient kleiner als 0 ist, daher müssen wir die Fläche links des empirischen t-Wertes abtragen. Und diese Wahrscheinlichkeit beträgt 88.3%. Jamovi und andere statistische Softwares haben nicht immer eine Funktion Korrelationen gerichtet zu testen. Du erkennst daher diesem Beispiel, dass wir der Auswertung statistischer Ergebnisse nicht blind den Ergebnissen der Tests folgen sollten, sondern unsere Ergebnisse immer mit unseren Hypothesen abgleichen müssen.","code":""},{"path":"multiple-lineare-regression.html","id":"konfidenzintervalle-1","chapter":"7 Multiple lineare Regression","heading":"7.4.6 Konfidenzintervalle","text":"Unsere beiden Tests konnten uns zeigen, ob wir uns auf Grundlage der Daten für die Null- oder Alternativhypothese entscheiden sollen. anderen Worten, der F-Test oder der t-Test zeigt uns, wie wir handeln sollen. Die Ergebnisse der Tests deuten darauf hin, dass wir annehmen sollten, dass die Anzahl der Worte der Mitschrift einem Zusammenhang mit der Erinnerungsleistung aus dem Vortrag steht und dass die wörtliche Überlappung der Mitschrift keinem Zusammenhang mit der Erinnerungsleistung aus dem Vortrag steht.Eine weitere Frage ist, wie groß der Zusammenhang der Population ist? Diese Frage können wir ansatzsweise mit Konfidenzintervallen beantworten. Wie bereits im letzten Modul gezeigt, besagt ein Konfidenzintervall, wie oft sich ein Populationsparameter im Schnitt innerhalb eines Intervalls befindet. Je größer die Stichprobe, desto enger wird das Intervall. Bei einem 95%-igen Konfidenzintervall beispielsweise befindet sich im Schnitt der wahre Populationsparameter 95 von 100 Fällen innerhalb des Intervalls. Ein Konfidenzintervall gibt einen starken Hinweis, wie groß beispielsweise eine Korrelation zwischen zwei Variablen ausfällt. Berechnen wir die Konfidenzintervalle für die beiden Parameter der letzten beiden Tests als nächstes.","code":""},{"path":"multiple-lineare-regression.html","id":"berechnung-des-standardisierten-konfidenzintervalls-für-den-parameter-der-anzahl-der-worte-in-der-mitschrift","chapter":"7 Multiple lineare Regression","heading":"7.4.7 Berechnung des standardisierten Konfidenzintervalls für den Parameter der Anzahl der Worte in der Mitschrift","text":"Beginnen wir mit dem Parameter für die Anzahl der Worte der Mitschrift. Wir haben vorhin heraus gefunden, dass es einen signifikanten Zusammenhang zwischen der Anzahl der Worte der Mitschrift und der Erinnerungsleistung aus dem Vortrag gibt. Als nächstes können wir uns fragen, wie groß der Korrelationskoeffizient der beiden Variablen vermutlich ist. Diesen können wir berechnen, indem wir die abhängige Variable und die unabhängigen Variablen z-standardisieren und danach folgende Formel anwenden:Im nächsten Video siehst du, wie die Konfidenzintervalle R berechnet werden können. Dieses Beispiel dient dir dazu, die einzelnen Schritte der Berechnung nachzuvollziehen. Du musst nicht der Lage sein, selbst eine solche Berechnung R durchzuführen. Es hilft allerdings hoffentlich deinem Verständnis für die Berechnung des Konfidenzintervalls.TODO: Einfügen Datei ci_berechnen_multiple_regression.RTODO: Einfügen VideoAus dem Konfidenzintervall erkennen wir im Übrigen auch, ob der Test signifikant ist. Sobald das Konfidenzintervall den Wert 0 nicht schneidet, erhalten wir ein signifikantes Ergebnis. Dies ist unserem Fall gegeben. Noch einmal grafisch können wir den Koeffizienten wie folgt angeben. Achte allerdings darauf, dass wir keine Gewissheit darüber haben, dass der wahre Korrelationskoeffizient innerhalb dieses Intervalls steckt. Es ist nur sehr wahrscheinlich.Wir könnten das gleiche für den anderen Parameter des Prädiktors machen. Dies überlasse ich allerdings dir. Die Lösung findest du der nächsten Datei:TODO: Einfügen Datei ci_overlap.R","code":""},{"path":"multiple-lineare-regression.html","id":"zusammenfassung-13","chapter":"7 Multiple lineare Regression","heading":"7.4.8 Zusammenfassung","text":"Wir haben diesem Submodul drei Fragestellungen der multiplen linearen Regression getestet. Zunächst haben wir einen allgemeinen F-Test mit einem Freiheitsgrad von 2 gerechnet und erkannt, dass dieser Test uns keine hilfreichen Informationen zu unseren Hypothesen gibt. Im Anschluss haben wir zwei Tests gerechnet, bei denen wir getestet haben, ob die Anzahl der Worte und die Überlappung der Mitschrift mit der Erinnerungsleistung aus dem Vortrag korreliert. Wir haben erkannt, dass wir für beide Tests ebenso einen t-Test berechnen können, da bei beiden Modellpaaren das erweiterte Modell einen Parameter mehr hat als das kompakte Modell. Ebenso haben wir gezeigt, dass wir bei der Interpretation des p-Wertes immer die Hypothese im Hinterkopf behalten müssen, um den p-Wert korrekt zu ermitteln. Ende des Submoduls haben wir gezeigt, wie standardisierte Konfidenzintervalle bei der multiplen Regression berechnet werden.","code":""},{"path":"multiple-lineare-regression.html","id":"berechnung-in-jamovi-2","chapter":"7 Multiple lineare Regression","heading":"7.5 Berechnung in Jamovi","text":"folgendem Video siehst du, wie die multiple Regression Jamovi und R berechnet werden kann:TODO: Einfügen VideoEine weitere Möglichkeit, die multiple Regression R zu berechnen ist die Funktion lm:TODO: Einfügen Video","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"einfaktorielle-varianzanalyse","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8 Einfaktorielle Varianzanalyse","text":"","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"einführung-6","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.1 Einführung","text":"Bisher haben wir drei verschiedene Testverfahren kennen gelernt: Der t-Test für eine Stichprobe, die einfache lineare Regression und die multiple lineare Regression. Durch diese drei Testsverfahren können wir bereits eine Fülle bildungswissenschaftlich relevanten Fragen beantworten. Zum Beispiel:Haben Gymnasiasten einen höheren Intelligenzquotienten als 100?Haben Gymnasiasten einen höheren Intelligenzquotienten als 100?Verringert sich das Stressempfinden von Studierenden, wenn sie mehr meditieren?Verringert sich das Stressempfinden von Studierenden, wenn sie mehr meditieren?Gibt es einen Zusammenhang zwischen der Zeit, die Studierende lernen und ihren Noten Klausuren?Gibt es einen Zusammenhang zwischen der Zeit, die Studierende lernen und ihren Noten Klausuren?Unser Werkzeugkasten ermöglicht es uns allerdings bisher nicht, Gruppenunterschiede zu testen. Beispielsweise können wir bisher keine Unterschiedshypothesen testen. diesem Modul werden wir daher folgenden beiden Fragestellungen testen:Lernen Studierende mehr, wenn sie ihr Wissen testen anstatt eine Concept-Map zu erstellen?Lernen Studierende, die während eines Vortrags handschriftlich mitschreiben mehr als Studierende, die mit einem Laptop bzw. einem E-Writer mitschreiben?Um solche Fragestellungen statistisch zu testen, müssen wir uns überlegen, wie wir diese Gruppenunterschiede durch die Parameter unseren statistischen Modellen kodieren können. Wir haben beispielsweise gesehen, dass b1 bei der einfachen linearen Regression den Zusammenhang zwischen zwei Variablen kodiert. Wir haben ebenso gesehen, dass wir bei der linearen und multiplen Regression Prädiktoren eingeführt haben (Xi), für welche wir die Werte einer metrischen Variable eingesetzt haben. Um nun Gruppenunterschiede statistisch zu testen, müssen wir zwei Probleme lösen:Wir müssen einen Weg finden, Mittelwertsunterschiede von Gruppen als Parameter zu kodieren (z.B. b1).Wir müssen einen Weg finden, Mittelwertsunterschiede von Gruppen als Parameter zu kodieren (z.B. b1).Wir müssen einen Weg finden, kategoriale Variablen (handschriftliche Mitschrift vs. Mitschrift mit dem Laptop) eine numerische Form zu bringen, die wir für Xi einfügen können (z.B. handschriftliche Mitschrift = 1, Mitschrift mit dem Laptop = -1). Das heißt, Xi ist im Gegensatz zur linearen und multiplen Regression nicht mehr kontinuierlich, sondern diskret skaliert.Wir müssen einen Weg finden, kategoriale Variablen (handschriftliche Mitschrift vs. Mitschrift mit dem Laptop) eine numerische Form zu bringen, die wir für Xi einfügen können (z.B. handschriftliche Mitschrift = 1, Mitschrift mit dem Laptop = -1). Das heißt, Xi ist im Gegensatz zur linearen und multiplen Regression nicht mehr kontinuierlich, sondern diskret skaliert.Um diese beiden Probleme zu lösen, werden wir sogenannte Kontrastkodierungen kennen lernen, welche uns ermöglichen, spezifische Gruppenunterschiede zu testen. Zum Beispiel werden wir Ende des Moduls der Lage sein, zu testen, ob Studierende, die handschriftlich mitschreiben mehr lernen als Studierende, die mit dem Laptop oder mit einem E-Writer mitschreiben.Wir werden diesem Modul zwei verschiedene Tests kennen lernen, die allerdings das gleiche Verfahren anwenden, welches wir bisher kennen gelernt haben. Genauer werden wir den t-Test für unabhängige Stichproben und die einfaktorielle Varianzanalyse kennen lernen. Für beide Verfahren werden wir F-Tests berechnen. Der Unterschied zwischen dem t-Test für unabhängige Stichproben und der einfaktoriellen Varianzanalyse liegt darin, dass sie sich darin unterscheiden, wie viel Gruppen man miteinander vergleicht. Beim t-Test für unabhängige Stichproben werden zwei Gruppen miteinander verglichen, bei der einfaktoriellen Varianzanalyse mehr als zwei Gruppen. Sobald du allerdings die Kontrastkodierung verstehst, wirst du sehen, dass beide Tests ähnlich statistisch modelliert werden.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"datensätze-dieses-moduls","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.1.1 Datensätze dieses Moduls","text":"Wir werden diesem Modul zwei verschiedene Datensätze verwenden. Bei beiden Datensätzen handelt es sich um Replikationsstudien bekannter Studien.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"t-test-für-unabhängige-stichproben-buttrick-et-al.-2018","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.1.2 t-Test für unabhängige Stichproben: Buttrick et al. (2018)","text":"Zunächst werden wir uns mit der Studie von Buttrick et al. (2018) beschäftigen. Buttrick und Kolleg*innen replizierten eine sehr bekannte Studie von Karpicke und Blunt (2011). dieser Studie wurde unter anderem untersucht, ob das Testen von Wissen, das heißt der freie Abruf von Wissen, für das Erlernen konzeptuellen Wissens lernförderlicher ist als das Erstellen von Concept Maps. Diese Studie war der Beginn einer intensiven Diskussion zur Frage, ob der Testing-Effekt nicht nur für einfaches Lernmaterial wie Wortpaarliste, sondern auch für komplexes Lernmaterial funktioniert (z.B. konzeptuelles Wissen). Beispielsweise kritisierten van Gog und Sweller (2015), dass der Testing-Effekt bei komplexem Lernmaterial nicht zu finden ist. Karpicke und Aue (2015) verteidigten ihre Position anschließend mit dem Argument, dass die Studien von van Gog und Sweller methodologisch mangelhaft waren. Wir werden diesem Modul den t-Test für unabhängige Stichproben verwenden, um die Ergebnisse von Buttrick et al. zu berechnen und die Frage beantworten, ob das Testen von Wissen zu einer besseren Erinnerungsleistung bei konzeptuellen Wissen ist als die Erstellung von Concept Maps.Die Prozedur des Experiments von Buttrick et al. (2018) sah folgendermaßen aus: Die Versuchspersonen wurden Kleingruppen (1 bis 4 Personen) getestet und lasen einen kurzen Text zum Thema Seeotter. Sie hatten fünf Minuten Zeit, den Text zu studieren. Die Versuchspersonen wurden anschließend willkürlich zwei Gruppen eingeteilt (Concept Map Gruppe vs. Testing Gruppe). Die Versuchspersonen der Concept-Map Gruppe hatten anschließend 25 Minuten Zeit mit dem Text eine Concept-Map zu erstellen. Diejenigen Versuchspersonen der Concept-Map Gruppe hatten 10 Minuten Zeit viel aus dem Text aufzuschreiben, wie sie sich erinnern konnten. Anschließend bekamen sie 5 Minuten Zeit, den Text erneut zu studieren und erhielten erneut 10 Minuten, sich die Inhalte des Textes frei zu erinnern. Eine Woche später erhielten die Versuchspersonen einen Follow-Test, welcher 14 Faktenfragen und zwei Inferenzfragen zum Thema des Textes beinhaltete. Beide Fragen testeten nach Aussage der Autoren konzeptuelles Wissen.Den Datenatz der Replikationsstudie von Buttrick et al. (2018) findest du hier:TODO: Einfügen Datei buttrick.csvFür diese Studie interessieren uns folgende Variablen:condition: Diese Variable kodiert, ob Studierende entweder eine Concept Map erstellt haben (Concept) oder ihr Wissen getestet haben (Retrieval). condition ist die unabhängige Variable.condition: Diese Variable kodiert, ob Studierende entweder eine Concept Map erstellt haben (Concept) oder ihr Wissen getestet haben (Retrieval). condition ist die unabhängige Variable.ts_avg: Diese Variable kodiert, wie viele richtige Antworten die Versuchspersonen bei den 16 Fragen des Abschlusstests Prozent korrekt beantwortet haben. ts_avg ist die abhängige Variable.ts_avg: Diese Variable kodiert, wie viele richtige Antworten die Versuchspersonen bei den 16 Fragen des Abschlusstests Prozent korrekt beantwortet haben. ts_avg ist die abhängige Variable.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"einfaktorielle-varianzanalyse-morehead-dunlosky-und-rawson-2014","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.1.2.1 Einfaktorielle Varianzanalyse: Morehead, Dunlosky und Rawson (2014)","text":"Für das Verfahren der einfaktoriellen Varianzanalyse werden wir erneut die Replikationsstudie von Morehead, Dunlosky und Rawson (2014) verwenden. Zur Erinnerung, dieser Studie wiederholten Morehead et al. eine Studie, die ursprünglich von Mueller und Oppenheimer (2014) durchgeführt wurde. beiden Studien wurde untersucht, ob die Mitschrift eines Vortrags mit verschiedenen Medien einen Einfluss auf die Erinnerungsleistung hat. Wir werden diese Replikationsstudie verwenden, um heraus zu finden, ob die handschriftliche Mitschrift während eines Vortrags lernförderlicher ist als die Mitschrift mit dem Laptop beziehungsweise einem E-Writer.Die Prodezur der Studie von Morhead et al. (2014) verlief wie folgt: Studierende sahen sich einen von fünf TED-Talks , welche im Schnitt 17 Minuten dauerten. Versuchspersonen wurden willkürlich einer der folgenden Gruppen eingeteilt. Entweder wurden die Versuchspersonen gebeten, während des Vortrags die Inhalte des Vortrags per Hand mitzuschreiben. Eine andere Gruppe wurde gebeten, die Inhalte des Vortrags mit dem Laptop mitzuschreiben. Eine dritte Gruppe wurde gebeten, die Inhalte des Vortrags mit einem E-Writer aufzuschreiben. Anschließend erhielten die Versuchspersonen für 30 Minuten eine Aufgabe, die nichts mit dem Experiment zu tun hatte. Anschließend füllten die Versuchspersonen einen Test aus, welcher aus Faktenfragen und konzeptuellen Fragen bestand. Zwei Tage später wurden die gleichen Fragen erneut abgefragt.Der Datensatz dieses Experiments befindet sich hier:TODO: Einfügen morehead_experiment1.csvFür diese Studie interessieren uns folgende Variablen:method: Die Versuchsgruppe, die die Versuchspersonen eingeordnet wurden: eWriter, laptop oder longhand.method: Die Versuchsgruppe, die die Versuchspersonen eingeordnet wurden: eWriter, laptop oder longhand.test2tot: Prozentueller Anteil der korrekten Fragen des Tests zwei Tage nach dem Aufschreiben der Notizen.test2tot: Prozentueller Anteil der korrekten Fragen des Tests zwei Tage nach dem Aufschreiben der Notizen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"kontrastkodierungen","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2 Kontrastkodierungen","text":"der Einführung dieses Moduls haben wir gesagt, dass wir zwei Probleme lösen müssen. Wir müssen kategorielle Werte, wie beispielsweise ob Studierende ihr Wissen getestet haben oder eine Concept-Map erstellt haben, numerische Werte überführen. Ebenso müssen wir einen Weg finden, die Parameter unseren statistischen Modellen als spezifische Hypothesen zu kodieren. Die Lösung dieser beider Probleme sind Kontrastkodierungen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"bei-k-gruppen-braucht-man-k---1-prädiktoren","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.1 Bei k Gruppen braucht man k - 1 Prädiktoren","text":"Für Kontrastkodierungen gilt, dass wir bei einem t-Test für unabhängige Stichproben bzw. einer einfaktoriellen Varianzanalyse für k Gruppen k - 1 Prädiktoren benötigen. Wenn ich beispielsweise testen möchte, ob Probanden, die sich ihr Wissen testen, mehr konzeptuelles Wissen erwerben als Studierende, die Concept-Maps anfertigen, bräuche ich einen Prädiktor (2 -1 = 1) im erweiterten Modell. Würde ich untersuchen, ob Studierende, die bei einem Vortrag handschriftlich mitschreiben, mehr lernen als Studierende, die mit dem Laptop oder einem E-Writer mitschreiben, bräuchte ich zwei Prädiktoren (3 - 1 = 2).","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"kategoriale-variablen-in-numerische-werte-überführen","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.2 Kategoriale Variablen in numerische Werte überführen","text":"Während wir bei der einfachen linearen Regression für die Prädiktoren Xi die Werte der unabhängigen Variablen einfügen können (siehe Bild links), können wir die Gruppen, welche der Regel als Text Variablen gespeichert sind (Concept und Retrieval) nicht direkt für Xi eintragen (siehe Bild rechts), da diese Gruppen nicht numerisch vorliegen.Wie wir Gruppen numerische Werte überführen, entscheidet darüber, welche Hypothesen wir mit den Modellpaaren testen können. Nehmen wir beispielsweise die Frage, ob Studierende, die ihr Wissen testen, mehr konzeptuelles Wissen erwerben als Studierende, die eine Concept-Map anfertigen. Da wir zwei Gruppen haben, müssten wir einen Kontrast für den Parameter X1 definieren (2 -1 = 1). Beispielsweise könnten wir der Testing-Gruppe eine 1 und der Concept Map Gruppe eine -1 zuordnen.Die Werte dieses Kontrasts würden wir für X1 einfügen. b1 kodiert als Folge den Mittelwertsunterschied beider Gruppen. Indem wir nun X1 im kompakten Modell auf 0 setzen, können wir testen, ob dieser Mittelwertsunterschied 0 beträgt:der unteren Tabelle siehst du nun eine Reihe Kontrasten, die du für verschiedene spezifische Hypothesen verwenden kannst. Wir werden diese Kontraste einzeln durchgehen und Beispielen zeigen, welche Fragestellungen mit ihnen beantwortet werden können. Das Ziel dieser Ausführungen ist, dass du lernst, wie statistische Modelle mit kategorialen Prädiktoren erstellt werden. den nächsten Modulen wirst du sehen, wie wir diese Kontraste nutzen, um Hypothesen zu testen.Die folgenden Kontraste werden alle von Jamovi unterstützt. Die Tabelle enthält sowohl den Namen des Kontrasts, die Hypothese, welche man mit den Kontrasten testen kann und die Bedeutung der Regressionskoeffizienten des erweiterten Modells. Ebenso zeigt die Tabelle , ob Kontraste orthogonal sind. Wir werden bei den Difference- bzw. Reverse-Helmert Kontrasten erklären, damit gemeint ist.Im Folgenden gehen wir die einzelnen Kontraste einzeln durch, um zu erklären, für welche Hypothesen sie genutzt werden können. Für alle Beispiele werden wir die Studie von Morehead und Kollegen verwenden.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"deviation--oder-sum-kontrast","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.3 Deviation- oder Sum-Kontrast","text":"Diese Kontraste eignen sich dazu, zu testen, ob sich ein Mittelwert einer Gruppe vom Mittelwert aller Gruppen unterscheidet. Du wirst eine solche Kontrastkodierung selten verwenden, da wir der Regel daran interessiert sind, spezifische Gruppenunterschiede zu testen.Nehmen wir folgendes Beispiel: Du möchtest heraus finden, ob Studierende, die per Hand mitschreiben, sich mehr oder weniger aus einem Vortrag erinnern als die Studierenden aller Gruppen zusammen. Um diese Hypothese zu testen, könntest du folgende Kontraste aufstellen:Nun bist du vermutlich geneigt zu denken, dass man mit diesem Kontrast testet, ob Studierende, die mit dem Laptop mitschrieben sich besser den Vortrag erinnern konnten als Studierende, die per Hand mitschrieben. Dem ist allerdings nicht . Der Grund hierfür ist, dass diese Kontrastgewichte nicht orthogonal sind (wir kommen gleich darauf zu sprechen). Deviation- oder Sum-Kontraste erkennst du daran, dass die erste Zeile der Kontrastegewichte auf -1 gesetzt wird und für die Gruppe, die mit allen Gruppen verglichen werden soll eine 1 gesetzt wird. Alle anderen Gruppen werden auf 0 gesetzt. Das bedeutet, durch X2 testen wir, ob die Studierende mit E-Writern sich besser oder schlechter den Vortrag erinnern konnten als alle Gruppen zusammen. Berechnen wir das erweiterte Modell auf Grundlage dieser Kontrastgewichte, erhalten wir dieses Modell:Du siehst, dass das Modell drei Parameter und zwei Prädiktoren hat. b1 kodiert den Mittelwertsunterschied zwischen der Laptopgruppe mit allen anderen Gruppen. b2 kodiert den Mitelwertsunterschied zwischen der E-Writer Gruppe mit allen anderen Gruppen. Beweisen können wir dies dadurch, indem wir uns die Mittelwerte der Gruppen ansehen:b0 ist offensichtlich der Mittelwert aller Mittelwerte (0.2508). b1 wiederum ist die Differenz des Mittelwerts der Laptopgruppe vom Gruppenmittelwert: 0.2333- 0.2508 = -0.0175. b2 wiederum ist die Differenz des Mittelwerte der E-Writer Gruppe vom Gruppenmittelwert: 0.250 - 0.2508 = 0.00085. Wir haben damit gezeigt, dass die Parameter spezifische Gruppenunterschiede testen. Indem wir die Prädiktoren dieser Parameter im kompakten Modell auf 0 setzten, können wir ebendiese Hypothesen durch unseren bekannten F-Test bzw. t-Test testen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"dummy--oder-simple-kontrast","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.4 Dummy- oder Simple-Kontrast","text":"Dummy-Kontraste sind Kontraste, bei denen die Kontrastgewichte lediglich auf 0 und 1 gesetzt werden. Sie können verwendet werden, um Mittelwertsunterschiede zwischen einer Referenzgruppe und allen anderen Gruppen zu testen.Für die Referenzgruppe werden einer Dummy-Kodierung alle Kontrastgewichte auf 0 gesetzt. Für alle Gruppen, die mit dieser Referenzgruppe verglichen werden sollen, wird pro Kontrast eine 1 eingesetzt. folgendem Beispiel wird jede Gruppe mit der Referenzgruppe derjenigen Studierenden verglichen, die per Hand mitgeschrieben haben.Berechnet man auf Grundlage dieser Kontraste das erweiterte Modell erhält man folgendes Modell:Ein Blick auf die untere Tabelle verrät uns, dass b0 nichts anderes ist als der Mittelwert der Gruppe, welche per Hand mitgeschrieben hat. b1 kodiert den Mittelwertsunterschied zwischen der Laptopgruppe und der Gruppe, die per Hand mitgeschrieben hat: 0.2333 - 0.269 = -0.036. b2 kodiert den Mittelwertsunterschied der E-Book Gruppe und der Gruppe, die per Hand mitgeschrieben hab: 0.250 - 0.269 = -0.019.Durch die Wahl dieser Dummy-Kodierung können wir durch unser Verfahren daher zwei Hypothesen testen: Ob sich die Mittelwerte zwischen der Gruppen Laptop und E-Writer vom Mittelwert der händischen Gruppe unterscheidet. Wir testen diese beiden Hypothesen, indem wir den Prädiktor des jeweiligen Parameters im kompakten Modell auf 0 setzen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"difference-oder-reverse-helmert-kontrast","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.5 Difference-oder Reverse-Helmert Kontrast","text":"Der dritte Kontrast ermöglicht es uns ebenso Mittelwertsunterschiede einzelner Gruppen zu testen. Er ermöglicht es uns aber ebenso eine Gruppe mit mehreren anderen Gruppen zu vergleichen. Dies ist bei einer Dummykodierung und einer Differenzkodierung nicht möglich. Beispielsweise können wir einen Reverse-Helmert-Kontrast verwenden, um zu testen, ob sich die e-Writer Gruppe mehr oder weniger aus dem Vortrag erinnert als die anderen beiden Gruppen.der folgenden Tabelle siehst du einen Reverse-Helmert-Kontrast. Bisher konnten wir aus Kontrastgewichten, die für die einzelnen Prädiktoren eingesetzt werden nicht erahnen, welche Hypothesen mit ihnen getestet werden können. Mit einem Reverse-Helmert-Kontrast allerdings schon. Beispielsweise testen wir bei X1, ob der Mittelwertunterschied der Laptopgruppe unterschiedlich vom Mittelwert der händischen Gruppe ist. Mit X2 testen wir, ob der Mittelwert der E-Writer Gruppe unterschiedlich vom Mittelwert der anderen beiden Gruppen ist.Der Grund, dass diese Kontrastkodierung der einzelnen Prädiktoren interpretierbar sind, liegt darin, dass diese Kontraste orthogonal sind. Orthogonale Kontraste folgen zwei Regeln:","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"erste-regel-bei-orthogonalen-kontrasten-muss-die-summe-der-kontrastgewichte-pro-prädiktor-0-ergeben","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.6 Erste Regel: Bei orthogonalen Kontrasten muss die Summe der Kontrastgewichte pro Prädiktor 0 ergeben","text":"Die erste Regel lautet, dass die Summe der Kontrastgewichte für jeden Prädiktor 0 ergeben muss:unserer Reverse-Helmert-Kodierung gilt daher, dass die Kontrastgewichte für X1 und X2 0 ergibt:","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"zweite-regel-bei-mehr-als-zwei-gruppen-muss-das-produkt-der-kontrastgewichte-der-prädiktoren-bei-orthogonalen-kontrasten-0-ergeben.","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.7 Zweite Regel: Bei mehr als zwei Gruppen muss das Produkt der Kontrastgewichte der Prädiktoren bei orthogonalen Kontrasten 0 ergeben.","text":"Da wir zwei Prädiktoren haben, müssen wir das Produkt der Kontrastgewichte dieser Prädiktoren berechnen und prüfen, ob deren Summe 0 ergibt.der unteren Tabelle siehst du, wie dieses Produkt berechnet wird. Du erkennst, dass die Summe des Produktes der beiden Kontraste 0 ergibt:Nun, stell dir eine andere Reverse-Helmert-Kodierung vor, welche für vier Gruppen definiert wird. Um einen orthogonalen Kontrast zu erzielen, müssten die Summe der Produkte aller Kontraste 0 ergeben:","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"alternative-berechnung-der-kontrastgewichte-bei-reverse-helmert-kontrasten","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.8 Alternative Berechnung der Kontrastgewichte bei Reverse-Helmert-Kontrasten","text":"Wir könnten dieser Stelle bereits das Modell auf Grundlage dieser Kontraste aufstellen. Allerdings wäre hierdurch die Interpretation der Parameter schwieriger. Damit die Parameter spezifische Mittelwertsunterschiede kodieren, müssen wir die einzelnen Kontraste durch die Anzahl der Gruppen teilen, die miteinander verglichen werden. Zum Beispiel werden im ersten Kontrast für X1 zwei Gruppen miteinander verglichen. Daher wird jedes Kontrastgewicht durch 2 geteilt. Im Prädiktor X2 wiederum wird die E-Writer Gruppe mit den anderen beiden Gruppen verglichen. Da wir für diesen Vergleich alle Gruppen betrachten, werden die Kontrastgewichte durch 3 geteilt.Verwenden wir dieses Set Kontrasten, erhalten wir folgendes Modell:Mit Blick auf die untere Tabelle sehen wir erneut, dass b0 den Mittelwert der Gruppenmittelwerte kodiert. b1 kodiert den Mittelwertsunterschied der Laptopgruppe und der Gruppe, die per Hand mitgeschrieben hat: 0.2333 - 0.269 = -0.0357 (mit kleinen Rundungsfehlern). b2 kodiert den Mittelwertsunterschied zwischen der E-Writer Gruppe und den anderen beiden Gruppen: 0.250 - ((0.2692308+ 0.2333) / 2) = -0.00127.Wir haben damit erneut gezeigt, dass die Parameter für Mittelwertsunterschiede den Gruppen stehen. Mit der richtigen Wahl der Reverse-Helmert-Kontrasten können wir entscheiden, welche Gruppen wir miteinander vergleichen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"helmert-kontrast","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.9 Helmert-Kontrast","text":"Helmert-Kontraste sind fast identisch mit Reverse-Helmert-Kontrasten, nur dass sie sozusagen spiegelverkehrt geschrieben werden. Für die Wahl der Hypothesen und die Interpretation der Ergebnisse machte es keinen Unterschied ob man Helmert- oder Reverse-Helmert-Kontraste verwendet.der unteren Tabelle siehst du eine Helmert-Kontrastkodierung. Im Unterschied zur Reverse-Helmert-Kodierung wird die obere Gruppe mit restlichen Gruppen verglichen. Bei der Reverse-Helmert-Kodierung wird die untere Gruppe mit den restlichen Gruppen weiter oben der Tabelle verglichen:Erneut können wir zeigen, dass wir durch diese Kodierung die der Tabelle beschriebenen Mittelwertsunterschiede testen können:b0 kodiert erneut den Mittelwert der Gruppenmittelwerte. b1 kodiert den Mittelwertsunterschied der Gruppe, die per Hand mitschreibt und den anderen beiden Gruppen: 0.269 - ((0.23333+ 0.250) / 2) = 0.027. b2 kodiert den Mittelwertsunterschied zwischen der Laptopgruppe und der E-Writer-Gruppe: 0.2333 - 0.250 = -0.0167.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"zusammenfassung-14","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.2.10 Zusammenfassung","text":"Wir haben diesem Submodul gelernt, wie wir Gruppen als numerische Werte kodieren können. Dabei sind wir verschiedene Kontrastkodierungssysteme durchgegangen. Durch die Wahl der Kontrastekodierung stellen wir unterschiedliche statistische Modelle auf, mit denen wir unterschiedliche Hypothesen testen können. diesem Submodul haben wir darauf verzichtet, zu zeigen, wie diese Parameter aus den Modellen berechnet werden. Das Prinzip bleibt allerdings das gleiche. Wir suchen das Modell, welches die geringste quadrierte Abweichung der tatsächlichen Werte von den vorhergesagten Werten hat (Ordinal Least Squares Methode). Auf Grundlage dieser berechneten Parameter haben gesehen, dass bei Helmert- bzw. Reverse-Helmert-Kontrasten die Parameter spezifische Mittelwertsunterschiede der Gruppen kodieren. Dieser Tatsache machen wir uns im nächsten Submodul zu Nutze, um sowohl einen t-Test für unabhängige Stichproben als auch eine einfaktorielle Varianzanalyse zu berechnen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"t-test-für-unabhängige-stichproben","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.3 t-Test für unabhängige Stichproben","text":"Das Ziel dieses Submoduls ist folgende Forschungsfrage zu beantworten: Lernen Studierende, die ihr Wissen testen, mehr konzeptuelles Wissen als Studierende, die eine Concept-Map anfertigen. Zur Erinnerung, Buttrick et al. (2018) replizierten eine Studie von Karpicke und Blunt (2011), welche genau dies herausgefunden hatte. Den vollständigen Bericht der Studie von Buttrick et al. findest du der unteren Datei:\nTODO: Karpicke & Blunt (2011) - Replication Report.pdfKarpicke berichten folgendes Ergebnis zu dieser Forschungsfrage:“hypothesis retrieval practice lead better recall one week later concept-mapping supported data. assigned retrieval practice (n = 23) recalled one-week follow-test assigned concept-mapping (n = 26): Retrieval M = 62.3% recalled, SD = 19%; Concept-Mapping M = 46.9% recalled, SD = 19%; t(48)=2.88, p = 0.006, r = 0.39 [95% CI: 0.11, 0.71].”Buttrick et al. (2018, S. 4)Wir werden diesem Submodul zeigen, wie dieses Ergebnis zu Stande kommt, das heißt, wie es mit unserem bekannten Verfahren des Hypothesentestens berechnet werden kann.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"aufstellen-der-kontrastkodierung","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.3.1 Aufstellen der Kontrastkodierung","text":"Beginnen wir damit, die Kontraste zu kodieren. Wir wissen, dass wir zwei Gruppenmittelwerte miteinander vergleichen möchten, die Gruppe der Studierenden, die eine Concept-Map anfertigt mit der Gruppe der Studierenden, die ihr Wissen testet. Da wir zwei Gruppen haben, benötigen wir lediglich einen Prädiktor unserem erweiterten Modell (k - 1 = 2 - 1 = 1). Wenngleich wir im letzten Submodul mehrere Kodierungssysteme kennen gelernt haben, haben wir bei zwei Gruppen nicht viele Möglichkeiten. Entweder verwenden wir eine Dummy-Kodierung mit einer 0 und einer 1, oder wir verwenden eine Helmert-Kodierung, bei der wir die Kodierung auf -1 und 1 setzen. Beide Kodierungen führen zu den gleichen Ergebnissen. Folgendermaßen könnten wir unsere Hypothese kodieren:Diese Konstrastkodierung führt dazu, dass der Parameter b1 die Mittelwertsdifferenz der beiden Gruppen kodiert. Indem wir b1 im kompakten Modell auf 0 setzen, können wir testen, ob die Mittelwerte der beiden Gruppen gleich sind. Dies können wir tun, da eine 0 hieße, dass es keine Differenz zwischen den Mittelwerten der beiden Gruppen gibt.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"aufstellen-des-statistischen-hypothesenpaares","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.3.2 Aufstellen des statistischen Hypothesenpaares","text":"Wir können den Mittelwertsunterschied der beiden Gruppen durch folgendes Modellpaar testen:Wie du siehst, umfasst das erweiterte Modell zwei Parameter und einen Prädiktor. Das kompakte Modell umfasst nur einen Parameter, da dort der Parameter b1 auf 0 gesetzt wurde. Im kompakten Modell kodiert b0 den Mittelwert der abhängigen Variable. Dies ist unserem Fall das konzeptuelle Wissen, welches die Studierenden zum Thema Seeotter hatten.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"berechnung-der-sum-of-squares-und-der-kennwerte","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.3.3 Berechnung der Sum of Squares und der Kennwerte","text":"Nun, da wir das erweiterte und das kompakte Modell kennen, können wir sowohl die Sum Squares als auch die zentralen Kennwerte berechnen. Es stellt sich heraus, dass der F-Wert bei 8.33 liegt für einen solchen Mittelwertsunterschied dieser beiden Gruppen unter der Annahme, dass die Gruppen sich nicht im Mittelwert unterscheiden bei 0.6% liegt. Wir haben damit ein signifikantes Ergebnis.Falls du diese Zahlen nachrechnen möchtest und sehen möchtest, wie ich auf dieses Ergebnis gekommen bin, schau dir die folgende R-Datei . Dort sind alle Schritte R nachgerechnet.TODO: Einfügen Datei buttrick_anova_in_r.RNun Buttrick et al. (2018) berichten statt einem F-Test einen t-Test. Damit meinen sie einen t-Test für unabhängige Stichproben: t(48) = 2.88, p = .006, r = 0.39 [95% CI: 0.11, 0.71]. Dieser wird eingesetzt, wenn man die Mittelwerte zweier Gruppen vergleichen möchte. Ebenso berichten sie die Effektgröße r = 0.39 als auch ein Konfidenzintervall für die Effektgröße. Zunächst können wir den t-Wert berechnen, indem wir die Wurzel auf F ziehen. Die Wurzel aus 8.33 ist der Tat 2.88. Als nächstes berichten Buttrick et al. die gleiche Wahrscheinlichkeit von p = .006. Da unser F-Test die gleiche Wahrscheinlichkeit ergibt, wissen wir, dass Buttrick et al. ungerichtet getestet haben. Sie haben daher getestet, ob Studierende, die sich testen mehr oder weniger konzeptuelles Wissen erwerben als Studierende, die Concept-Maps erstellen. der t-Verteilung dargestellt, haben sie folgenden beiden Flächen abgetragen:Wäre ihre Hypothese gewesen, dass Studierende, die sich testen, mehr konzeptuelles Wissen erwerben als Studierende, die eine Concept-Map anfertigen, hätten sie gerichtet getestet. diesem Fall hätten sie nur die Fläche rechts des empirischen t-Wertes abtragen müssen.Hierdurch hätte sich die Wahrscheinlichkeit für einen solchen t-Wert unter Annahme der Nullhypothese halbiert (von .006 auf 0.0029). Ebenso berichten Buttrick et al. eine Effektgröße von r = 0.39. Für t-Tests ist es der Regel üblicher eine Effektgröße von Cohen’s d anzugeben. Rosnow und Rosenthal (2003) berichten folgende Formel zur Berechnung der Effektgröße r bei einem t-Test für unabhängige Stichproben:t kennzeichnet den empirischen t-Wert und df die Freiheitsgrade des erweiterten Modells. Setzen wir diese Werte die Formel ein, erhalten wir das gleiche Ergebnis wie Buttrick et al. (2018):Wir hätten es uns aber auch einfacher machen können, indem wir r aus der Wurzel aus PRE berechnen. Erinnere dich aus dem Modul zur einfachen linearen Regression, dass PRE auch als R2 bezeichnet wird und das Quadrat des Korrelationskoeffizienten r ist. Wenn wir daher die Wurzel aus PRE ziehen, sollten wir r erhalten:Und ist es auch. Der Vollständigkeit halber können wir zudem noch die Effektgröße Cohen’s d berechnen. Du hast bereits gesehen, dass wir r dem t-Wert und den Freiheitsgraden des erweiterten Modells berechnen können. Ebenso können wir aus diesen beiden Werte durch folgende Formel Cohen’s d bei einem t-Test für unabhängige Stichproben berechnen:Mehr Informationen zur Umrechnung von Effektgrößen findest du hier.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"zusammenfassung-15","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.3.4 Zusammenfassung","text":"Entscheidend für uns ist dieser Stelle, dass wir gezeigt haben, dass wir den t-Test für unabhängige Stichproben durch unser gängiges Verfahren berechnen konnten. Ein entscheidender Schritt dorthin war die Aufstellung eines Kontrastes, der es ermöglicht die Gruppenzugehörigkeit numerische Werte zu überführen. Durch die Wahl eines Helmert-Kontrasts konnten wir das erweiterte Modell aufstellen, dass der Parameter b1 für den Mittelwertsunterschied der beiden Gruppen steht. Zum Schluss haben wir gezeigt, dass der t-Wert die Wurzel aus dem F-Wert ist und dass man Effektgrößen mit verschiedenen Formeln umrechnen kann.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"einfaktorielle-varianzanalyse-anova","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4 Einfaktorielle Varianzanalyse (ANOVA)","text":"Das Ziel dieses Submoduls ist folgende Forschungsfrage zu beantworten: Macht es für die Erinnerungsleistung aus einem Vortrag einen Unterschied, mit welchem Medium Studierende während des Vortrags mitschreiben. Genauer möchten wir diesem Submodul mit Hilfe des Datensatzes von Morehead et al. (2014) klären, ob Studierende, die während einem Vortrag per Hand mitschreiben mehr aus einem Vortrag behalten als Studierende, die mit einem Laptop beziehungsweise einem E-Writer mitschreiben. Morehead et al. (2014) haben diese Fragestellung zwar nicht dieser Form explizit ihrem Artikel gestellt, da sie eine sogenannte mehrfaktorielle Varianzanalyse berechnet haben, allerdings zweckentfremden wir den Datensatz diesem Fall für unsere Fragestellung, da wir bisher noch nichts über die mehrfaktorielle Varianzanalyse erfahren haben.Wir werden erneut folgendes Prozedere verwenden: Zunächst überlegen wir uns die Kontrastkodierung für unsere Gruppen. Anschließend berechnen wir das erweiterte und kompakte Modell auf Grundlage dieser Kontrastkodierung. Anschließend berechnen wir zwei Tests. Einen allgemeinen F-Test mit einem Freiheitsgrad von 2, mit welchem wir prüfen, ob es überhaupt Mittelwertsunterschiede zwischen den drei Gruppen gibt. Dieser Test wird allerdings nicht unsere eigentliche Fragestellung beantworten. Daher testen wir als nächstes einen spezifischen Kontrast, der prüft, ob Studierende, die während einem Vortrag per Hand mitschreiben mehr aus einem Vortrag behalten als Studierende, die mit einem Laptop beziehungsweise einem E-Writer mitschreiben.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"aufstellen-der-kontrastkodierung-1","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.1 Aufstellen der Kontrastkodierung","text":"Beginnen wir erneut damit, die Kontraste zu definieren. Und verwenden wir erneut einen Helmert-Kontrast, welcher uns ermöglicht, die Parameter des erweiterten Modells als Mittelwertsunterschiede der Gruppen darzustellen. Da wir drei Gruppen haben, benötigen wir unserem erweiterten Modell zwei Prädiktoren und drei Parameter. Folgende Kontrastkodierung kodiert unsere Fragestellung (siehe X1):Diese Konstrastkodierung führt dazu, dass der Parameter b1 die Mittelwertsdifferenz der Gruppe der Studierenden, welche per Hand schreiben und der anderen beiden Gruppen kodiert. Wir werden gleich zeigen, dass das stimmt. Der zweite Kontrast führt dazu, dass b2 die Mittelwertsdifferenz der Laptopgruppe und der E-Writer-Gruppe kodiert.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"allgemeiner-f-test","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.2 Allgemeiner F-Test","text":"Wir haben zu Beginn dieses Submoduls gesagt, dass wir zwei F-Tests berichten. Zunächst berechnen wir einen allgemeinen F-Test, durch welchen wir prüfen können, ob sich irgendwelche Mittelwerte zwischen den drei Gruppen unterscheiden. Dieser Test heißt allgemein, da der Freiheitsgrad des erweiterten Modells größer als 1 ist. Immer wenn dies der Fall ist, ist eine Interpretation der Ergebnisse schwierig. Beispielsweise können wir auf Grundlage dieses Ergebnisses nicht herausfinden, welche Gruppen sich voneinander unterscheiden. Dennoch, der allgemeine F-Test wird durch alle gängigen Softwares berichtet und wir sollten daher wissen, welche Fragestellung er testet.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"aufstellen-des-hypothesenpaares","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.2.1 Aufstellen des Hypothesenpaares","text":"Bei dem allgemeinen F-Test prüfen wir, ob es irgendwelche Mittelwertsunterschiede zwischen den drei Gruppen gibt. Hierzu setzen wir sowohl die Parameter b1 und b2 im kompakten Modell auf 0:Da wir einen Helmert-Kontrast verwenden, wissen wir, dass b0 im erweiterten Modell den Mittelwert der drei Gruppenmittelwerte kodiert. b1 kodiert den Mittelwertsunterschied zwischen den Studierenden, die per Hand mitschrieben und den Studierenden, die mit einem E-Writer bzw. einem Laptop mitschrieben. b2 kodiert den Mittelwertsunterschied zwischen diejenigen Studierenen, die mit dem Laptop mitschrieben und diejenigen Studierenden, die mit einem E-Writer mitschrieben. b0 im kompakten Modell kodiert den Mittelwert der abhängigen Variable. unserem Fall ist die abhängige Variable das konzeptuelle Wissen der Studierenden aus dem Vortrag.Folgende Modelle erhalten wir:Ein Blick auf die Mittelwerte der Gruppen zeigt uns, dass die Parameter der Tat die Mittelwertsunterschiede der Gruppen kodieren. Beispielsweise liegt b1 bei 0.028. Dies ist der Mittelwertsunterschied der per Hand-Gruppe und den restlichen beiden Gruppen: 0.269 - ((0.25 + 0.233) / 2) = 0.028.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"berechnung-der-kennwerte","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.2.2 Berechnung der Kennwerte","text":"Nun, da wir das Modellpaar kennen, können wir den F-Wert berechnen:Die genauen Schritte zur Berechnung dieser Kennwerte kannst du erneut folgendem R-Skript nachrechnen. Ich erwarte nicht, dass du das Skript komplett verstehst. Es ist eher für interessierte Studierende gedacht, die wissen wollen, wie die Kennwerte berechnet werden.TODO: Einfügen Datei morehead_allgemeiner_f_test.RWir erhalten ein nicht-signifkantes Ergebnis. Das heißt, der Mittelwertsunterschied, welchen wir unserer Stichprobe erhalten haben, ist nicht sonderlich unwahrscheinlich, wenn wir annehmen, dass es Wirklichkeit keinen Mittelwertsunterschied zwischen den Gruppen gibt. Wir bleiben daher bei der Nullhypothese, dass es keinen Mittelwertsunterschied zwischen den drei Gruppen gibt.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"testen-der-spezifischen-hypothese","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.3 Testen der spezifischen Hypothese","text":"Der allgemeine F-Test wird von fast allen Softwares berichtet, er beantwortet allerdings nicht unsere Fragestellung. Wir wollten wissen, ob Studierende, die per Hand mitschreiben mehr aus einem Vortrag lernen als Studierende, die mit einem technischen Gerät mitschreiben (Laptop oder E-Writer). Es kann der Fall eintreten, dass der allgemeine F-Test keine Signifikanz zeigt, ein spezifischer Kontrast aber schon. Prüfen wir daher diese Hypothese mit Hilfe einer Kontrastanalyse.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"aufstellen-des-statistischen-modellpaares","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.3.1 Aufstellen des statistischen Modellpaares","text":"Beginnen wir mit den beiden Modellen. Das erweiterte Modell ist das gleiche Modell wie beim allgemeinen F-Test. Die beiden Parameter b1 und b2 kodieren die im Helmert-Kontrast kodierten Kontraste. Im kompakten Modell nehmen wir , dass der Mittelwertsunterschied zwischen den Studierenden, die per Hand mitschreiben mit den Studierenden, die mit einem technischen Gerät mitschreiben gleich ist. Wir berechnen daher ein Modell, bei dem b1 auf 0 gesetzt wird.Folgende Modelle erhalten wir (siehe Bild unten). Wie du siehst, sind die Werte bei b0 und b2 zwischen beiden Modellen unterschiedlich. Dies ist dadurch zu erklären, dass wir die Parameter für jedes Modell eigens berechnen. Die Zahlen ändern sich allerdings nur minimal, da wir orthogonale Kontraste berechnet haben.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"berechnung-der-kennwerte-1","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.3.2 Berechnung der Kennwerte","text":"Nun, da wir die Modelle berechnet haben, können wir die Kennwerte berechnen und berichten:Erneut findest du anbei das R-Skript, mit denen ich diese Kennwerte berechnet habe:TODO: Einfügen Datei morehead_spezifischer_test.RWir erhalten erneut ein nicht-signifikantes Ergebnis. Dies bedeutet, dass wir weiter davon ausgehen, dass Studierende, die per Hand bei einem Vortrag mitschreiben sich genauso viel aus dem Vortrag erinnern wie Studierende, die mit einem technischen Gerät mitschreiben.Zum Schluss müssen wir noch eine Korrektur vornehmen: Wir wollten wissen, ob Studierende, die per Hand mitschreiben mehr aus einem Vortrag lernen als Studierende, die mit einem technischen Gerät mitschreiben. Der F-Test testet allredings ungerichtet, weshalb wir unserem Fall den p-Wert halbieren müssen. Das können wir, da die Mittelwerte der Gruppen hypothesenkonform sind. Das heißt, die Differenz des Mittelwerts der Studierenden, die per Hand mitgeschrieben haben ist um 0.02758 größer als der Studierenden, die mit einem technischen Gerät mitgeschrieben haben. Der korrekte p-Wert lautet daher p = .218.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"zusammenfassung-16","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.4.4 Zusammenfassung","text":"Wir haben diesem Modul gezeigt, wie und wir mit einer einfaktoriellen Varianzanalyse berechnen. Dabei haben wir gesehen, dass der t-Test für unabhängige Stichproben und die einfaktorielle Varianzanalyse sich nur der Anzahl der Parameter im erweiterten Modell unterscheiden. Beim t-Test für unabhängige Stichproben hat das erweiterte Modell zwei Parameter und maximal einen Kontrast. Bei einer einfaktoriellen Varianzanalyse gibt es unendliche viele Möglichkeiten der Anzahl der Parameter. Beide Tests verwenden allerdings die gleiche Prozedur, welche wir bereits kennen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"post-hoc-analysen","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.5 Post-Hoc Analysen","text":"den letzten beiden Submodulen haben wir Hypothesen getestet. Das heißt, wir hatten Annahmen, die wir statistisch geprüft haben. Das Gegenteil dieser Vorgehensweise sind sogenannte Post-Hoc Tests oder explorative Tests. Manchmal haben wir keine konkrete Hypothese und möchten alle Gruppenvergleiche einer einfaktoriellen Varianzanalyse testen. Dies schafft allerdings das Problem der Alpha-Fehler Kumulierung.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"alpha-fehler-kumulierung","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.5.1 Alpha-Fehler Kumulierung","text":"Wir wissen aus dem Modul zum statistischen Hypothesentesten, dass wir bei einem Alpha-Niveau von 5% 5% der Fälle die Nullhypothese fälschlicherweise ablehnen. Beispielsweise könnte es sein, dass Studierende, die per Hand mitschreiben tatsächlich mehr aus einem Vortrag lernen als Studierende, die mit einem technischen Gerät mitschreiben. Je mehr Tests wir allerdings rechnen, desto höher wird die Wahrscheinlichkeit, dass wir einen Alpha-Fehler erhalten. Wir können diese Wahrscheinlichkeit berechnen. Im folgenden siehst du, wie diese sogenannte Family-Wise-Error-Rate berechnet wird:α steht für das Alpha-Niveau und c für die Anzahl der Tests. Nehmen wir , du hast zu Beginn deiner Studie keine Hypothesen und vergleichst 3 Gruppen nach ihrer Signifikanz. Beispielsweise jene drei Gruppen aus unserem letzten Submodul (Mitschrift per Hand, Laptop und E-Writer). diesem Fall läge die Wahrscheinlichkeit für einen Alpha-Fehler (sofern die Nullhypothese stimmt) bei 14.3%. Bei 10 Tests wiederum läge diese Wahrscheinlichkeit bei 40%. Bei 20 Tests wiederum bei 64%. Grafisch dargestellt siehst du, dass bei 80 Tests die Chance für einen Alpha-Fehler bei fast 100% liegt.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"bedeutung-der-alpha-fehler-kumulierung-für-die-statistische-praxis","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.5.2 Bedeutung der Alpha-Fehler Kumulierung für die statistische Praxis","text":"Stell dir folgenden ethisch-fragwürdigen Forscher mit dem Namen Professor Müller vor: Professur Müller möchte auf jeden Fall zeigen, dass er signifikante Ergebnisse einem Experiment gefunden hast. Zwar weißt du mittlerweile, dass die Signifikanz nicht mit der praktischen Bedeutsamkeit gleichzusetzen ist, allerdings glaubt Professor Müller dennoch, signifikanz bedeutet wichtig. Herr Müller hatte eine Hypothese, die er anhand von 5 Gruppen und einer einfaktoriellen Varianzanalyse getestet hat. Er erhielt ein nicht-signifikantes Ergebnis und war enttäuscht. Er jedoch etwas “rausbekommen.” Daher vergleicht er einfach alle Mittelwertsvergleiche durch t-Tests. Bei fünf Tests liegt die Wahrscheinlichkeit für einen Alpha-Fehler bei 22,6%. Tatsächlich findet er ein signifikantes Ergebnis und schreibt seinen Artikel um als hätte er von Beginn , diesen Mittelwertsunterschied geglaubt.Dieses Verfahren wird auch als Harking bezeichnet (Hypothesizing results known). Harking geschieht, wenn Wissenschaftler*innen explorative Analysen als Hypothesen ausgeben, die sie von Anfang aufgestellt haben. Harking ist problematisch, da es dazu führt, dass mehr Alpha-Fehler als Effekte berichtet werden als wenn Wissenschaftler*innen bei ihren Hypothesen bleiben, die sie vor einem Experiment aufgestellt haben. Und eine Methode hierfür ist, bei einer einfaktoriellen Varianzanalyse alle Gruppenvergleiche zu rechnen und nur die signifikanten zu berichten. anderen Worten, eine explorative Analyse wird als Hypothese ausgegeben (siehe auch Gernsbacher, 2018). Wir sollten daher bei explorativen Analysen immer sogenannte Post-Hoc Tests (explorative Analysen) die Alpha-Fehler-Kumulierung kontrollieren. Es gibt viele Tests, die uns das ermöglichen. Wir lernen dieser Stelle die bekannteste kennen: Die Bonferroni-Korrektur.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"bonferroni-korrektur","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.5.3 Bonferroni-Korrektur","text":"Die einfachste Methode, um sicher zu stellen, dass sich die Alpha-Fehler nicht mit der Anzahl der Tests kumulieren ist die Bonferroni-Korrektur. Bei der Bonferroni-Korrektur wird der Alpha-Fehler durch die Anzahl der Tests geteilt:Wenn du beispielsweise drei Gruppenvergleiche explorativ testest, teilst du das Alpha-Niveau von 0.05 durch 3. Dadurch entscheidest du dich für ein signifikantes Ereignis nur dann, wenn p für jeden Test unter den Wert 0.0167 fällt. Die Bonferroni-Korrektur hat den Nachteil, dass sie sehr konservativ ist und zu einer geringeren Power führt (siehe VanderWeele & Mathur, 2019). Falls also ein Effekt vorliegt, verringert sich durch dieses Korrekturverfahren die Wahrscheinlichkeit, dass wir diesen Effekt finden. Dies ist dadurch zu erklären, dass wir die Nullhypothese erst ablehnen, wenn der empirische p-Wert unter dem korrigiertem kritischen p-Wert fällt.Jamovi wird die Bonferroni-Korrektur nicht dadurch angegeben, dass der kritische p-Wert adjustiert wird, sondern, indem der empirische p-Wert angepasst wird. Dies geschieht, indem der empirische p-Wert mal der Anzahl der Tests gerechnet wird. Erhält man aus drei Tests beispielsweise die p-Werte .03, .01 und .02, dann werden diese jeweils mal drei gerechnet: .09, .03, .06.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"zusammenfassung-und-weitere-korrekturmethoden","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.5.4 Zusammenfassung und weitere Korrekturmethoden","text":"Es gibt eine ganze Reihe weiterer Korrekturverfahren, die wir diesem Seminar nicht beantworten werden. Mehr Informationen zu diesen Testverfahren kannst du bei Shaffer (1995) finden. Für unsere Zwecke ist es wichtig zu wissen, dass der Alpha-Fehler bei einer Reihe explorativer Tests kontrolliert werden sollte. Ansonsten läuft man Gefahr, zu oft Alpha-Fehler zu machen.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"berechnung-in-jamovi-3","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.6 Berechnung in Jamovi","text":"den folgenden Videos erkläre ich dir, wie die drei Tests dieses Moduls Jamovi berechnet werden.","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"t-test-für-unabhängige-stichproben-1","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.6.1 t-Test für unabhängige Stichproben","text":"TODO: Einfügen Video","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"einfaktorielle-varianzanalyse-1","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.6.2 einfaktorielle Varianzanalyse","text":"TODO: Einfügen Video","code":""},{"path":"einfaktorielle-varianzanalyse.html","id":"kontrastanalyse","chapter":"8 Einfaktorielle Varianzanalyse","heading":"8.6.3 Kontrastanalyse","text":"TODO: Einfügen VideoTODO: Stand vorher schon drin:Welch-Test nicht vergessen","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"tatusmehrfaktorielle-varianzanalyse","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9 tatusMehrfaktorielle Varianzanalyse","text":"","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"einführung-7","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.1 Einführung","text":"Stell dir folgendes Szenario vor: Du hast kürzlich einen Artikel über den Expertise-Reversal Effect gelesen. diesem Artikel wird erläutert, dass manche Lernstrategien für Menschen mit geringem Vorwissen  einem Thema effektiver sind als für Menschen mit hohem Vorwissen. Eine Woche später sitzt du einem Seminar über Lehrstrategien. Deine Dozentin stellt dir drei verschiedene Lehrstrategien vor. Problembasiertes Lernen, projektbasiertes Lernen und die direkte Instruktion. Beim Problembasiertes Lernen werden Lernende angeleitet, Probleme Kleingruppen gemeinsam zu lösen. Das Lehrarrangement ist gestaltet, dass die Lehrkraft minimal instruiiert und den Lernenden Ressourcen die Hand gibt, mit denen sie die Probleme selbstständig lösen können (Hmelo-Silver, 2004). Projektbasiertes Lernen hat einen ähnlichen Ansatz, nur dass dort anstatt Probleme gelöst, Projekt entwickelt werden (Barron et al., 1998). Bei der direkten Instruktion ist das Lehrarrangement sehr stark strukturiert, indem die Lehrkraft Kurzvorträge hält, den Lernenden geeignete Übungen und Feedback über diese Übungen gibt (Magliaro et al., 2005). Nach dem Seminar überlegst du, ob die Idee des Expertise-Reversal Effects und der drei Lehrstrategien nicht miteinander kombiniert werden könnte. Du glaubst, dass Noviz*innen, also Menschen mit geringem Vorwissen einem Thema, mehr von der direkten Instruktion und weniger von projekt- und problemorientierten Lernstrategien profitieren als Expert*innen. Der Grund für diese Hypothese ist, dass projekt- und problembasiertes Lernen die Noviz*innen überfordern könnte, da diese Lernenden nicht genug Vorwissen haben, um komplexen Probleme/Projekte zu lösen. Die direkte Instruktion sollte allerdings für Noviz*innen hilfreich sein, da sie sozusagen “die Hand genommen” werden und dadurch ein gutes Verständnis des Lernstoffs aufbauen können. Du entscheidest dich, diese Hypothese deiner Bachelorarbeit zu testen.Die Fragestellung dieses Moduls lautet: Ist direkte Instruktion effektiver als problem- bzw. projektbasiertes Lernen und ist dieser Effekt abhängig vom Vorwissen der Lernenden?","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"mehrfaktorielle-varianzanalyse","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.1.1 Mehrfaktorielle Varianzanalyse","text":"Mit den bisherigen Testverfahren kannst du diese Hypothese allerdings noch nicht testen. Bisher haben wir lediglich die einfaktorielle Varianzanalyse kennen gelernt, mit der wir Gruppenunterschiede eines Faktors prüfen können. Ein Faktor ist eine kategoriale Variable, welche verschiedene Ausprägungen hat. Beispielsweise hatten wir im letzten Modul den Faktor Lernstrategie (Concept Map vs. Retrieval Practice) oder Mitschrift (per Hand, per Laptop, per E-Writer) der einfaktoriellen Varianzanalyse verwendet. Und daher kommt auch der Begriff einfaktoriell. Bei der einfaktoriellen Varianzanalyse verwenden wir nur einen Faktor. Um allerdings deine Hypothese zu prüfen, benötigen wir einen weiteren Faktor (Lehrstrategie und Expertise). diesem Modul werden wir daher lernen, wie eine mehrfaktorielle Varianzanalyse berechnet wird, indem wir deine Hypothese testen.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"datensatz","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.1.2 Datensatz","text":"deiner Bachelorarbeit bist du folgendermaßen vorgegangen: Du hast zunächst Versuchspersonen akquiriert, welche ein unterschiedliches Vorwissen zum Thema natürliche Selektion hatten. Hierzu hast du fortgeschrittene Biologiestudierende (mindestens 5. Fachsemester) und Studienbeginnende des Fachs Biologie rekrutiert. Insgesamt konntest du 76 Personen für dein Experiment gewinnen. Alle Versuchspersonen kamen für zwei Tage dein Labor. Jede Versuchsperson wurde randomisiert die drei Lehrgruppen eingeteilt. Zu Beginn des Experiments wurde das Vorwissen der Versuchspersonen zum Thema natürliche Selektion erhoben. Anschließend nahmen die Versuchspersonen pro Tag für vier Stunden einer Simulation teil, bei der sie ihrem Lehrsetting unterrichtet wurden. Versuchspersonen der projekt- und problemorientierten Lernumgebung interagierten dieser Simulation mit digitalen Kommiliton*innen, mit welchen sie das Projekt umsetzten bzw. das Problem lösten. Versuchspersonen mit der direkten Instruktion erhielten eine Lernumgebung mit den gleichen Inhalten, allerdings wurden sie von einer digitalen Lehrkraft unterrichtet. Eine Woche nach dem letzten Lehrtag kamen die Versuchspersonen erneut das Labor und ihr Wissen über natürliche Selektion wurde erneut geprüft.Den Datensatz für dieses Modul findest du hier:TODO: Einfügen Datei expert_study.csvDer Datensatz umfasst folgende sieben Variablen. Wir interessieren uns diesem Modul für die Variablen expertise, method und improvement:id: Die ID der Versuchspersonid: Die ID der Versuchspersonexpertise: Ein Faktor, welcher kodiert, ob die Person eine Expertin / ein Experte oder eine Novizin / ein Novize ist.expertise: Ein Faktor, welcher kodiert, ob die Person eine Expertin / ein Experte oder eine Novizin / ein Novize ist.age: Das Alter der Personage: Das Alter der Personmethod: Ein Faktor, welcher die Lehrstrategie kodiert, welche die Person bekommen hat (direkte Instruktion, problembasiertes Lernen, projektbasiertes Lernen)method: Ein Faktor, welcher die Lehrstrategie kodiert, welche die Person bekommen hat (direkte Instruktion, problembasiertes Lernen, projektbasiertes Lernen)test_prior: Das Vorwissen der Testperson zum Thema natürliche Selektiontest_prior: Das Vorwissen der Testperson zum Thema natürliche Selektiontest_delay: Das Wissen zum Thema natürliche Selektion der Person eine Woche nach dem Ende der Lehrsituationtest_delay: Das Wissen zum Thema natürliche Selektion der Person eine Woche nach dem Ende der Lehrsituationimprovement: Die Differenz zwischen dem Wissen Ende des Experiments (test_delay) und dem Wissen vor dem Experiment (test_prior). Höhere Werte bedeuten, dass die Person mehr Wissen erworben hat.improvement: Die Differenz zwischen dem Wissen Ende des Experiments (test_delay) und dem Wissen vor dem Experiment (test_prior). Höhere Werte bedeuten, dass die Person mehr Wissen erworben hat.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"mehrfaktorielle-versuchsdesigns","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.2 Mehrfaktorielle Versuchsdesigns","text":"Hörst du Wissenschaftler*innen zu, sprechen sie manchmal von einem 2x2 (zwei mal zwei), 2x3 oder auch einem 3x3 Design. sie damit meinen ist, dass das Versuchsdesign mehrere Faktoren beeinhaltet, die verschiedene Ausprägungen haben.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"einfaktorielle-designs","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.2.1 Einfaktorielle Designs","text":"Versuchen wir uns dieser Idee anzunäheren und beginnen wir mit einem 2 Design. diesem Design gibt es nur einen Faktor, welcher allerdings verschiedene Ausprägungen hat. Zum Beispiel haben wir im letzten Modul getestet, ob Studierende, die sich testen ( (Retrieval Practice), mehr konzeptuelles Wissen erlernen als Studierende, die eine Concept Map erstellen:Ein solches Design nennen wir einfaktorielles Design. Wir könnten auch sagen, es ist ein 2 Design. Im letzten Modul haben wir ebenso die Hypothese getestet, ob sich Studierende, die per Hand mitschreiben, sich mehr die Inhalte aus einem Vortrag erinnern als Studierende, die mit einem Laptop oder E-Writer mitschreiben:+========================+:========:+:===========:+==============+ +————————+———-+————-+————–+Dieses Design könnn wir als 3 Design bezeichnen, da der eine Faktor drei Ausprägungen hat.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"zweifaktorielles-design","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.2.2 Zweifaktorielles Design","text":"Nun, unserer Fragestellung haben wir zwei Faktoren, das Vorwissen und die Lehrstrategie. Daher sprechen wir von einem zweifaktoriellen Design. Grafisch können wir diese Faktoren wie folgt darstellen:Ein solches Design nennt man 3x2 Design, da es zwei Faktoren umfasst und diese Faktoren drei und zwei Ausprägungen haben. Der Faktor Lehrsetting hat drei Ausprägungen (projektbasiertes Lernen, problembasiertes Lernen, direkte Instruktion) und der Faktor Vorwissen hat zwei Ausprägungen (Experte, Novize). Ein weiteres zweifaktorielles Design könnte wie folgt aussehen:Ein solches Design nennt man 2x2 Design. Der erste Faktor Essen kodiert, ob Versuchspersonen einen Schweinebraten oder eine Eiscreme essen. Der zweite Faktor Sauße kodiert, ob Versuchspersonen auf diesem Essen Schokoladensauße erhalten oder nicht. Mit einem solchen Design könnte man beispielsweise testen, ob der positive Effekt von Schokoladensauße auf Essen nur für Eiscreme und nicht für Schweinebraten gilt. Man würde erwarten, dass Schokosauße auf Schweinebraten nicht schmeckt, während Schokosauße auf Eiscreme durchaus lecker schmeckt.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"dreifaktorielles-design","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.2.3 Dreifaktorielles Design","text":"Wir könnten diese Idee unendlich weiter spinnen. Beispielsweise einem dreifaktoriellen Design. Ein 2x3x2 Design beispielsweise könnte folgendermaßen aussehen: Der erste Faktor kodiert, ob eine Person schon einmal einen Workshop zum Thema Moderation teilgenommen hat oder nicht (2 Ausprägungen). Der zweite Faktor kodiert, welches Training zum Thema Moderation eine Person bekommt (3 Ausprägungen). Der dritte Faktor kodiert, ob der Workshop zwei Tage aufgeteilt wurde oder nicht (2 Ausprägungen). Ein solches Design ist durchaus komplexer als ein zwei faktorielles Design. Man könnte damit beispielsweise testen, ob die zeitliche Verteilung eines Workshops nur effektiv für Menschen ist, welche ein bestimmtes Training bekommen und gleichzeitig nur für Menschen effektiv ist, die bereits einem Training teilgenommen haben. Wir werden diesem Modul auf ein solches Design verzichten und ein klassisches zweifaktorielles Design berechnen.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"allgemeines-zu-mehrfaktoriellen-designs","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.2.4 Allgemeines zu mehrfaktoriellen Designs","text":"jedem mehrfaktoriellen Design werden Versuchspersonen der Regel Gruppen eingeteilt. Beispielsweise werden bei einem 2x3 Design, Versuchspersonen sechs Gruppen eingeteilt. Dies gilt allerdings nur, wenn die Versuchspersonen nicht mehrmals getestet werden, sprich wenn es kein Within-Design ist. diesem Kurs testen wir nur Hypothesen, denen Personen nicht mehrmals getestet wurden, sondern denen Personen Gruppen aufgeteilt werden. Ein solches Design nennt man -Subjects Design. Genauer würden wir sagen, dass wir diesem Modul ein 2x3 -Subjects Design testen. Die Anzahl der Gruppen jedem -Subjects Design können wir berechnen, indem wir die Anzahl der Ausprägungen pro Faktor multiplizieren:Für unser Experiment musst du daher die Versuchspersonen sechs Gruppen aufteilen. Im nächsten Schritt müssen wir diese Gruppen numerische Werte überführen und eine Kontrastkodierung bestimmten, um die statistischen Modelle aufzustellen.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"kontrastkodierung","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.3 Kontrastkodierung","text":"Das Ziel dieses Submoduls ist es, unsere Alternativhypothese ein statistisches Modell zu überführen. Hierfür müssen wir zunächst eine Kontrastkodierung wählen, durch die Parameter unseres Modells die Gruppenunterschiede kodieren, welche wir später testen möchten. Beispielsweise werden wir diesem Modul verstehen, wie die Kontrastkodierung aussehen muss, um zu testen, ob der Effekt der direkten Instruktion im Vergleich zu den anderen beiden Lehrsettings zwischen Expert*innen und Noviz*innen unterschiedlich ist. Man nennt diese Methode Interaktion. Beginnen wir mit der Kontrastkodierung, die wir schon kennen.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"konstrastkodierung-lehrstrategie","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.3.1 Konstrastkodierung Lehrstrategie","text":"deiner Hypothese gehst du davon aus, dass die direkte Instruktion lernwirksamer ist als problem- bzw. projektbasiertes Lernen. Da der Faktor Lehrstrategie drei Ausprägungen umfasst, benötigst du k - 1 = 3 - 1 = 2 Prädiktoren, um diesen Faktor im erweiterten Modell zu kodieren. Mit folgender Kontrastkodierung kannst du diese erste Hypothese später testen:Du siehst, dass wir für diesen Faktor eine Helmert-Kodierung verwendet haben. Durch die Helmert-Kodierung wird der Parameter b1 den Mittelwertsunterschied zwischen der Gruppe der direkten Instruktion und den anderen beiden Gruppen kodieren. Der Parameter b2 wird den Mittelwertsunterschied zwischen der Gruppe, welche problembasiertes Lernen und der Gruppe, die projektbasiertes Lernen erhält, kodieren.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"konstrastkodierung-expertinnen","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.3.2 Konstrastkodierung Expert*innen","text":"Weiterhin möchtest du den Mittelwertsunterschied zwischen Expert*innen und Noviz*innen kodieren. Da du später wissen möchtest, ob die direkte Instruktion nur für Noviz*innen und nicht für Expert*innen wirksam ist, benötigst du eine Kodierung, die den Mittelwertsunterschied von Expert*innen und Noviz*innen unterscheidet. Hierfür verwenden wir erneut eine Helmert-Kodierung. Du hast zwei Ausprägungen, daher benötigst du lediglich einen Prädiktor, um diesen Unterschied zu kodieren:","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"kodierung-der-interaktion","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.3.3 Kodierung der Interaktion","text":"Nun, deine zentrale Fragestellung ist, ob der positive Effekt der direkten Instruktion für Noviz*innen zu finden ist und bei Expert*innen ausbleibt. Mit der bisherigen Kontrastkodierung würden wir den einzelnen Gruppen folgende Kontrastgewichte pro Prädiktor zuordnen:Bei einer Expertin beispielsweise, die die direkte Instruktion bekommt, würden wir für X1 2/3, für X2 0 und für X3 1/2 einsetzen. Du siehst anhand der Tabelle ebenso, welche Hypothese wir mit jedem der drei Prädiktoren testen können. Mit Hilfe von X1 beispielsweise können wir testen, ob Versuchspersonen, die direkte Instruktion bekommen, besser abschneiden als Versuchspersonen, die die anderen beiden Strategien erhalten. Ebenso kannst du erkennen, dass wir mit Hilfe von X3 kodieren können, ob sich der Wissenserwerb zwischen den Expert*innen und den Noviz*innen unterscheidet. Nun, deine Fragestellung ist allerdings, ob der Effekt, den wir mit X1 kodieren, abhängig vom Effekt ist, den wir mit X3 kodieren? Wir können eine solche Interaktion testen, indem wir die Kodierungen der einzelnen Prädiktoren miteinander multiplizieren:Nun, diese Tabelle ist auf den ersten Blick vermutlich verwirrend. haben wir hier gemacht? Formal haben wir nichts anderes gemacht, als die Kodierungen für die Prädiktoren zwischen den Gruppen miteinander multipliziert. Man nennt ein solches Verfahren eine Interaktion. Genauer haben wir X1 mit X3 und X2 mit X3 multipliziert. Da wir fünf Prädiktoren haben, ergibt sich daraus folgendes erweitertes Modell:Die Parameter diesem Modell haben nun folgende Bedeutung:b0: Der Mittelwert der Mittelwert der aller Gruppen (siehe sechs Gruppen der oberen Tabelle)*\n\nb0: Der Mittelwert der Mittelwert der aller Gruppen (siehe sechs Gruppen der oberen Tabelle)*b1: Der Mittelwertsunterschied zwischen den Gruppen, welche die direkte Instruktion erhalten haben, und den anderen beiden Lehrstrategiegruppen.b1: Der Mittelwertsunterschied zwischen den Gruppen, welche die direkte Instruktion erhalten haben, und den anderen beiden Lehrstrategiegruppen.b2: Der Mittelwertsunterschied zwischen den Gruppen, welche problembasiertes Lernen erhalten haben, und den Gruppen, welche projektbasiertes Lernen erhalten haben.b2: Der Mittelwertsunterschied zwischen den Gruppen, welche problembasiertes Lernen erhalten haben, und den Gruppen, welche projektbasiertes Lernen erhalten haben.b3: Der Mittelwertsunterschied zwischen den Expertengruppen und den Novizengruppenb3: Der Mittelwertsunterschied zwischen den Expertengruppen und den Novizengruppenb4: Differenz der Mittelwertsunterschiede der direkten Instruktion und den anderen beiden Lehrstrategien zwischen den Expert*innen und den Noviz*innen? anderen Worten: Ist der Mittelwertsunterschied, der b0 kodiert ist, zwischen Expert*innen und Noviz*innen gleich? Oder, profitieren Noviz*innen mehr von der direkten Instruktion als Expert*innen ?b4: Differenz der Mittelwertsunterschiede der direkten Instruktion und den anderen beiden Lehrstrategien zwischen den Expert*innen und den Noviz*innen? anderen Worten: Ist der Mittelwertsunterschied, der b0 kodiert ist, zwischen Expert*innen und Noviz*innen gleich? Oder, profitieren Noviz*innen mehr von der direkten Instruktion als Expert*innen ?b5: Differenz der Mittelwertsunterschiede des problembasierten Lernens und des projektbasierten Lernens zwischen den Expert*innen und den Noviz*innen? anderen Worten: Ist der Mittelwertsunterschied, der b1 kodiert ist zwischen Expert*innen und Noviz*innen gleich? Oder, profitieren Noviz*innen mehr von problembasiertem Lernen als von projektbasiertem Lernen als Expert*innen?b5: Differenz der Mittelwertsunterschiede des problembasierten Lernens und des projektbasierten Lernens zwischen den Expert*innen und den Noviz*innen? anderen Worten: Ist der Mittelwertsunterschied, der b1 kodiert ist zwischen Expert*innen und Noviz*innen gleich? Oder, profitieren Noviz*innen mehr von problembasiertem Lernen als von projektbasiertem Lernen als Expert*innen?Insbesondere die letzten beiden Parameter sind nun interessant. Um diese besser zu verstehen, schauen wir uns ein Liniendiagramm der Mittelwert der sechs Gruppen :Und schauen wir b4 genauer . Dieser Parameter zeigt die Differenz zwischen dem Mittelwertsunterschied der direkten Instruktion und den anderen beiden Lehrstrategien bei den Noviz*innen und dem Mittelwertsunterschied der direkten Instruktion und den anderen beiden Lehrstrategien bei den Expert*innen . der Grafik erkennst du bereits, dass Noviz*innen mehr von der direkten Instruktion profitiert haben als von den anderen beiden Lehrstrategien. Bei den Expert*innen war dies nicht der Fall, da die Mittelwerte aller Lehrstrategiegruppen sehr nah beieinander liegen. Wir können dies noch genauer zeigen, indem wir nur die beiden Lehrstrategien betrachten:Schätzen wir einmal die Mittelwertsunterschiede zwischen beiden Gruppen. Bei den Noviz*innen lag der Wissenserwerb derjenigen, welche die direkte Instruktion bekommen haben, bei etwa 5.9. Der Mittelwert der anderen beiden Lehrstrategien der Noviz*innen lag bei etwa 2.8. Bei den Expert*innen lag der Wissenserwerb derjenigen, welche die direkte Instruktion bekommen haben, bei etwa 4.2. Der Mittelwert der anderen beiden Lehrstrategien der Expert*innen lag bei etwa 3.9. Berechnen wir die Differenz dieser Werte zwischen den beiden Gruppen:Uns interessiert insbesondere die grüne Zelle. Dies ist der Mittelwertsunterschied der beiden Mittelwertsunterschiede voneinander. Die direkte Instruktion bei den Noviz*innen im Vergleich zu den anderen beiden Lehrstrategien war demnach um 2.8 Punkte höher als bei den Expert*innen. Und genau dies drückt der Parameter b4 nun durch unsere Interaktion aus. Das erweiterte Modell, welches sich aus unserer Kontrastkodierung ergibt, sieht wie folgt aus:Wie du siehst, liegt b4 bei 2.70. Der kleine Unterschied von 2.8 zu 2.7 liegt Rundungsfehlern. Der Parameter der anderen Interaktion liegt bei 0.90. Mit diesem Modell sind wir nun der Lage, folgende Hypothesen zu testen, indem wir einzelne Parameter auf 0 schalten:b1 (1.703) auf 0: Ist die direkte Instruktion lernförderlicher als die anderen beiden Lehrstrategien?b1 (1.703) auf 0: Ist die direkte Instruktion lernförderlicher als die anderen beiden Lehrstrategien?b2 (-0.008) auf 0: Ist problembasiertes Lernen lernförderlicher als projektbasiertes Lernen?b2 (-0.008) auf 0: Ist problembasiertes Lernen lernförderlicher als projektbasiertes Lernen?b3 (-0.15) auf 0: Ist der Wissenserwerb bei Expert*innen höher/unterschiedlich als bei Noviz*innen?b3 (-0.15) auf 0: Ist der Wissenserwerb bei Expert*innen höher/unterschiedlich als bei Noviz*innen?b4 (2.70) auf 0: Ist der Effekt der direkten Instruktion bei den Noviz*innen größer/unterschiedlich als bei den Expert*innen?b4 (2.70) auf 0: Ist der Effekt der direkten Instruktion bei den Noviz*innen größer/unterschiedlich als bei den Expert*innen?b5 (0.90) auf 0: Ist der Effekt des problembasierten Lernens gegenüber dem projektbasierten Lernen bei den Noviz*innen größer/unterschiedlich als bei den Expert*innen?b5 (0.90) auf 0: Ist der Effekt des problembasierten Lernens gegenüber dem projektbasierten Lernen bei den Noviz*innen größer/unterschiedlich als bei den Expert*innen?Wir werden im folgenden einzelne dieser Parameter auf 0 schalten und demnach verschiede Hypothesen testen. Dabei werden wir sowohl Haupteffekte, Interaktionen, Simple Effects als auch Kontraste testen. Bei jedem dieser Verfahren werden wir andere Parameter auf 0 schalten.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"zusammenfassung-17","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.3.4 Zusammenfassung","text":"diesem Submodul haben wir gezeigt, wie man mehrere Faktoren als Konstrastkodierung ein erweitertes Modell integrieren kann. Dabei haben wir festgestellt, dass wir für jeden einzelnen Faktor die gleiche Kontrastkodierung verwenden können, welche wir im letzten Modul kennen gelernt haben. Ebenso konnten wir zeigen, dass wir durch die Multiplikation der Kontraste sogenannte Interaktionen berechnen können. Interaktionen ermöglichen uns, zu überprüfen, wie unterschiedlich bestimmte Mittelwertsunterschiede zwischen den Ausprägungen eines anderen Faktors sind. Durch dieses Verfahren können wir unseren statistischen Werkzeugkasten erweitern, indem wir spezifischere Hypothesen testen können. Dies werden wir nachfolgend tun.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"statistisches-hypothesentesten-haupteffekte","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.4 Statistisches Hypothesentesten: Haupteffekte","text":"der mehrfaktoriellen Varianzanalyse wird meist zwischen Haupteffekten und Interaktionen unterschieden. Ein Haupteffekt prüft, ob es Gruppenunterschiede innerhalb eines Faktors gibt. unserem Beispiel haben wir zwei Faktoren (Lehrstrategien und Expertise). Das heißt, wir können zwei Haupteffekte berechnen. Haupteffekte sind demnach von der Logik nichts anderes als die einfaktorielle Varianzanalyse, allerdings einem Modell, welches mehrere Faktoren umfasst.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"haupteffekt-des-faktors-lehrstrategie","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.4.1 Haupteffekt des Faktors Lehrstrategie","text":"Beginnen wir mit dem ersten Faktor. Im letzten Submodul haben wir das erweiterte Modell aufgestellt, mit Hilfe dessen wir unsere Hypothesen testen können. Nun geht es darum, ein kompaktes Modell zu wählen, welches es uns ermöglicht, diese Hypothesen zu testen und die Wahrscheinlichkeit für den entsprechenden F-Wert zu berechnen. Für den Haupteffekt müssen wir immer alle Parameter eines Faktors im kompakten Modell auf 0 setzen. Da wir drei Gruppen des Faktors Lehrstrategie haben, wird dieser Faktor durch zwei Prädiktoren kodiert. Daher müssen wir die Parameter, die die Gruppenunterschiede der Lehrstrategien kodieren, auf 0 setzen:Durch diese Modelle können wir nun testen, ob es Mittelwertsunterschiede zwischen den drei Lehrstrategiegruppen gibt. Wohlgemerkt sagt uns dieser Test nicht, welche Gruppen sich voneinander unterscheiden. Wir wissen aber, dass wir den Gruppenunterschied zwischen der direkten Instruktion und den anderen beiden Lehrstrategien testen könnten, wenn wir nur b1 auf 0 setzen. Hier sind die Ergebnisse des Hauptfaktors Lehrstrategie:Mehrere Dinge sind hier wichtig. Zunächst sind die Freiheitsgrade der Modelle etwas schwieriger zu berechnen. Das erweiterte Modell hat sechs Parameter und 76 Datenpunkte (Versuchspersonen). Daher können dieses Modell noch 70 Parameter hinzugefügt werden. Im kompakten Modell sind es zwei Parameter mehr, die hinzufügt werden können, da es zwei Parameter weniger hat als das erweiterte Modell.  PRE liegt bei 0.117. Damit sagen wir, dass das erweiterte Modell 11.7% der Fehler des kompakten Modells erklärt (bzw. der Varianz erklärt). Ansonsten erkennen wir, dass es einen signifikanten Effekt gibt. Das heißt, wir lehnen die Annahme ab, dass sich die drei Gruppenmittelwerte nicht voneinander unterscheiden.Wenn du die Ergebnisse händisch R nachrechnen möchtest, findest du das Skript hier:TODO: Einfügen Datei haupteffekt_lehrstrategien.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"haupteffekt-des-faktors-expertise","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.4.2 Haupteffekt des Faktors Expertise","text":"Ganz ähnlich können wir vorgehen, um zu überprüfen, ob der Wissenserwerb der Expert*innen größer war als der Wissenserwerb der Noviz*innen. diesem Fall müssen wir nur den Parameter b3 auf 0 setzen, da bei zwei Gruppen ein Prädiktor genügt, um den Gruppenunterschied dieser beiden Gruppen zu kodieren:Ein F-Test mit diesem Modellpaar ergibt folgendes Ergebnis:Wir finden einen nicht-signifikanten Effekt. Das heißt, wir gehen weiterhin davon aus, dass der Wissenserwerb (unsere abhängige Variable) sich nicht zwischen den Expert*innen und Noviz*innen unterscheidet. Der Effekt ist zudem minimal, da das erweiterte Modell nur 0.1% der Varianz im kompakten Modell aufklärt.Wenn du die Ergebnisse händisch R nachrechnen möchtest, findest du das Skript hier:TODO: Einfügen Datei haupteffekt_expertise.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"zusammenfassung-18","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.4.3 Zusammenfassung","text":"diesem Submodul haben wir die Haupteffekte der mehrfaktoriellen Varianzanalyse berechnet. Wir haben gesehen, dass wir für jeden Faktor einen Haupteffekt berechnen können. Bei einem Haupteffekt werden zudem alle Parameter eines Faktors auf 0 gesetzt. Dies hat zur Folge, dass bei mehr als zwei Gruppen innerhalb eines Faktors keine Aussagen über die spezifischen Mittelwertsunterschiede gemacht werden können. Wir haben zudem heraus gefunden, dass die Annahme direkte Instruktion ist genauso lehrreich wie problem- oder projektbasiertes Lernen unhaltbar ist. Wir haben ebenso heraus gefunden, dass der Wissenszuwachs bei Expert*innen und Noviz*innen gleich war. Als nächstes berechnen wir den Interaktionseffekt.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"statistisches-hypothesentesten-interaktionseffekt","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.5 Statistisches Hypothesentesten: Interaktionseffekt","text":"Fragen wir uns nun, ob der Effekt der Lehrstrategie (zwischen den drei Gruppen) abhängig von der Expertise der Personen ist. Wir werden im Übrigen diesem Submodul unsere Fragestellung noch nicht zufriedenstellend beantworten können. Dies liegt darin, dass wir diesem Submodul die Interaktion der beiden Haupteffekte testen. Hierdurch kommen wir zwar der Antwort unserer Fragestellung näher, es ist allerdings nicht die Antwort, welche wir schlussendlich wissen wollen. zwei Submodulen werden wir eine schlauere Antwort erhalten. Beginnen wir aber mit dem Interaktionseffekt.Bei einem Interaktionseffekt prüfen wir der Regel die Interaktion aller Faktoren miteinandern. Im statistischen Modell gesprochen, schalten wir daher alle Interaktionen auf 0:Der Interaktionseffekt beantwortet die Frage, ob ein Effekt von den Ausprägungen eines anderen Faktors abhängig ist.Wie du erkennst, haben wir die Parameter b4 und b5 auf 0 geschaltet. Mit dem zugehörigen F-Test prüfen wir, ob der Haupteffekt der Lehrstrategie abhängig ist von der Expertise der Personen. Wir wissen aber auch, dass der Haupteffekt nur sagt, dass sich Gruppen voneinander unterscheiden, nicht, welche Gruppen sich voneinander unterscheiden. Bei einem signifikanten Effekt können wir daher lediglich sagen, dass es beispielsweise bei den Noviz*innen einen Effekt der Lehrstrategien gibt, nicht aber bei den Expert*innen. Testen wir diese Annahme:Tatsächlich, wir finden einen signifikanten Effekt. Der Effekt der Lehrstrategie ist von der Expertise der Personen abhängig. Du siehst allerdings auch, dass der p-Wert gerade unter dem Alpha-Niveau liegt. Läge der p-Wert bei 0.051, würden wir die Nullhypothese annehmen. Da der p-Wert allerdings drei Nachkommastellen kleiner ist, lehnen wir die Nullhypothese ab. Wenn dir das spitzfindig erscheint, ist dem auch . Beachte allerdings, dass wir eine Hypothese nicht mit einem Test widerlegen können. Wiederholen wir viele dieser Tests werden wir mit der Dauer die richtigen Entscheidungen treffen (sofern der Test richtig konstruiert ist; z.B. wenn er eine ausreichend große Power hat). Dabei kann es durchaus sein, dass wir wie diesem Beispiel eine knappe Entscheidung treffen müssen. Egal wie der p-Wert ausfällt, wir treffen die Entscheidung auf der Grundlage unseres Alpha-Niveaus. Daher lehnen wir diesem Fall die Nullhypothese ab. Im Übrigen versuchen Wissenschaftler*innen häufig verzweifelt, dennoch von einem signifikanten Effekt zu sprechen, wenn der p-Wert bei 0.051 oder ähnlich liegt. Eine amüsante Liste, welche Ausdrücke Wissenschaftler*innen dafür verwenden, findest du hier. Diese Versuche sind allerdings fehl Platz und sollten nicht praktiziert werden.Wenn du die Berechnungen R nachvollziehen möchtest, schau dir das folgende Skript :TODO: Einfügen Datei interaktionseffekt.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"zusammenfassung-19","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.5.1 Zusammenfassung","text":"Wir haben nun gezeigt, wie wir den Interaktionseffekt bei einer mehrfaktoriellen Varianzanalyse berechnen können. Die Logik ist wie immer die gleiche wie bei jedem anderen Test. Wir setzen bestimmte Parameter auf 0 und berechnen aus den beiden Modellen einen F-Test. Wir mussten bei diesem Test allerdings feststellen, dass wir unsere Hypothese noch nicht zufriedenstellend beantworten können. zwei Submodulen werden wir erfahren, wie dies geht. Im nächsten Submodul zeigen wir erstmal, wie wir mit signifikanten Interaktionseffekten umgehen.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"statistisches-hypothesentesten-simple-effects","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.6 Statistisches Hypothesentesten: Simple Effects","text":"Du hast einen signifikanten Interaktionseffekt gefunden, nun? Wir wollten ursprünglich wissen, ob der Effekt der direkten Instruktion abhängig ist von der Expertise der Lernenden. Diese Hypothese werden wir durch Simple Effects nicht prüfen können, wir werden allerdings folgende Frage beantworten können: Unterscheidet sich die Lernwirksamkeit der drei Lehrstrategien bei den Expert*innen und unterscheidet sich die Lernwirksamkeit der drei Lehrstrategien bei den Noviz*innen? Du siehst, dass wir zwei Fragestellungen testen. Dies tun wir, indem wir zwei F-Tests für jeweils nur eine Ausprägung des Faktors Expertise machen. Das heißt, wir rechnen zwei einfaktorielle Varianzanalysen. Eine für die Noviz*innen und eine für die Expert*innen. Ist der Effekt bei den Noviz*innen signifikant und nicht bei den Expert*innen, können wir sagen, dass bestimmte Lehrstrategien bei den Noviz*innen wirksamer sind als andere und dass die Wahl der Lehrstrategie bei den Expert*innen keinen Unterschied macht.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"simple-effekt-der-novizinnen","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.6.1 Simple Effekt der Noviz*innen","text":"Berechnen wir daher den ersten Simple Effekt. Wir filtern hierzu den Datensatz um alle Personen, die Noviz*innen sind. Hierdurch haben wir nicht mehr 76 Personen, sondern 43 Personen im Datensatz. Danach berechnen wir eine einfaktorielle Varianzanalyse, wie wir sie im vorherigen Modul kennen gelernt haben:Der zugehörige F-Test ergibt folgendes Ergebnis:Wir finden einen signifikanten Effekt. Das heißt, wir gehen davon aus, dass die Lehrstrategien bei den Noviz*innen unterschiedlich wirksam sind.folgendem Skript kannst du die einzelnen Berechnungen R nachvollziehen, wenn du möchtest:TODO: Einfügen Datei simple_effect_novizen.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"simple-effect-der-expertinnen","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.6.2 Simple Effect der Expert*innen","text":"Ganz ähnlich gehen wir nun für die Expert*innen vor. Wir filtern zunächst den Datensatz um alle Personen, die Expert*innen sind. Dieser Datensatz umfasst 33 Personen. Das Modellpaar ist das gleiche wie beim Simple Effekt der Noviz*innen. Folgendes Ergebnis erhalten wir auf Grundlage der Daten und des Modellpaares:Nun sehen wir, dass es keinen signifikanten Effekt gibt. Die Wahl der Lernstrategie beeinflusst bei Expert*innen den Wissenszuwachs nicht. Der Effekt ist zudem minimal (0.9% der Varianz wird aufgeklärt).folgendem Skript kannst du die einzelnen Berechnungen R nachvollziehen, wenn du möchtest:TODO: Einfügen Datei simple_effect_experts.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"zusammenfassung-20","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.6.3 Zusammenfassung","text":"Wir haben nun die signifikante Interaktion aus dem vorherigen Modul aufgelöst, indem wir gezeigt haben, dass es einen signifkanten Effekt bei den Noviz*innen, aber nicht bei den Expert*innen gibt. Anscheinend wirken manche Lernstrategien bei den Noviz*innen besser als andere. Wie bereits eingangs beschrieben, beantwortet selbst diese Analyse unsere Fragestellung nicht. Wir wollten wissen, ob die direkte Instruktion (im Vergleich zu den anderen beiden Lernstrategien) bei den Noviz*innen wirksamer ist als bei den Expert*innen. Dies können wir abschließend im nächsten Submodul beantworten, indem wir eine Kontrastanalyse mit Hilfe nur einer Interaktion berechnen.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"statistisches-hypothesentesten-spezifischer-interaktionskontrast","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.7 Statistisches Hypothesentesten: Spezifischer Interaktionskontrast","text":"Erinnern wir uns die zu Beginn des Moduls gestellte Fragestellung:Die Fragestellung dieses Moduls lautet: Ist direkte Instruktion effektiver als problem- bzw. projektbasiertes Lernen und ist dieser Effekt abhängig vom Vorwissen der Lernenden?Ehrlich gesagt, haben wir weder die erste noch die zweite Frage bisher beantwortet. Der Haupteffekt der Lehrstrategie konnte uns zeigen, dass die Wahl der Lehrstrategie einen Unterschied auf den Wissenszuwachs hat. Allerdings wissen wir nicht, welche Lehrstrategie welchen Unterschied macht. Ebenso konnten wir zwar einen Interaktionseffekt finden, wir wissen allerdings nicht, ob nun die direkte Instruktion bei den Noviz*innen im Vergleich zu den Expert*innen besser wirkt. Wir werden daher jetzt diese beiden Fragestellungen testen, indem wir spezifische Kontraste rechnen. Wir sprechen immer von spezifischen Kontrasten, wenn das erweiterte Modell genau einen Freiheitsgrad mehr hat als das kompakte Modell. Beginnen wir mit der ersten Frage: Ist die direkte Instruktion lernwirksamer als problem- bzw. projektbasiertes Lernen?","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"direkte-instruktion-vs.-problem--bzw.-projektbasiertes-lernen","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.7.1 direkte Instruktion vs. problem- bzw. projektbasiertes Lernen","text":"Als wir das erweiterte Modell aufgestellt haben, hatten wir eine Helmert-Kontrastkodierung für den Faktor Lehrstrategie gewählt, bei der der Parameter b1 für den Mittelwertsunterschied zwischen der direkten Instruktion und den anderen beiden Lehrstrategiegruppen steht. Durch diese clevere Konstruktion der Kontraste können wir b1 auf 0 setzen und testen, ob die Lehrstrategie direkte Instruktion lernwirksamer ist als die andere beiden Lehrstrategien. Das tun wir, indem wir prüfen, wie wahrscheinlich es ist, dass die Mittelwerte sich weit voneinander unterschieden, wenn es Wirklichkeit keinen Unterschied macht, welche Lehrstrategie benutzt wird. Dementprechend sehen unsere Modellpaare wie folgt aus:Wie immer müssen wir nun lediglich einen F-Test berechnen, um unsere Hypothese zu prüfen:Wir finden ein signifikantes Ergebnis. Wir müssen die Annahme, dass die direkte Instruktion gleich lerneffektiv ist wie die anderen beiden Lehrstrategien verwerfen und entscheiden uns daher vorerst für die Annahme, dass die direkte Instruktion lehrwirksamer ist als die anderen beiden Lehrstrategien. Wir sollten allerdings zudem darauf achten, dass wir eine gerichtete Hypothese haben. Wir können daher (auch, da die deskriptiven Daten hypothesenkonform sind), den p-Wert teilen.Wir werden zudem die Ergebnisse später als t-Test berichten. Gewöhnlich wird bei einem t-Test die Effektgröße Cohen’s d angegben. Die Formel zur Berechnung von Cohen’s d bei einer einfaktoriellen und mehrfaktoriellen Varianzanalyse haben wir bereits im letzten Modul kennngelernt:Da der t-Wert die Wurzel aus F ist, liegt der t-Wert bei 3.04. Der Freiheitsgrad des erweiterten Modells liegt bei 70. Daraus ergibt sich folgende Effektgröße:Ebenso könntest du das PRE einfach unter folgender Webseite unter 14. Transformation effect sizes eingeben. Wie du sehen wirst, ergibt sich das gleiche Cohen’s d aus dieser Webseite. Diesen Effekt bezeichnen wir als mittelgroß. Das Ergebnis des Tests kannst du hier R nachrechnen:TODO: Einfügen specific_constrast_direct_instruction.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"die-interaktion-des-effekts-der-direkten-instruktion","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.7.2 Die Interaktion des Effekts der direkten Instruktion","text":"Jetzt kommen wir schlussendlich zu unserer eigentlichen Fragestellung. Wir haben nun heraus gefunden, dass die direkte Instruktion wirksamer ist (zumindest auf Grundlage der Signifikanz) als die anderen beiden Lehrmethoden. Die Frage ist nun, ob dieser Effekt bei Noviz*innen und nicht bei Expert*innen zu finden ist. Diese Frage können wir beantworten, indem wir den Parameter b4 im erweiterten Modell auf 0 setzen. Aus dem Beginn dieses Moduls wissen wir noch, dass dieser Parameter die Differenz der Mittelwertsunterschiede zwischen der direkten Instruktion und den anderen beiden Lehrstrategien zwischen den Expert*innen und Noviz*innen darstellt. Liegt dieser Parameter bei 0, wirkt die direkte Instruktion bei Expert*innen genauso gut wie bei Noviz*innen. Ist dieser Parameter positiv, wirkt die direkte Instruktion bei Noviz*innen besser als bei Expert*innen. Wird testen diese Fragestellung mit folgendem Modellpaar:Der F-Test ergibt folgendes Ergebnis:Nun haben wir die Antwort auf unsere Hypothese. Der Effekt der direkten Instruktion ist anscheinend abhängig vom Vorwissen der Personen. Noviz*innen scheinen mit der direkten Instruktion mehr zu lernen als mit den anderen beiden Lehrstrategien, bei den Expert*innen scheint die direkte Instruktion gleich effektiv zu sein wie die anderen beiden Lehrstrategien. Der Effekt liegt bei PRE = 0.076 oder bei Cohen’s d = 0.57 (mittlerer Effekt).Das Ergebnis des Tests kannst du hier R nachrechnen:TODO: Einfügen Datei specific_contrast_interaktion.R","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"ergebnisse-berichten","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.7.3 Ergebnisse berichten","text":"Wir haben die Ergebnisse auf unsere Tests berechnet, nun können wir diese berichten:“Um zu prüfen, ob die direkte Instruktion lernwirksamer ist als problem- bzw. projektbasiertes Lernen und um zu prüfen, ob der Effekt der direkten Instruktion abhängig vom Vorwissen der Lernenden ist, wurde eine mehrfaktorielle Varianzanalyse gerechnet. Als abhängige Variable wurde der Wissenszuwachs während des Trainings verwendet. Als Faktoren wurden die Lehrstrategien (direkte Instruktion, problembasiertes Lernen und projektbasiertes Lernen) und die Expertise der Lernenden (Expert*innen und Novize) verwendet. Wir fanden einen signifikanten Haupteffekt der Lehrstrategie, F(2, 70) = 4.62, p = .013, η2p = 0.12, und einen signifkanten Interaktionseffekt, F(2, 70) = 3.15, p = .049, η2p = 0.08. Spezifische Kontrastanalysen zeigten, dass die direkte Instruktion lernwirksamer war als die anderen beiden Lehrstrategien, t(70) = 3.04, p = .002, d = 0.73 (mittlerer Effekt). Eine weitere Kontrastanalyse ergab einen signifikanten Interaktionseffekt zwischen dem Effekt der direkten Instruktion und der Expertise der Lernenden, t(70) = 2.41, p = .019, d = 0.57 (mittlerer Effekt). Die Ergebnisse deuten darauf hin, dass Noviz*innen von der direkten Instruktion profitieren, während die Wahl der Lehrstrategie für die Expert*innen keinen Unterschied macht.”","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"zusammenfassung-21","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.7.4 Zusammenfassung","text":"Wir haben diesem Submodul erfolgreich die Hypothese getestet und berichtet, welche wir zu Beginn des Moduls aufgestellt haben. Dabei haben wir heraus gefunden, dass die direkte Instruktion eine besonders wirksame Lehrstrategie für Noviz*innen ist und die Wahl der Lehrstrategie bei Expert*innen keinen Einfluss auf den Wissenszuwachs hat. Wir haben insbesondere durch dieses Submodul gesehen, dass Haupteffekte und Interaktionen nicht immer die Fragen beantworten, die wir gerne beantwortet sehen und, dass spezifische Kontraste häufig mehr Aufschluss über unsere Fragen geben. Es ist daher wichtig, sich vor dem Prüfen einer Hypothese bei einer mehrfaktoriellen Varianzanalyse genaue Vorstellungen zu machen, wie die Kodierung gestaltet sein muss, damit man später die eigenen Fragestellungen testen kann.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"berechnung-in-jamovi-4","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.8 Berechnung in Jamovi","text":"den folgenden Videos erkläre ich dir, wie man alle Verfahren, die wir diesem Modul kennen gelernt haben, Jamovi und R berechnen kannst.","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"haupteffekte","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.8.1 Haupteffekte","text":"TODO: Einfügen Video","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"interaktionseffekt","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.8.2 Interaktionseffekt","text":"TODO: Einfügen Video","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"simple-effects","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.8.3 Simple Effects","text":"TODO: Einfügen Video 1TODO: Einfügen Video 2","code":""},{"path":"tatusmehrfaktorielle-varianzanalyse.html","id":"spezifische-kontraste","chapter":"9 tatusMehrfaktorielle Varianzanalyse","heading":"9.8.4 Spezifische Kontraste","text":"TODO: Einfügen Video 1TODO: Einfügen Video 2","code":""},{"path":"ancova.html","id":"ancova","chapter":"10 ANCOVA","heading":"10 ANCOVA","text":"","code":""},{"path":"ancova.html","id":"einführung-8","chapter":"10 ANCOVA","heading":"10.1 Einführung","text":"Bisher haben wir Hypothesen getestet, deren Modellen entweder nur kontinuierliche oder nur diskrete Prädiktoren eingesetzt wurden. Bei der linearen Regression haben wir kontinuierliche Prädiktoren verwendet, bei der ein- und mehrfaktoriellen Varianzanalyse diskrete Prädiktoren. Dies wird sich diesem Modul ändern. Unser Ziel diesem Modul ist es, die gleiche Fragestellung aus dem letzten Modul zu beantworten, nur diesmal, indem wir ein erweitertes Modell verwenden, das sowohl diskrete als auch kontinuierliche Prädiktoren umfasst. Solche Modelle werden als Kovarianzanalysen (ANCOVAs) bezeichnet. Übersetzt können wir eine ANCOVA auch als eine Varianzanalyse mit Kovariaten (stetig skalierte Variablen) bezeichnen. Erinnern wir uns erneut die Fragestellung aus dem letzten Modul:Ist direkte Instruktion effektiver als problem- bzw. projektbasiertes Lernen und ist dieser Effekt abhängig vom Vorwissen der Lernenden?Ein Grund dafür, dass wir die gleiche Fragestellung mit einem anderen Modell testen werden, ist, dass wir durch die mehrfaktorielle Varianzanalyse nicht erfahren können, wie stark der Zusammenhang zwischen dem Vorwissen (Kovariate) der Lernenden und dem Wissen eine Woche nach dem Training ist. Eine der zentralsten Kenntnisse der Lehr- und Lernforschung ist, dass Vorwissen der wichtigste Prädiktor für Lernen ist. Je mehr ich schon über ein Thema weiß, desto besser kann ich mir neues Wissen zu diesem Thema aneignen. Wir konnten diesen Zusammenhang allerdings im letzten Modul nicht testen, da wir als abhängige Variable den Wissenserwerb vor und nach dem Training verwendet haben. Vermutlich gibt es jedoch einen starken Zusammenhang zwischen dem, eine Person bereits über natürliche Selektion weiß, und dem die gleiche Person eine Woche später darüber weiß. Wir werden diesem Modul daher das Wissen vor dem Training das erweiterte Modell als Kovariate einbauen und das Wissen eine Woche nach dem Training als abhängige Variable verwenden.Ein weiterer Grund für die Verwendung der Kovarianzanalyse (ANCOVA) ist, dass wir dadurch eine höhere Power haben, unter der Bedingung, dass es keinen Zusammenhang zwischen der Kovariate (hier Vorwissen - stetig skaliert) und den Versuchsbedingungen (hier Lehrstrategiemethode) gibt. Eine höhere Power bedeutet, dass wir mit einer größeren Wahrscheinlichkeit einen Effekt finden werden, sofern er existiert. der Regel möchten wir eine hohe Power erzielen.","code":""},{"path":"ancova.html","id":"datensatz-1","chapter":"10 ANCOVA","heading":"10.1.1 Datensatz","text":"Der Datensatz für dieses Modul ist genau der gleiche wie im letzten Modul:TODO: Einfügen Datei expert_study.csvWir werden diesem Modul die Variablen method, test_prior, test_delay und expertise verwenden. Unsere abhängige Variable ist die Variable test_delay, die Kovariate wird die Variable test_prior sein.id: Die ID der Versuchspersonid: Die ID der Versuchspersonexpertise: Ein Faktor, welcher kodiert, ob die Person eine Expertin / ein Experte oder eine Novizin / ein Novize ist.expertise: Ein Faktor, welcher kodiert, ob die Person eine Expertin / ein Experte oder eine Novizin / ein Novize ist.age: Das Alter der Personage: Das Alter der Personmethod: Ein Faktor, welcher die Lehrstrategie kodiert, welche die Person bekommen hat.method: Ein Faktor, welcher die Lehrstrategie kodiert, welche die Person bekommen hat.test_prior (Kovariate - stetig skaliert): Das Vorwissen der Testperson zum Thema natürliche Selektiontest_prior (Kovariate - stetig skaliert): Das Vorwissen der Testperson zum Thema natürliche Selektiontest_delay: Das Wissen zum Thema natürliche Selektion der Person eine Woche nach dem Ende der Lehrsituationtest_delay: Das Wissen zum Thema natürliche Selektion der Person eine Woche nach dem Ende der Lehrsituationimprovement: Die Differenz zwischen dem Wissen Ende des Experiments (test_delay) und dem Wissen vor dem Experiment (test_prior). Höhere Werte bedeuten, dass die Person mehr Wissen erworben hat.improvement: Die Differenz zwischen dem Wissen Ende des Experiments (test_delay) und dem Wissen vor dem Experiment (test_prior). Höhere Werte bedeuten, dass die Person mehr Wissen erworben hat.","code":""},{"path":"ancova.html","id":"post--und-pre-werte-vs.-differenzmaße","chapter":"10 ANCOVA","heading":"10.2 Post- und Pre Werte vs. Differenzmaße","text":"diesem Submodul möchte ich zeigen, dass wir die gleiche Fragestellung aus dem letzten Modul mit zwei verschiedenen erweiterten Modellen beantworten können. Wir werden ebenso klären, weshalb man überhaupt eine Kovarianzanalyse berechnen sollte.","code":""},{"path":"ancova.html","id":"modell-mit-differenzmaß-als-abhängige-variable-ohne-kovariate","chapter":"10 ANCOVA","heading":"10.2.1 Modell mit Differenzmaß als abhängige Variable (ohne Kovariate)","text":"Beginnen wir mit unserem erweiterten Modell aus dem letzten Modul. Das Modell umfasste sechs Parameter und fünf Prädiktoren. Wir hatten das Modell gewählt, dass die Parameter für spezifische Gruppenunterschiede stehen. Beispielsweise haben wir X1 kodiert, dass b1 für den Mittelwertsunterschied zwischen der direkten Instruktion und den anderen beiden Lehrstrategien steht. Ebenso haben wir X4 kodiert, dass b4 für die Frage steht, ob der Effekt von b1 für Expert*innen und Noviz*innen gleich ist.Das Modell ist im oberen Bild notiert, dass die abhängige Variable der geschätzte Wert des Modells ist. Wir können das Modell umschreiben, dass die abhängige Variable der tatsächliche Wert ist, sprich der tatsächliche Wissenswerb der Proband*innen:Du kannst erkennen, dass wir das Dach auf der abhängigen Variable entfernt haben und zudem einen Fehlerterm Ende des Modells hinzugefügt haben (ei). Yi steht hier für den Wissenswerb der Proband*innen. Wir könnten diesen alternativ auch als die Differenz zwischen dem Vorwissen und dem Wissen eine Woche nach dem Training angeben. Wir bezeichnen Zi im unteren Bild zukünftig als die Kovariate. Die Kovariate ist unserem Fall das Vorwissen der Proband*innen vor dem Training:Nun haben wir eine akkuratere Darstellung der abhängigen Variable. Es ist ein Differenzmaß aus zwei Werten: Dem Vorwissen und dem Wissen eine Woche nach dem Training. Ein positiver Wert bedeutet, dass die Proband*innen etwas dazu gelernt haben, ein negativer, dass die Proband*innen nach dem Training weniger wissen als vor dem Training. Mit diesem erweiterten Modell haben wir im letzten Modul folgende Ergebnisse erzielt:Ein Ergebnis unserer Tests war, dass es eine signifikante Interaktion der Lehrstrategie und der Expertise gibt. Ebenso haben wir heraus gefunden, dass es einen signifikanten Effekt der direkten Instruktion gibt. Das heißt, die direkte Instruktion schien lernförderlicher zu sein als die anderen beiden Lehrstrategien. Dieser Effekt wiederum interagiert mit dem Vorwissen der Lernenden. Bei Noviz*innen finden wir den Effekt der direkten Instruktion, bei Expert*innen nicht. Du könntest nun zufrieden sein und diese Ergebnisse deiner Bachelorarbeit berichten. Allerdings solltest du wissen, welche Auswirkungen es hat, Differenzmaße zu verwenden und keine Kovariate zu verwenden, um die gleichen Hypothesen zu testen.","code":""},{"path":"ancova.html","id":"kovarianzanalysen-haben-unter-bestimmten-bedingungen-mehr-power","chapter":"10 ANCOVA","heading":"10.2.2 Kovarianzanalysen haben unter bestimmten Bedingungen mehr Power","text":"Zu Beginn des Kurses hatten wir gesagt, dass wir wenn möglich eine hohe Power (> 80%) erzielen möchten. Das heißt, wir möchten wenn möglich eine hohe Wahrscheinlichkeit bei einem Test erzielen, ein signifikantes Ergebnis zu erhalten. Sofern der Effekt natürlich auch existiert. Die Power können wir manipulieren, indem wir die Stichprobengröße anpassen. unserem Fall können wir die Power allerdings auch erhöhen, indem wir das Vorwissen als Kovariate das erweiterte Modell einfügen und als abhängige Variable das Wissen über natürliche Selektion eine Woche nach dem Training definieren.Nicht jede Kovarianzanalyse hat allerdings eine höhere Power. Entscheidend ist, dass die Ausprägungen des Faktors Lehrstrategie nicht mit dem Vorwissen korrelieren. Bei einem Experiment, welchem Proband*innen randomisiert den Versuchsgruppen zugeordnet werden, ist dies meistens gegeben. unserem Experiment beispielsweise haben wir zunächst das Vorwissen der Lernenden getestet und die Proband*innen danach willkürlich eine der drei Versuchsgruppen eingeteilt. Wenn wir daher eine einfaktorielle Varianzanalyse der Versuchsgruppen mit dem Vorwissen als abhängige Variable berechnen, erhalten wir keinen signifikanten Effekt. Dies bedeutet, dass die Gruppen sich nicht im Vorwissen unterscheiden:Dieses signifikante Ergebnis bedeutet zudem, dass das Vorwissen und die Gruppenzugehörigkeit eine geringe gemeinsame Varianz des kompakten Modells aufklären und damit eine der Bedingungen erfüllen, die zu einer höheren Power führt.Eine zweite Bedingung für höhere Power ist, dass die Kovariate hoch mit der abhängigen Variable korreliert. Dies können wir annehmen, da das Vorwissen der Regel hoch prädiktiv für weitere Lernerfahrungen ist. Um sicher zu sein, berechnen wir eine einfache lineare Regression zwischen dem Vorwissen und dem Wissen eine Woche nach dem Training und schauen uns das Ergebnis :Wir klären unglaubliche 91% der Varianz des kompakten Modells auf. Das heißt, das Vorwissen erklärt den Lernzuwachs der Personen fast vollständig.","code":""},{"path":"ancova.html","id":"weitere-gründe-kovariaten-in-ein-modell-zu-integrieren","chapter":"10 ANCOVA","heading":"10.2.3 Weitere Gründe, Kovariaten in ein Modell zu integrieren","text":"Unser Argument war gerade, dass wir bei einem Experiment, dem wir die Gruppenzugehörigkeit randomisieren, eine höhere Power haben. Es können allerdings noch weitere Argumente für eine Kovarianzanalyse gemacht werden. Beispielsweise bei einem quasi-experimentellen Design. Bei einem quasi-experimentellem Design werden Gruppen Proband*innen nicht willkürlich zugeordnet, sondern die Gruppen gibt es bereits vor einem Experiment. Stell dir beispielsweise vor, du testest, ob sich Republikaner*innen und Demokrat*innen der Frage unterscheiden, wie viel Einfluss der Staat auf die Gesundheitsversorgung der Bevölkerung haben sollte. Beide Gruppen gibt es bereits vor der Erhebung der Daten. Ebenso könntest du vergleichen, wie viele Stunden Menschen mit Abitur und Menschen mit einem Werkrealschulabschluss pro Woche lesen. Erneut handelt es sich um natürliche Gruppen, die vor der Datenerhebung existierten. Solche Gruppen unterscheiden sich häufig ebenso anderen Variablen, die einen Einfluss auf die abhängige Variable haben können. Beispielsweise gibt es vermutlich einen hohen Zusammenhang zwischen der Zustimmung zu der Frage, ob der Staat eine verpflichtende Gesundheitsversorgung umsetzt und der persönlichen Kranheitsgeschichte einer Person. Sprich, wer bereits öfters auf die Gesundheitsversorgung angewiesen war, befürwortet eine stärkere staatliche Versorgung der Gesundheit der Bevölkerung. Eine Kovarianzanalyse, der Republikaner*innen mit Demokrat*innen verglichen werden, ermöglicht diesem Fall den Effekt der politischen Zugehörigkeit für die persönliche Krankheitsgeschichte zu kontrollieren. Mit einem solchen Test könnten wir prüfen, ob die Zustimmung einer gesetzlichen Krankenversicherung von der politischen Zugehörigkeit abhängt, wenn Personen sich nicht ihrer Krankheitsgeschichte unterscheiden. Kontrollieren bedeutet daher, dass wir einen Prädiktor Abhängigkeit eines anderen Prädiktors interpretieren: Wenn sich Personen nicht ihrer Krankheitsgeschichte unterscheiden, dannn erwarten wir folgende Zustimmung zur gesetzlichen Krankenversicherung. Würden wir keine Kovariate einfügen, könnte es sein, dass der Unterschied der politischen Zugehörigkeit durch eine andere Variable erklärt werden kann. Sprich, dass wir einen falschen Inferenzschluss machen. Dies ist nur ein Beispiel und die Möglichkeiten der statistischen Analyse sind ungleich komplizierter als es hier kurz angerissen wurde. Es zeigt aber sehr gut, dass wir bei quasiexperimentellen Designs immer überlegen sollten, welche Kovariaten ein Modell hinzuzufügen sind.","code":""},{"path":"ancova.html","id":"modell-der-kovarianzanalyse-mit-kovariate","chapter":"10 ANCOVA","heading":"10.2.4 Modell der Kovarianzanalyse (mit Kovariate)","text":"Nun, da wir die Gründe kennen, eine Kovarianzanalyse zu berechnen, können wir uns das erweiterte Modell für unsere Kovarianzanalyse aufstellen. Hierzu bringen wir die Kovariate Z von der linken Seite der Gleichung auf die rechte Seite der Gleichung:Im Vergleich zum vorherigen Modell haben sich ein paar Dinge geändert:Zunächst hat das erweiterte Modell mit der Kovariate einen Parameter und einen Prädiktor mehr. Hierdurch ändern sich ebenso die Freiheitsgrade unserem Test. Beispielsweise kann dem erweiterten Modell durch den weiteren Parameter nur noch ein Parameter weniger hinzugefügt werden. Das heißt der Freiheitsgrad des erweiterten Modells reduziert sich um die Zahl 1. Ebenso werden wir durch das erweiterte Modell die Fehler des kompakten Modells besser aufklären können. Wie bereits zu Beginn des Kurses erwähnt, je mehr Parameter wir haben, desto besser können wir die Fehler des kompakten Modells aufklären. Des Weiteren ändern sich die Parameter der beiden Modelle selbst. Ohne die Kovariate stehen die Parameter für die Gruppenmittelwertsunterschiede. Mit der Kovariate stehen die Parameter für die Gruppenmittelwertsunterschiede, allerdings kontrolliert für die Kovariate. Wir würden beispielsweise b1 folgendermaßen interpretieren: Wenn zwei Personen das gleiche Vorwissen haben, beträgt der Mittelwertsunterschied zwischen der direkten Instruktion und den anderen beiden Lehrstrategien b1. Das heißt, wir können die Parameter nur noch Abhängigkeit der Kovariate interpretieren.","code":""},{"path":"ancova.html","id":"zusammenfassung-22","chapter":"10 ANCOVA","heading":"10.2.5 Zusammenfassung","text":"diesem Submodul haben wir gezeigt, dass wir die mehrfaktorielle Varianzanalyse, welche wir im letzten Modul kennen gelernt haben, auch als Kovarianzanalyse berechnen können. Wir haben zunächst gezeigt, wie das Modell der mehrfaktoriellen Varianzanalyse ein Modell mit einer Kovariate überführt werden kann. Ebenso haben wir gezeigt, weshalb es Sinn macht, eine Kovarianzanalyse zu berechnen. Zunächst hilft es unter bestimmten Bedingungen, die Power des Tests zu erhöhen, des Weiteren ermöglicht uns eine Kovarianzanalyse, für andere Variablen zu kontrollieren, die mit den Ausprägungen von Gruppen im Zusammenhang stehen können.","code":""},{"path":"ancova.html","id":"statistisches-hypothesentesten-3","chapter":"10 ANCOVA","heading":"10.3 Statistisches Hypothesentesten","text":"diesem Modul werden wir die gleichen Fragestellungen testen, die wir im letzten Modul getestet haben. Allerdings diesmal, indem wir eine Kovarianzanalyse berechnen. Im Grunde genommen berechnen wir eine mehrfaktorielle Varianzanalyse mit einem Interaktionseffekt und einer Kovariate. Wir werden dabei nicht jeden einzelnen Test einzeln berechnen, sondern alle Ergebnisse auf einmal präsentieren und genau untersuchen, worin sich die Ergebnisse zwischen der mehrfaktoriellen Varianzanalyse aus dem letzten Modul und der Kovarianzanalyse diesem Modul unterscheiden.","code":""},{"path":"ancova.html","id":"darstellung-der-ergebnisse-der-beiden-tests","chapter":"10 ANCOVA","heading":"10.3.1 Darstellung der Ergebnisse der beiden Tests","text":"der folgenden Tabelle siehst du die zentralen Ergebnisse der mehrfaktoriellen Varianzanalyse aus dem letzten Modul und der Kovarianzanalyse, wie wir sie diesem Modul rechnen. Wir werden die Tabelle gleich im Einzelnen durchgehen. Achte auf die unterschiedlichen Freiheitsgrade und p-Werte:\nSource\n\nSSohne\n\nSSmit\n\ndfohne\n\ndfmit\n\nFohne\n\nFmit\n\npohne\n\npmit\n\nPREohne\n\nPREmit\n\nModel\n\n94.600\n\n4432.6\n\n5\n\n6\n\n3.52\n151.24\n\n.007\n< .001\n\n.20\n.20\nLehrstrategie\n\n49.679\n\n52.5\n\n2\n\n2\n\n4.62\n5.37\n\n.013\n.007\n\n.12\n.14\n\nExpertise\n\n0.428\n25.7\n\n1\n\n1\n\n0.08\n5.26\n\n.779\n.025\n\n.00\n.07\n\nLehrstrategie*Expertise\n\n33.904\n27.6\n\n2\n\n2\n\n3.1532\n2.82\n\n.049\n.07\n\n.08\n.08\n\ndirekte Instruktion vs. problem- bzw. projekt\n\n49.67\n50.6\n\n1\n\n1\n\n9.24\n10.36\n\n.003\n.002\n.12\n.13\nInteraktion direkte Instruktion und Expertise\n\n31.18\n25.1\n\n1\n\n1\n\n5.80\n5.14\n\n.019\n.027\n\n.08\n.07\n\nVorwissen\n-\n\n1615.8\n\n-\n\n1\n\n-\n\n330.78\n\n-\n\n< .001\n\n-\n\n.83\n\nError\n\n376.329\n337.0\n\n70\n\n69\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\nTotal\n\n40.929\n4769.6\n\n75\n\n75\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n","code":""},{"path":"ancova.html","id":"der-effekt-der-expertise","chapter":"10 ANCOVA","heading":"10.3.2 Der Effekt der Expertise","text":"Zunächst müssen wir feststellen, dass wir im letzten Modul keinen Effekt der Expertise hatten, nun allerdings finden wir diesen Effekt (da wir ein signifikanes Ereignis haben):Zu erklären ist diese Änderung, indem wir uns fragen, die abhängige Variable ist und welche Hypothesen wir mit den beiden Tests gerechnet haben. Bei der mehrfaktoriellen Varianzanalyse war die abhängige Variable der Wissenszuwachs vom Pre- zum Posttest. Dieser war offensichtlich zwischen Noviz*innen und Expert*innen gleich. Mit der Kovarianzanalyse allerdings ist die abhängige Variable das Wissen zum Thema natürliche Selektion eine Woche nach dem Training. Das Ergebnis der Kovarianzanalyse sagt uns nun, dass Expert*innen mehr über natürliche Selektion wissen als Noviz*innen. Oder anders gesagt, wenn Noviz*innen und Expert*innen gleich viel vor dem Training über natürliche Selektion wissen, werden Expert*innen nach dem Training mehr wissen als Noviz*innen. Genau dies ist die Bedeutung der Kovariate. Zusammengefasst prüfen wir daher mit der Kovarianzanalyse eine andere Fragestellung als bei der mehrfaktoriellen Varianzanalyse.","code":""},{"path":"ancova.html","id":"der-freiheitsgrad-des-allgemeinen-f-tests-erweitert-sich-um-1","chapter":"10 ANCOVA","heading":"10.3.3 Der Freiheitsgrad des allgemeinen F-Tests erweitert sich um 1","text":"Du siehst ebenso, dass sich beim allgemeinen Modell, bei dem wir alle Prädiktoren auf 0 setzen, der Freiheitsgrad von 5 (ohne Kovariate) auf 6 (mit Kovariate) steigert:Zur Erinnerung, Model meint hier, dass wir das erweiterte Modell mit der Kovariate mit dem einfachsten kompakten Modell vergleichen, bei dem wir nur einen Parameter haben, der für den Mittelwert der abhängigen Variable steht:Modelle der KovarianzanalyseDu siehst, dass das erweiterte Modell sieben Parameter hat. Das kompakte Modell hat einen Parameter. Daher hat das erweiterte Modell sechs Parameter mehr als das kompakte Modell. Dieser Test beantwortet unsere Fragestellungen nicht, daher ist er nicht wichtig. Er zeigt allerdings durch die Freiheitsgrade, dass das zu Grunde liegende Modell anders ist.","code":""},{"path":"ancova.html","id":"die-p-werte-werden-größer-bzw.-kleiner","chapter":"10 ANCOVA","heading":"10.3.4 Die p-Werte werden größer bzw. kleiner","text":"Ebenso kannst du erkennen, dass die p-Werte anders sind und dass sich teilweise auch die Signifikanz ändert. Beispielsweise ist sowohl der p-Wert der Lehrstrategie, der Expertise und des Effekts der direkten Instruktion kleiner:\nSource\n\nSSohne\n\nSSmit\n\ndfohne\n\ndfmit\n\nFohne\n\nFmit\n\npohne\n\npmit\n\nPREohne\n\nPREmit\n\nLehrstrategie\n\n49.679\n\n52.5\n\n2\n\n2\n\n4.62\n5.37\n\n.013\n.007\n\n.12\n.14\n\nExpertise\n\n0.428\n25.7\n\n1\n\n1\n\n0.08\n5.26\n\n.779\n.025\n\n.00\n.07\n\nLehrstrategie*Expertise\n\n33.904\n27.6\n\n2\n\n2\n\n3.1532\n2.82\n\n.049\n.07\n\n.08\n.08\n\ndirekte Instruktion vs. problem- bzw. projekt\n\n49.67\n50.6\n\n1\n\n1\n\n9.24\n10.36\n\n.003\n.002\n.12\n.13\nInteraktion direkte Instruktion und Expertise\n\n31.18\n25.1\n\n1\n\n1\n\n5.80\n5.14\n\n.019\n.027\n\n.08\n.07\n\nError\n\n376.329\n337.0\n\n70\n\n69\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\nTotal\n\n40.929\n4769.6\n\n75\n\n75\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\nAllerdings findest du auch, dass die Interaktion zwischen Lehrstrategie und Expertise nicht mehr signifikant ist, da sie nun die 5%-Schwelle übersteigt. Der Grund hierfür liegt darin, dass die beiden Interaktionseffekte (df = 2) wenige Fehler des kompakten Modells aufklären (27.6 anstatt 33.9) und, dass das erweiterte Modell einen Parameter weniger aufnehmen kann (df = 69 anstatt df = 70). Ersteres hat zur Folge, dass der F-Wert kleiner wird, zweiteres hat zur Folge, dass wir eine andere F-Verteilung zur Prüfung der Hypothese verwenden müssen.Alle anderen binären statistischen Entscheidungen bleiben allerdings gleich. Das Beispiel zeigt allerdings schon, dass die Entscheidung über eine Kovariate oder ein Differenzmaß bei einer mehrfaktoriellen Varianzanalyse einen Einfluss auf die statistische Entscheidung haben kann. Ohne die Kovariate finden wir eine signifikante Interaktion, mit der Kovariate nicht. Forschende haben dadurch manche Möglichkeiten, die sie darin unterstützen, ein Verfahren zu wählen, welches doch zu einem signifikanten Ergebnis führt (siehe Kerr, 1998). sollte es allerdings nicht sein. Die Modelle, welche Forschende aufstellen, sollten inhaltlich begründet sein und weniger aufgrund des Wunsches, ein signifikantes Ergebnis zu erzielen.","code":""},{"path":"ancova.html","id":"das-vorwissen-ist-prädiktiv-für-das-wissen-nach-dem-training","chapter":"10 ANCOVA","heading":"10.3.5 Das Vorwissen ist prädiktiv für das Wissen nach dem Training","text":"Mit der Kovariate können wir zudem eine weitere interessante Frage beantworten: Wie wichtig ist das Vorwissen für das Wissen zum Thema natürliche Selektion nach dem Training? Und die Antwort ist: “Sehr wichtig”:Wie du siehst, klärt allein der Prädiktor Vorwissen (nur ein Prädiktor!) 83% der Varianz im Test eine Woche nach dem Training auf. Wer sozusagen bereits viel über ein Thema weiß, wird auch eine Woche später sehr viel über dieses Thema wissen. den Kennwerten gesprochen könnten wir auch sagen: Der Prädiktor Vorwissen ist 330 mal besser der Lage, die Fehler des kompakten Modells aufzuklären als wir für einen weiteren Prädiktor erwarten würden. Oder: Die Wahrscheinlichkeit, dass wir ein solches Ergebnis erhalten, wenn das Vorwissen keinen Einfluss auf das Wissen eine Woche nach dem Training hat, liegt bei unter 0.00001% (oder sogar noch geringer). Die mehrfaktorielle Varianzanalyse mit einem Differenzmaß als abhängige Variable konnte uns dieses Ergebnis nicht liefern. Eine Kovarianzanalyse allerdings schon.","code":""},{"path":"ancova.html","id":"zusammenfassung-23","chapter":"10 ANCOVA","heading":"10.3.6 Zusammenfassung","text":"Wir haben diesem Submodul gesehen, wie sich die statistischen Ergebnisse eines Tests ändern, wenn wir eine Kovarianzanalyse berechnen. Genauer haben wir die Ergebnisse der mehrfaktoriellen Varianzanalyse aus dem letzten Modul mit einer Kovarianzanalyse verglichen. Im Vergleich haben wir heraus gefunden, dass das erweiterte Modell bei einer Kovarianzanalyse einen Parameter und einen Prädiktor mehr hat als das kompakte Modell. Ein weiteres Ergebnis war, dass die Ergebnisse der Tests teilweise andere Hypothesen beantworten. Beispielsweise haben wir Beispiel des Effekts der Expertise gesehen, dass dieser Test eine andere Fragestellung beantwortet und die dramatische Änderung der statistischen Entscheidung dadurch zu erklären ist. Ebenso haben wir gesehen, dass wir durch eine Kovarianzanalyse den Effekt der Kovariate testen können und dadurch mehr statistische Fragen beantworten können als mit einem Differenzmaß als abhängige Variable.","code":""},{"path":"ancova.html","id":"berechnung-in-jamovi-5","chapter":"10 ANCOVA","heading":"10.4 Berechnung in Jamovi","text":"TODO: Einfügen Video 1TODO: Einfügen Video 2","code":""},{"path":"mediation.html","id":"mediation","chapter":"11 Mediation","heading":"11 Mediation","text":"","code":""},{"path":"moderation.html","id":"moderation","chapter":"12 Moderation","heading":"12 Moderation","text":"","code":""},{"path":"statistische-voraussetzungen.html","id":"statistische-voraussetzungen","chapter":"13 Statistische Voraussetzungen","heading":"13 Statistische Voraussetzungen","text":"","code":""},{"path":"statistische-voraussetzungen.html","id":"einführung-9","chapter":"13 Statistische Voraussetzungen","heading":"13.1 Einführung","text":"Das allgemeine lineare Modell, welches wir diesem Kurs kennen gelernt haben (kompaktes und erweitertes Modell), ist eine der beliebtesten Methoden der Sozialforschung, um Hypothesen zu testen. Die Idee des linearen Modells ist allerdings eine menschliche Erfindung und daher nicht perfekt.Beispielsweise hat jeder Test, den wir mit Hilfe des linearen Modells gerechnet haben, bestimmte Annahmen, die wir beachten sollten.Nehmen wir die Skalierung der abhängigen Variable. allen Tests dieses Kurses war die abhängige Variable metrisch (intervall- oder verhältnisskaliert) skaliert. Wäre die abhängige Variable diskret skaliert (z.B. Parteizugehörigkeit), könnten wir keines unserer Testverfahren dieses Kurses verwenden. Ebenso könnte es sein, dass die abhängige Variable binär skaliert ist, dass heißt, dass es nur zwei Ausprägungen gibt. Stell dir vor, du möchstest ein Modell aufstellen, dass vorhersagt, ob eine Person den Untergang der Titanic überlebt hat. Solche Fragen lassen sich beispielsweise mit der logistischen Regression prüfen, nicht aber mit dem allgemeinen linearen Modell.Das allgemeine lineare Modell hat allerdings noch weitere Annahmen, die wir zumindest bei jedem Test kennen sollten. Diese Annahmen sind die Linearität des Modells, die Normalverteilung der Residuen, die Homoskedastizität und die Unabhängigkeit der Daten. Sind diese Annahmen nicht getroffen, kann es im schlimmsten Fall sein, dass unsere Ergebnisse verfälscht sind. Beispielsweise, indem die Verletzungen der Annahmen den Beta-Fehler verringern bzw. die Power der Studie reduzieren. Wir werden diese Annahmen diesem letzten Modul des Kurses besprechen und auch erfahren, wie robust unsere Tests sind, das heißt, wie stark die Ergebnisse der Tests verändert werden, sollten die Annahmen nicht umgesetzt sein.Bevor wir beginnen, ein kleiner Hinweis: Der Umgang mit Verletzungen der Annahmen wird unter Forschenden unterschiedlich gehandhabt. Manche Forschende wissen nicht, dass diese Annahmen überhaupt existieren, andere sehen es nicht streng mit den Verletzungen der Annahmen. Andere wiederum nehmen es sehr genau und versuchen, den besten Weg zu finden, wie mit diesen Verletzungen umgegangen wird. Ich werde diesem Modul keine Position dazu beziehen. Mir ist es wichtig, dass du über die Annahmen Bescheid weißt. Wie mit Verletzungen der Annahmen umgegangen wird, solltest du mit dir oder der Betreuerin / dem Betreuer deiner Forschungsarbeiten besprechen.","code":""},{"path":"statistische-voraussetzungen.html","id":"übersicht-der-annahmen-des-allgemeinen-linearen-modells","chapter":"13 Statistische Voraussetzungen","heading":"13.2 Übersicht der Annahmen des allgemeinen linearen Modells","text":"der folgenden Tabelle siehst du die Annahmen, welche das allgemeine lineare Modell (alle Modelle, die wir diesem Kurs kennenlernen werden) annimmt. Für jeden Test ist dargestellt, wie diese Annahmen herkömmlicherweise geprüft werden. Beispielsweise lässt sich die Normalität der Residuen durch den Shapiro-Wilk Test bei den meisten Tests prüfen.Wie du erkennst, ist die erste Annahme bei allen Tests erfüllt. Dies liegt daran, dass alle unsere Tests auf Grundlage des allgemeinen linearen Modells berechnet werden, welches immer eine metrisch skalierte abhängige Variable umfasst. Die Linearität der Daten prüfen wir der Regel für die einfache und lineare Regression. Die Linearität bei der einfachen linearen Regression kann man prüfen, indem man sich die Daten grafisch betrachtet. Die Normalität der Residuen kann sowohl durch grafische Plots als auch durch den Shapiro-Wilk Test (und weitere) geprüft werden. Diese Annahme besagt, dass die Fehler der Modelle normalverteilt sind. Homoskedastizität ist eine der schwierigsten Annahmen. Diese Anname besagt, dass die Varianz der Residuen (der Fehler) für jeden Wert X etwa gleich sein sollten. Für die Regressionsanalysen heißt dies, dass die Fehler sich gleichmäßig im Modell verteilen. Für die Varianzanalyse heißt dies, dass die Varianzen der einzelnen Gruppen ähnlich zueinander sind. Geprüft wird diese Annahme häufig durch den Levene Test. Zuletzt nehmen die Tests die Unabhängigkeit der Daten . Die Unabhängigkeit kann man nur durch die Sichtung des experimentellen Designs prüfen. Wenn du beispielsweise Schulklassen Daten erhebst, sind diese Daten selten unabhängig, da Schüler*innen innerhalb einer Klasse mehr Ähnlichkeiten aufweisen als Schüler*innen zwischen Klassen (indem beispielsweise eine Klasse mehr Wissen über eine Thematik hat als eine andere Klasse). diesem Kurs haben wir keine Tests kennen gelernt, mit denen Hypothesen mit abhängigen Daten gerechnet werden könnten. Dies wäre für dich ein nächster Schritt, wenn du über die Inhalte dieses Kurses hinaus gehen möchtest (siehe Repeated Measures Design). Im Folgenden werden wir die einzelnen Testverfahren kennen lernen.","code":""},{"path":"statistische-voraussetzungen.html","id":"linearität","chapter":"13 Statistische Voraussetzungen","heading":"13.3 Linearität","text":"Beginnen wir mit der Linearität. Und schauen wir uns dazu nochmal das erweiterte Modell der linearen Regression aus diesem Kurs . diesem Modell hatten wir die Hypothese aufgestellt, dass es einen positiven Zusammenhang zwischen der Anzahl der Worte einer Mitschrift von Studierenden und der Erinnerungsleistung aus einem Vortrag gibt. Folgendes Modell hatte sich damals ergeben:Du siehst, dass das erweiterte Modell (hier blau dargestellt) eine Linie darstellt. Genau dies meinen wir mit Linearität. Wir nehmen , dass die Daten eine lineare Beziehung haben. Um besser zu verstehen, eine lineare Beziehung ist, schau dir folgende Datenvisualisierungen :Diese Darstellung ist das Anscombe Quartett angelehnt, welches vom Statistiker Francis Anscombe entwickelt wurde. Die Daten selbst stammen von Albert Cairo, einem Datenvisualisierer, welcher mit diesen Beispielen zeigen möchte, wie wichtig es ist, Daten zu visualisieren. Uns zeigt diese Darstellung, dass Daten nicht immer linear sind. Allerdings ist dies eine Annahme des allgemeinen linearen Modells. Nun, warum ist eine Verletzung dieser Annahme ein Problem? Es ist ein Problem, da das lineare Modell manchmal eine lineare Beziehung annimmt, die nicht linear ist. Nehmen wir einmal den exponentiellen Anstieg der Covid Fälle weltweit. Exponentiell bedeutet, dass für jede Wertsteigerung von X, Y höher ansteigt. Modelle sollen allerdings immer einen Teil der Wirklichkeit darstellen. Ein lineares Modell stellt diesem Beispiel diese Wirklichkeit nicht dar und ist daher nicht geeignet, als Modell der Daten zu dienen. Für dich als Forscher*heißt dies, dass es bei jeder linearen oder multiplen Regression notwendig ist, die Daten zu visualisieren, bevor du einen Test rechnest. Ist die Beziehung zwischen X und Y offensichtlich nicht linear, ist das allgemeine lineare Modell evtl. nicht passend und du solltest ein anderes Modell verwenden (siehe hier).","code":""},{"path":"statistische-voraussetzungen.html","id":"normalverteilung-der-residuen","chapter":"13 Statistische Voraussetzungen","heading":"13.4 Normalverteilung der Residuen","text":"Die erste Annahme ist die Normalverteilung der Residuen. Diese Annahme bedeutet, dass die Fehler der Modelle normalverteilt sind:Wir prüfen demnach, ob die Abstände einer jeden Vorhersage des Modells mit den wahren Werten der Stichprobe eine Normalverteilung darstellen.","code":""},{"path":"statistische-voraussetzungen.html","id":"prüfung-der-annahme-durch-ein-histogramm-der-residuen","chapter":"13 Statistische Voraussetzungen","heading":"13.4.1 Prüfung der Annahme durch ein Histogramm der Residuen","text":"Schauen wir uns dazu die Verteilung der Residuen der einfachen linearen Regression zu Beginn des Kurses . Bei diesem Modell hatten wir den Zusammenhang zwischen der Anzahl der Worte einer Mitschrift und der Erinnerungsleistung aus einen Vortrag geprüft. Wenn ich die Fehler des erweiterten Modells ei als Histogramm darstelle, erhalte ich folgendes Ergebnis:Nun, die Fehler verteilen sich nicht perfekt einer Normalverteilung. Die Verteilung ist ein wenig rechtsschief, da mehr Werte links der Mitte der Verteilung zu finden sind. Ein Histogramm ist allerdings nur eine Möglichkeit, die Normalverteilung der Residuen zu prüfen. Häufig wird auch der Q-Q Plot verwendet.","code":""},{"path":"statistische-voraussetzungen.html","id":"q-q-plot","chapter":"13 Statistische Voraussetzungen","heading":"13.4.2 Q-Q Plot","text":"Die Einzelheiten eines Q-Q Plots sind kompliziert, für dich als Forscher*ist zunächst wichtig, wie man mit einem Q-Q Plot umgeht: Je näher die Punkte des Q-Q Plots der dargestellten Gerade liegen, desto stärker sind die Residuen normalverteilt. der folgenden Darstellung siehst du den Q-Q Plot für die Daten der einfachen linearen Regression, welche wir weiter oben vorgestellt haben. Wie du siehst, gibt es Abweichungen der Punkte von der Linie, allerdings sind diese Abweichungen nicht erstaunlich groß. Es kann daher argumentiert werden, dass die Annahme der Normalverteilung der Residuen nicht verletzt wurde.","code":""},{"path":"statistische-voraussetzungen.html","id":"was-ist-mit-anderen-testverfahren","chapter":"13 Statistische Voraussetzungen","heading":"13.4.3 Was ist mit anderen Testverfahren?","text":"Wir haben gerade das Beispiel der einfachen linearen Regression verwendet. Das Argument kann jedoch für alle unsere Tests verwendet werden, da wir wissen, dass das erweiterte Modell Vorhersagen macht, die von den realen Werten abweichen. Wir können daher für jeden Test sowohl ein Histogramm als auch ein Q-Q Plot erstellen. Genau deswegen findest du bei der ANOVA Jamovi ebenso unter Assumption Checks eine Checkbox, bei der du dir einen Q-Q Plot ausgeben lassen kannst. Zum Beispiel haben wir im Modul zur einfaktoriellen Varianzanalyse getestet, ob das Testen von Wissen für den Erwerb konzeptuellen Wissens wirksamer ist als die Erstellung einer Concept-Map. Im folgenden Bild siehst du, dass wir ebenso für diesen Test die Normalität mit Hilfe eines Q-Q Plots testen können.","code":""},{"path":"statistische-voraussetzungen.html","id":"shapiro-wilk-test","chapter":"13 Statistische Voraussetzungen","heading":"13.4.4 Shapiro-Wilk Test","text":"Ein weiterer Test zur Prüfung der Normalverteilung ist der Shapiro-Wilk Test. Allerdings weicht dieser Test ein wenig von der eben vorgestellten Idee der Normalverteilung ab, da er testet, ob die Daten, nicht die Residuen normalverteilt sind. Der Test beantwortet daher eine etwas andere Frage und macht eine Aussage über die Normalverteilung der Daten. Bei einem nicht-signifikanten Ergebnis wird davon ausgegangen, dass die Daten normalverteilt sind. Jamovi können wir den Shapiro-Wilk Test berechnen, indem wir unter Assumption Checks auf Normality (Shapiro-Wilk) klicken. den Ergebnissen erhalten wir anschließend das Ergebnis. Im folgenden Bild habe ich den Shapiro-Wilk Test für die Testing-Hypothese (Testing vs. Concept-Map) berechnet. Du siehst, dass das Ergebnis nicht signifikant ist, daher kann von einer Normalverteilung der Daten ausgegangen werden.","code":""},{"path":"statistische-voraussetzungen.html","id":"zusammenfassung-24","chapter":"13 Statistische Voraussetzungen","heading":"13.4.5 Zusammenfassung","text":"Die Annahme der Normalverteilung der Residuen geht davon aus, dass die Fehler des erweiterten Modells eine Normalverteilung darstellen. Wir haben drei Wege kennen gelernt, diese Annahme zu prüfen. Die Darstellung der Fehler einem Histogramm, den Q-Q Plot und den Shapiro-Wilk Test. besten schaust du dir sowohl grafische Verfahren und prüfst die Annahme durch einen Test wie den Shapiro-Wilk Test. Inwieweit Verletzungen der Normalität die Ergebnisse verfälschen, ist eine umfangreiche Debatte (siehe auch Schmider et al., 2010 und diesen Beitrag). Du solltest daher immer abwägen und recherchieren, ob dein Test Gefahr läuft, durch Verletzungen der Annahme der Normalverteilung verfälschte Ergebnisse zu liefern.","code":""},{"path":"statistische-voraussetzungen.html","id":"homoskedastizität","chapter":"13 Statistische Voraussetzungen","heading":"13.5 Homoskedastizität","text":"Eine der kryptischsten Annahmen ist die Homoskedastizität. Der Begriff klingt bereits neu, dass man sich keine Vorstellung machen kann, er bedeutet. Machen wir einen Versuch diesem Submodul. Die Definition der Annahme ist, dass die Varianz der Residuen für jeden Wert von X gleich sein soll.","code":""},{"path":"statistische-voraussetzungen.html","id":"residual-plots","chapter":"13 Statistische Voraussetzungen","heading":"13.5.1 Residual Plots","text":"Beginnen wir, uns diese Definition Beispiel der linearen Regression klar zu machen. Im nächsten Bild siehst du einen sogenannten Residual Plot. dieser Darstellung ist auf der X-Achse die unabhängige Variabe (Anzahl der Worte der Mitschrift) dargestellt. Auf der Y-Achse sind die Residuen abgetragen. Schau dir beispielsweise den Punkt ganz rechts der X-Achse . Der Punkt befindet sich auf der Y-Achse auf der Höhe von etwa 0.1. Das heißt, für den Wert X wurde der wahre Wert Y um 0.1 Punkte überschätzt.Wir können diesen Residual Plot nutzen, um die Homoskedastizität zu prüfen. dem Plot können wir diese Annahme prüfen, indem wir folgendermaßen vorgehen: Wir fragen uns, ob die Abstände der Punkte zu der Linie für die verschiedenen Werte auf der X-Achse gleichmäßig sind? der oberen Visalisierung siehst du beispielsweise, dass die Abstände der Residuen zu der Linie für kleine Werte von X weiter sind als für hohe Werte von X. der Tendenz herrscht daher keine perfekte Homoskedastizität vor. Residual plots werden allerdings meist nicht anhand der Werte der Prädiktoren, sondern durch sogenannte Fitted Values dargestellt. Fitted Values sind nichts anderes als die vorhergesagte Werte einem Modell. der folgenden Visualisierung siehst du einen Residual Plot, dem statt des Prädiktors auf der X-Achse die Fitted Values dargestellt sind.Wie du siehst, sieht diese Darstellung exakt gleich aus wie oben. Dies liegt allerdings daran, dass wir eine einfache lineare Regression verwendet haben. Bei einer einfaktoriellen Varianzanalyse sähe diese Darstellung anders aus. Du solltest daher wenn möglich auf die Fitted Values zurück greifen.Um ein extremes Beispiel zu sehen, empfehle ich dir diesen Link. Dort wird anhand von zwei Grafiken sehr schnell ersichtlich, wie eine Verletzung der Homoskedastizität aussieht.","code":""},{"path":"statistische-voraussetzungen.html","id":"prüfung-der-homoskedastizität-durch-die-darstellung-der-regressionsgerade","chapter":"13 Statistische Voraussetzungen","heading":"13.5.2 Prüfung der Homoskedastizität durch die Darstellung der Regressionsgerade","text":"Bei der einfachen linearen Regression können wir diese Annahme zudem prüfen, indem wir uns die Abstände der Punkte von der Regressionsgerade ansehen. Dieses Verfahren ist den Residual Plots sehr ähnlich, nur dass wir die Visualisierung anders betrachten müssen. Wenn du nun diese Darstellung mit dem Residual Plot vergleichst, siehst du der rechten Hälfte der beiden Visualisierungen, dass die Abstände der Punkte von der Regressionsgerade ähnlich aussehen, und dass diese Abstände auf der rechten Hälfte der X-Achse kleiner sind als auf der linken Hälfte der X-Achse. Grafisch ist der Residual Plot daher nichts anderes als wenn du die Regressionsgerade horizontal richtest und die Daten entsprechend der Regressionsgerade angepasst werden.","code":""},{"path":"statistische-voraussetzungen.html","id":"prüfung-der-homoskedastizität-durch-den-levene-test","chapter":"13 Statistische Voraussetzungen","heading":"13.5.3 Prüfung der Homoskedastizität durch den Levene-Test","text":"Bei der einfachen linearen Regression lassen sich sehr einfach grafische Verfahren einsetzen. Bei den Verfahren der Varianzanalsye ist dies etwas schwieriger. Daher gibt es Tests, die prüfen können, ob die Varianzen der Prädiktoren bei unterschiedlichen Ausprägungen ähnlich sind. Gehen wir einen Schritt zurück die erweiterten Modelle der Varianzanalyse. Bei diesen Modellen mussten wir Gruppen als Kontraste kodieren, indem wir Gruppen numerische Werte überführt haben. Wenn wir nun sagen, dass die Varianzen der Prädiktoren bei unterschiedlichen Ausprägungen der Prädiktoren gleich sein sollen, meinen wir folgendes: Die Varianzen der Gruppen sollten zwischen den Gruppen gleich sein. Wenn du beispielsweise eine einfaktorielle Varianzanalyse mit zwei Gruppen rechnest (t-Test für unabhängige Stichproben), prüfst du für die Feststellung der Homoskedastizität, ob die Varianzen von Gruppe 1 und von Gruppe 2 ähnlich sind. Die Idee bleibt die selbe wie bei der einfachen linearen Regression, nur dass wir bei der Varianzanalyse von den Varianzen der Gruppen und nicht von Ausprägungen der Werte des Prädiktoren denken müssen. Und wir testen diese Annahme mit Hilfe des Levene-Tests.Der Levene-Test ist erneut ein statistischer Hypothesentest, der folgende Ergebnisse liefert. Ist das Ergebnis signifikant, ist keine Homoskedastizität gegeben. Ist das Ergebnis nicht signfikant, ist Homoskedastizität gegeben. Jamovi erlaubt für jede Varianzanalyse den Levene-Test zu berechnen. Klicke dazu auf Assumption Checks und dann auf Homogeneity tests. folgendem Beispiel erhalten wir kein signifikantes Ergebnis, daher kann von der Annahme der Homoskedastizität ausgegangen werden.","code":""},{"path":"statistische-voraussetzungen.html","id":"zusammenfassung-25","chapter":"13 Statistische Voraussetzungen","heading":"13.5.4 Zusammenfassung","text":"Die Homoskedastizität ist eine der weiteren Annahmen des allgemeinen linearen Modells und daher von allen Tests, die wir diesem Kurs kennen gelernt haben. Die Annahme ist umgesetzt, wenn die Varianz der verschiedenen Ausprägungen der Prädiktoren gleichmäßig ist. Bei der linearen Regression können wir diese Annahme grafisch prüfen, bei der Varianzanalyse können wir den Levene-Test verwenden.","code":""},{"path":"statistische-voraussetzungen.html","id":"unabhängigkeit-der-daten","chapter":"13 Statistische Voraussetzungen","heading":"13.6 Unabhängigkeit der Daten","text":"Alle bisherigen Tests dieses Kurses sind davon ausgegangen, dass unsere Daten unabhängig voneinander sind. Unabhängigkeit tritt immer dann auf, wenn uns das Auftreten eines Wertes Xi keine Aussage über eine andere Ausprägung von Xi macht. Stell dir einen t-Test für unabhängige Stichproben vor, bei dem wir vor einer Intervention das Vorwissen von zwei Gruppen vergleichen. Die Kenntnis über das Vorwissen einer Person ermöglicht dir nicht, das Vorwissen einer anderen Person vor der Intervention zu bestimmen. Allerdings sind nicht alle Daten immer unabhängig voneinander. Stell dir vor, du möchtest vergleichen, ob Männer und Frauen unterschiedlich zufrieden ihrer Beziehung sind. Hierzu befragst du sowohl Männer und Frauen aus vier Paaren nach ihrer Beziehungszufriedenheit:Wenn du nun den Wert eines Partners kennst, erhältst du automatisch Informationen über den Wert des anderen Partners. Da sich Paare zu einem gewissen Teil übereinstimmen, wie zufrieden sie ihrer Beziehung sind, sind die Daten voneinander abhängig. Ist ein Partner unter dem Mittelwert der abhängigen Variable, wird der Partner oder die Partnerin vermutlich ebenso unter dem Mittelwert sein. Wir nennen diese Art der Abhängigkeit positive Abhängigkeit, da die Daten ähnlich zueinander sind. Eine negative Abhängigkeit würde auftreten, wenn Werte gegensätzlich voneinander abhängig sind. Stell dir zum Beispiel vor, du testest die Breite von Baumkronen. Deine Daten umfassen Baumpaare, die sehr eng beieinander stehen. Wenn nun ein Baum eine sehr breite Krone hat, wird der benachbarte Baum vermutlich eine kleinere Krone haben, da beide um das Sonnenlicht kämpfen. diesem Fall sprechen wir von einer negativen Abhängigkeit.Abhängigkeit kann einerseits entstehen, wenn Daten wie diesen Beispielen gruppiert sind, andererseits tritt Abhängigkeit auf, wenn Daten sequentiell erhoben werden. Stell dir hierzu vor, du erhebst die Cholesterinwerte von Proband*innen über mehrere Messzeitpunkte, um zu prüfen, ob der Cholesterinspiegel der Personen steigt oder sinkt. Eine Person, die bereits beim ersten Messzeitpunkt einen hohen Cholesterinspiegel hat, wird vermutlich auch beim zweiten Messzeitpunkt einen hohen Cholesterspiegel haben. Genausogut wird eine Person, die einen niedrigen Cholesterinspiegel beim ersten Messzeitpunkt hat, vermutlich auch beim zweiten Messzeitpunkt einen niedrigen Cholesterinspiegel haben. Die Folge ist, dass die Daten abhängig voneinander sind. Aus den Daten allein können wir nicht sagen, ob die Abhängigkeit durch eine Gruppierung oder durch sequentielle Messzeitpunkte geschieht. Es ist unser Versuchsdesign, welches uns Hinweise liefert, welche Abhängigkeit vorherrscht. Wir nennen diese zwei Möglichkeiten gekreuzte Daten und genestete Daten.","code":""},{"path":"statistische-voraussetzungen.html","id":"gekreuzte-daten","chapter":"13 Statistische Voraussetzungen","heading":"13.6.1 Gekreuzte Daten","text":"Normalerweise treten gekreuzte Daten auf, wenn wir Daten einer Versuchsperson mehrmals erheben. Wir haben gerade eben bereits das Beispiel des Cholesterins kennen gelernt. Der Cholesterinspiegel von Proband*innen wird mehrmals gemessen. Stell dir ein anderes Beispiel vor: Du möchtest untersuchen, ob eine bestimmte Übung einen Einfluss darauf hat, wie schnell Proband*innen einen Meditationszustand kommen. Du gehst davon aus, dass Proband*innen, die diese Übung über längere Zeit durchführen, schneller einen Meditationszustand kommen. Alle Proband*innen führen die Übung über drei Wochen durch. Du testest die Dauer bis die Proband*innen den Meditationszustand kommen je einmal wöchentlich. Folgende Ergebnisse erhältst du: Zunächst kannst du anhand der Tabelle erkennen, dass die Proband*innen im Schnitt über die Wochen schneller den Meditationszustand kommen. Die Probandin mit der ID 4 zum Beispiel benötigt Anfang 250 Sekunden, dann 230 Sekunden, dann 210 Sekunden. Ebenso erkennst du, dass die Daten abhängig voneinander sind. Beispielsweise fällt auf, dass die Werte der Probandin mit der ID 4 relativ hoch bleiben, wenn wir sie mit der Probandin mit der ID 2 vergleichen. Wer bereits lange Zeit beim ersten Messzeitpunkt benötigt, wird auch beim nächsten Messzeitpunkt mehr Zeit benötigen.Wann sind die Daten allerdings gekreuzt? Wir sprechen von gekreuzten Daten, wenn die Werte einzelner Personen verschiedenen Ausprägungen eines Faktors vorliegen. diesem Fall haben wir den Faktor Zeitpunkt mit drei Ausprägungen (Woche 1, Woche 2, Woche 3). Für jede*n Proband*liegt ein Wert jeder Ausprägung vor. Die Daten wären nicht gekreuzt, wenn Daten nur einer Ausprägung eines Faktors vorlägen. Stell dir zum Beispiel mehrere Schulklassen vor, die unterschiedliche Lernstrategien erhalten. Schulklasse , B und C erhalten Lernstrategie Z und Schulklasse D, E und F erhalten Lernstrategie Q. Die Abhängigkeit der Daten entsteht dadurch, dass die Schüler*innen jeweils der gleichen Klasse stecken. Diese Daten sind nicht gekreuzt, da die Schüler*innen nur je einer Ausprägung des Faktors Schulklasse stecken.Ein anderes Beispiel: Du möchtest prüfen, ob sich das Verhalten von Schüler*innen ändert, wenn man ihnen öfter Lob gibt. Bisher hätten wir solche Fragestellungen getestet, indem wir zwei unabhängige Gruppen umgesetzt hätten, welche entweder gelobt werden oder nicht gelobt werden. Durch ein solches Design könnten wir allerdings nicht prüfen, ob Lob über die Zeit zu einer Veränderung des Verhaltens der Schüler*innen führt. deinem neuen Design gibst du daher allen Schüler*innen über fünf Messzeitpunkte Lob. Erneut sind die Daten gekreuzt, da für jede Ausprägung des Faktors Messzeitpunkt ein Datenpunkt je eines Schülers / einer Schülerin steckt. den Lehrbüchern spricht man dann der Regel von Messwiederholungsdesigns. Diese sind der einfachsten Form immer dadurch erkennbar, dass die Daten gekreuzt sind.","code":""},{"path":"statistische-voraussetzungen.html","id":"genestete-daten","chapter":"13 Statistische Voraussetzungen","heading":"13.6.2 Genestete Daten","text":"Wir hatten genestete Daten bereits mit unserem Schulklassenbeispiel kennen gelernt. Schüler*innen innerhalb einer Schulklasse erhalten entweder die Lernstrategie Q oder die Lernstrategie Z. Genestete Daten zeichnen sich dadurch aus, dass die Proband*innen bzw. Datenpunkte nur einer Ausprägung eines Faktors vorliegen. diesem Fall erhalten die Schüler*innen der jeweiligen Gruppen nur eine der beiden Lernstrategien. Diese Aussage gilt nur für den Fall, wenn wir entweder gekreuzte oder genestete Daten vorliegen haben. Es gibt auch Designs, die beide Strukturen beinhalten. Über diese Designs werden wir allerdings diesem Modul nicht sprechen. Um genestete Daten besser zu verstehen, siehst du hier Beispiel des Lernstrategietrainings:der Tabelle kannst du erkennen, dass die Schüler*innen innerhalb einer Schule immer nur entweder Treatment Q oder Treatment Z bekommen. Die Daten sind daher nicht gekreuzt. Allerdings sind die Daten unter dem Faktor der Schulklasse genested, dazu führst, dass sich Schüler*innen innerhalb einer Klasse ähnlich sind. Manche Klassen sind im Schnitt besser als die anderen Klassen. Hierdurch wissen wir, dass beispielsweise eine Schülerin aus Klasse , die sehr gut ist, vermutlich besser sein wird, als eine Schülerin aus Klasse B, die etwas schlechter ist. Genestete Daten finden sich sehr häufig großen Schulstudien, denen Erhebungen Klassen erhoben werden. Stell dir beispielsweise die PISA-Studie vor, der nicht nur Klassen, sondern auch Schulen genested vorliegen können. Die statistischen Verfahren solchen Designs werden zunehmend komplexer.","code":""},{"path":"statistische-voraussetzungen.html","id":"folgen-gekreuzter-und-genesteter-daten-für-die-power-einer-studie","chapter":"13 Statistische Voraussetzungen","heading":"13.6.3 Folgen gekreuzter und genesteter Daten für die Power einer Studie","text":"Ignoriert man die gekreuzte oder genestete Struktur von Daten, hat dies Einfluss auf den F-Wert und damit auch auf die Power einer Studie. Verletzung der Annahme der Unabhängigkeit sind die gravierendsten und sollten auf jeden Fall beachtet werden, wenn man die Daten mit Hilfe verschiedener statistischer Verfahren auswertet. Eine Übersicht der Auswirkungen siehst du der folgenden Tabelle: Stell dir ein Beispiel vor: Du möchtest eine Messwiederholungsanalyse mit gekreuzten Daten rechnen. Innerhalb der Daten herrscht eine positive Abhängigkeit. Beispielsweise indem man die Entwicklung der intrinsischen Motivation von Studierenden über eine längere Zeit testet. Wer Anfang intrinsisch motiviert ist, wird wohl auch später intrinsisch motiviert sein. Verletzt du nun die Annahme der Abhängigkeit und berechnest statt einer Messwiederholungsanalyse eine einfaktorielle Varianzanalyse, erhältst du der Regel einen zu kleinen F-Wert. Dies bedeutet, du bist mit einer geringeren Wahrscheinlichkeit der Lage, einen möglichen Effekt zu finden, da deine Power geringer wird. Als Folge könntest du über viele Experimente zu dem Entschluss kommen, dass es zu keiner Veränderung der intrinsischen Motivation kommt, obwohl dieser Effekt existiert. Du solltest daher von vorneherein überlegen, ob dein Design abhängig oder unabhängig ist. Erst dann kannst du die korrekten Verfahren zum Testen deiner Hypothese auswählen.","code":""},{"path":"statistische-voraussetzungen.html","id":"zusammenfassung-26","chapter":"13 Statistische Voraussetzungen","heading":"13.6.4 Zusammenfassung","text":"Wir haben diesem Modul die Vorraussetzungen der allgemeinen linearen Modelle und damit unserer Testverfahren kennen gelernt. Manchmal werden diese Annahmen verletzt und dann müssen wir uns Gedanken machen, wie wir damit umgehen. Es gibt dabei keine festen Regeln, wie mit Verletzungen der Annahmen umgegangen werden soll. Forschende verfahren sehr unterschiedlich. Manche nehmen es sehr ernst mit den Verletzungen der Annahmen, andere weniger. jedem Fall solltest du darüber informiert sein, dass es diese Annahmen gibt und dass diese deine Ergebnisse verfälschen können. Mit diesem Modul haben wir diesen Kurs abgeschlossen. Du solltest nun der Lage sein, die meisten statistischen Fragestellungen durch die besprochenen Testverfahren prüfen zu können. Die wichtigste Botschaft dieses Kurses ist, dass wir nie Theorien bestätigen können, sondern nur falsifizeren können. Der Begriff der Signifikanz ist nur ein statistischer Ausdruck für diese Idee. Die andere zentrale Botschaft dieses Kurses ist, dass alle Testverfahren dieses Kurses durch das allgemeine lineare Modell geprüft werden können, indem wir erweiterte und kompakte Modelle aufstellen. Hast du diese Idee einmal verstanden, wirst du erkennen, dass ein t-Test für unabhängige Stichproben nur ein Sonderfall der einfaktoriellen Varianzanalyse ist. Und dass die einfache lineare Regression mit der einfaktoriellen Varianzanalyse zu vergleichen ist, nur dass die Prädiktoren anders definiert sind. Ich hoffe, ich konnte dir diese beiden Ideen diesem Kurs vermitteln.","code":""},{"path":"was-du-sonst-noch-wissen-musst.html","id":"was-du-sonst-noch-wissen-musst","chapter":"14 Was du sonst noch wissen musst","heading":"14 Was du sonst noch wissen musst","text":"","code":""},{"path":"was-du-sonst-noch-wissen-musst.html","id":"interraterreliabilität","chapter":"14 Was du sonst noch wissen musst","heading":"14.1 Interraterreliabilität","text":"","code":""},{"path":"was-du-sonst-noch-wissen-musst.html","id":"cronbachs-alpha-and-omegas-alpha","chapter":"14 Was du sonst noch wissen musst","heading":"14.2 Cronbach’s Alpha and Omega’s Alpha","text":"https://www.tandfonline.com/doi/full/10.1080/19312458.2020.1718629","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
